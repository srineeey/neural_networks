{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import dataset_class_gsimage\n",
    "import torch_net_class\n",
    "import utils\n",
    "\n",
    "import functools\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizing CUDA\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Utilizing CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Utilizing CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load Data\n",
    "\"\"\"\n",
    "mnist_image_folder = \"../mnist_cnn/mnist/\"\n",
    "mnist_image_names = os.listdir(mnist_image_folder)\n",
    "mnist_image_paths = glob.glob(mnist_image_folder + \"*\")\n",
    "image_size = [1,28,28]\n",
    "label_path_csv = \"mnist_labels.csv\"\n",
    "dataset = dataset_class_gsimage.image_dataset(mnist_image_folder, mnist_image_paths, image_size, label_path_csv)\n",
    "dataset.label_df.head()\n",
    "target_attributes = [\"number\"]\n",
    "output_attributes = [str(i) for i in range(0,10)]\n",
    "pred_attributes = [str(i) for i in range(np.prod(image_size))]\n",
    "#dataset.set_label_names(target_attributes)\n",
    "dataset.label_names = target_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset.get_image(50)[0].reshape([28,28]))\n",
    "print(dataset.get_image(50)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1, 28, 28]\n",
      "[3, 3]\n",
      "1\n",
      "[32, 26, 26]\n",
      "[2, 2]\n",
      "2\n",
      "[32, 13, 13]\n",
      "[4, 4]\n",
      "3\n",
      "[64, 10, 10]\n",
      "[2, 2]\n",
      "0\n",
      "[1, 28, 28]\n",
      "[3, 3]\n",
      "1\n",
      "[32, 26, 26]\n",
      "[2, 2]\n",
      "2\n",
      "[32, 13, 13]\n",
      "[4, 4]\n",
      "3\n",
      "[64, 10, 10]\n",
      "[2, 2]\n",
      "4\n",
      "[64, 5, 5]\n",
      "5\n",
      "1600\n",
      "6\n",
      "1600\n",
      "7\n",
      "1600\n",
      "8\n",
      "1600\n",
      "9\n",
      "1600\n",
      "10\n",
      "10\n",
      "[[1, 28, 28], [32, 26, 26], [32, 13, 13], [64, 10, 10], [64, 5, 5], 1600, 1600, 1600, 1600, 1600, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HYPERPARAMETERS\n",
    "\"\"\"\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "val_epochs = [10,20,30]\n",
    "save_state_epochs = [10000]\n",
    "\n",
    "\n",
    "\"\"\"Manually set network structure\"\"\"\n",
    "\"\"\"\n",
    "    This list can be loaded into the constructor of the Net neural network class, to automatically generate the network structure\n",
    "    type = pointer to the layer function'\n",
    "    layer_pars = parameters which must be given to the layer function in order to initialize it\n",
    "    act_func = activation function to be applied directly after feeding to the corresponding layer\n",
    "    dropout = certain neurons cna be dropped out if specified\n",
    "\"\"\"\n",
    "\n",
    "fixed_net_struct = []\n",
    "image_size = dataset.get_image_size()\n",
    "input_size = image_size\n",
    "target_size = len(target_attributes)\n",
    "#output_size = target_size\n",
    "output_size = len(output_attributes)\n",
    "\n",
    "#[ [[in_channels, out_channels],[kernel_size], ...]\n",
    "kernel_pars = [ [[input_size[0],32],[3,3],1,0], [[32,32],[2,2],2,0], [[32,64],[4,4],1,0], [[64,64],[2,2],2,0] ]\n",
    "act_func = torch.relu\n",
    "\n",
    "for i, kernel_par in enumerate(kernel_pars):\n",
    "    if i%2 == 0:\n",
    "        layer_type = nn.Conv2d\n",
    "        fixed_net_struct.append( {\"type\": layer_type, \"layer_pars\": {\"in_channels\": kernel_par[0][0], \"out_channels\": kernel_par[0][1], \"kernel_size\": kernel_par[1], \"stride\": kernel_par[2], \"padding\": kernel_par[3], \"bias\": True}, \"act_func\": act_func} )\n",
    "    else:\n",
    "        layer_type = nn.MaxPool2d\n",
    "        fixed_net_struct.append( {\"type\": layer_type, \"layer_pars\": {\"kernel_size\": kernel_par[1], \"stride\": kernel_par[2], \"padding\": kernel_par[3]}} )\n",
    "    \n",
    "conv_sizes = utils.calc_layer_sizes(input_size, fixed_net_struct)\n",
    "fc_input_size = np.product(conv_sizes[-1])\n",
    "fixed_net_struct.append( {\"type\": nn.Flatten, \"layer_pars\": {\"start_dim\": 1}} )    \n",
    "#fixed_net_struct.append( {\"type\": utils.Reshape, \"layer_pars\": {\"new_shape\": [-1,fc_input_size]}} )    \n",
    "fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": fc_input_size, \"out_features\": fc_input_size}, \"bias\": True, \"act_func\": act_func} )\n",
    "fixed_net_struct.append( {\"type\": nn.BatchNorm1d, \"layer_pars\": {\"num_features\": fc_input_size}} )\n",
    "fixed_net_struct.append( {\"type\": nn.Dropout, \"layer_pars\": {\"p\": 0.25 }} )\n",
    "fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": fc_input_size, \"out_features\": fc_input_size}, \"bias\": True, \"act_func\": act_func} )\n",
    "fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": fc_input_size, \"out_features\": output_size}, \"bias\": True, \"act_func\": act_func} )\n",
    "fixed_net_struct.append( {\"type\": nn.Softmax, \"layer_pars\": {\"dim\": 1}} )\n",
    "#dim 0 or 1???\n",
    "#fixed_net_struct.append( {\"type\": nn.ConvTranspose2d, \"layer_pars\": {\"in_channels\": 1, \"out_channels\": 1, \"kernel_size\": [1,1], \"stride\": 1, \"padding\": 1, \"bias\": True}, \"act_func\": act_func} )\n",
    "\n",
    "layer_sizes = utils.calc_layer_sizes(input_size, fixed_net_struct)\n",
    "print(layer_sizes)\n",
    "\n",
    "\"\"\"create list of parameters manually\"\"\"\n",
    "\n",
    "hyper_parameters = {}\n",
    "hyper_parameters[\"loss_func\"] = nn.CrossEntropyLoss\n",
    "hyper_parameters[\"optimizer\"] = optim.Adam\n",
    "hyper_parameters[\"batch_size\"] = 10 \n",
    "hyper_parameters[\"lr\"] = 0.0001\n",
    "hyper_parameters[\"net_struct\"] = fixed_net_struct\n",
    "\n",
    "hyper_parameters[\"val_method\"] = \"holdout\"\n",
    "hyper_parameters[\"val_method_pars\"] = {\"train\" : 0.9, \"val\" : 0.1, \"test\" : 0.}\n",
    "#hyper_parameters[\"val_method\"] = \"k_fold\"\n",
    "#hyper_parameters[\"val_method_pars\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = max(val_epochs)+1\n",
    "\n",
    "lr=hyper_parameters[\"lr\"]\n",
    "batch_size = hyper_parameters[\"batch_size\"]\n",
    "loss_func = hyper_parameters[\"loss_func\"]()\n",
    "net_struct = hyper_parameters[\"net_struct\"]\n",
    "val_method = hyper_parameters[\"val_method\"]\n",
    "val_method_pars = hyper_parameters[\"val_method_pars\"]\n",
    "optimizer_type = hyper_parameters[\"optimizer\"]\n",
    "\n",
    "val_pred_paths = []\n",
    "val_label_paths = []\n",
    "\n",
    "train_loss = np.zeros(epochs)\n",
    "val_loss = np.zeros(len(val_epochs))\n",
    "\n",
    "net_state_paths = []\n",
    "\n",
    "#create training log\n",
    "log_file_name = \"log.txt\"\n",
    "log_file = open(log_file_name, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = SummaryWriter()\n",
    "\n",
    "net = torch_net_class.Net(net_struct, dataset.get_image_size())    \n",
    "net.init_weights(torch.nn.init.xavier_normal_)\n",
    "net.set_batch_size(batch_size)\n",
    "#net.set_layer_sizes(layer_sizes)\n",
    "net.to(device)\n",
    "#net.show_layers()\n",
    "net_parameters = net.parameters()\n",
    "\n",
    "optimizer = optimizer_type(net_parameters, lr=lr)\n",
    "\n",
    "\"\"\"SPECIFY OUTSIDE FOR K-FOLD VALIDATION\"\"\"\n",
    "data_loader = utils.load_split_data(dataset=dataset, batch_size=batch_size, method=val_method, method_pars=val_method_pars, random_seed=random_seed, log_file=log_file)\n",
    "\n",
    "if val_method == \"holdout\":\n",
    "    test_loader = data_loader[2]\n",
    "val_loader = data_loader[1]\n",
    "train_loader = data_loader[0]\n",
    "\n",
    "val_dir = \"val/\"\n",
    "try:\n",
    "    os.makedirs(val_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "train_state_dir = \"net_states/\"\n",
    "try:\n",
    "    os.makedirs(train_state_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "epoch = 0\n",
    "val_i = 0\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    batch_nr = 0\n",
    "    epoch_loss = np.zeros(len(train_loader))\n",
    "    \n",
    "    \"\"\"Actual training step\"\"\"\n",
    "    for train_mini_batch in train_loader:\n",
    "        batch_loss, train_output = utils.step(net, train_mini_batch, output_size, loss_func, optimizer, device, mode=\"train\", log_file=log_file)\n",
    "        epoch_loss[batch_nr] = batch_loss.item()\n",
    "        batch_nr += 1\n",
    "    mean_epoch_loss = epoch_loss.mean()\n",
    "    train_loss[epoch] = mean_epoch_loss\n",
    "    print(f\"mean epoch {epoch} train loss: {mean_epoch_loss}\\n\")\n",
    "    \n",
    "    \n",
    "    \"\"\"save the neural networks state\"\"\"\n",
    "    if epoch in save_state_epochs:\n",
    "        train_state_epoch_file_path = train_state_dir + f\"state_epoch_{epoch}\"\n",
    "        train_state = {\"epoch\" : epoch, \"state_dict\": net.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "        torch.save(train_state, train_state_epoch_file_path)\n",
    "        net_state_paths.append(train_state_epoch_file_path)\n",
    "        print(f\"saved model from epoch {epoch}\")\n",
    "        \n",
    "    \"\"\"\n",
    "    Validation\n",
    "    \"\"\"\n",
    "    if epoch in val_epochs:\n",
    "        val_label = []\n",
    "        val_pred = []\n",
    "        \n",
    "        val_batch_nr = 0\n",
    "        val_epoch_loss = np.zeros(len(val_loader))\n",
    "        \n",
    "        for val_mini_batch in val_loader:\n",
    "            label_batch = val_mini_batch[1]\n",
    "            val_label.append(label_batch.detach().cpu().numpy())\n",
    "            val_batch_loss, val_output = utils.step(net, val_mini_batch, output_size, loss_func, optimizer, device, mode=\"val\", log_file=log_file)\n",
    "            val_epoch_loss[val_batch_nr] = val_batch_loss.item()\n",
    "            #val_pred.append(val_output.detach().cpu().numpy())\n",
    "            class_batch_pred = []\n",
    "            #print(val_output)\n",
    "            for val in val_output:\n",
    "                class_index = val.argmax().detach().cpu()\n",
    "                class_batch_pred.append(class_index)\n",
    "            #print(class_batch_pred)\n",
    "            val_pred.append(class_batch_pred)\n",
    "            val_batch_nr += 1\n",
    "            \n",
    "        mean_val_epoch_loss = val_epoch_loss.mean()\n",
    "        val_loss[val_i] = mean_val_epoch_loss\n",
    "        print(f\"mean epoch {epoch} val loss: {mean_val_epoch_loss}\\n\")\n",
    "        \n",
    "        val_i += 1\n",
    "        \n",
    "        val_pred_path = val_dir + \"/\" + f\"val_epoch_{epoch}_pred\"\n",
    "        val_label_path = val_dir + \"/\" + f\"val_epoch_{epoch}_labels\"\n",
    "        #print(np.array(functools.reduce(operator.iconcat, val_pred, [])))\n",
    "        np.array(functools.reduce(operator.iconcat, val_pred, [])).tofile(val_pred_path, sep=\" \")\n",
    "        np.array(functools.reduce(operator.iconcat, val_label, [])).tofile(val_label_path, sep=\" \")\n",
    "        #np.array(val_pred).tofile(val_pred_path)\n",
    "        #np.array(val_label).tofile(val_pred_label)\n",
    "        \n",
    "        val_pred_paths.append(val_pred_path)\n",
    "        val_label_paths.append(val_label_path)\n",
    "        \n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot training loss curve and save as image\"\"\"\n",
    "train_loss_img_file_name = \"train_loss.png\"\n",
    "x_epochs = range(epochs)\n",
    "plt.plot(x_epochs, train_loss)\n",
    "#plt.title()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"training loss\")\n",
    "plt.savefig(train_loss_img_file_name)\n",
    "plt.show()\n",
    "plt.close()\n",
    "train_loss_txt_file_name = \"train_loss.txt\"\n",
    "np.savetxt(train_loss_txt_file_name, train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = np.fromfile(val_label_paths[-1], sep=\" \")\n",
    "val_pred = np.fromfile(val_pred_paths[-1], sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = sklearn.metrics.confusion_matrix(val_labels,val_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_conf_mat = conf_mat/conf_mat.sum(axis=1)\n",
    "norm_conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(norm_conf_mat,cmap=\"YlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = sklearn.metrics.accuracy_score(val_labels, val_pred)\n",
    "rec = sklearn.metrics.recall_score(val_labels, val_pred, average=None)\n",
    "prec = sklearn.metrics.precision_score(val_labels, val_pred, average=None)\n",
    "\n",
    "print(\"Accuracy:\\n {}\".format(acc))\n",
    "\n",
    "print(\"Recall:\\n {}\".format(rec))\n",
    "print(\"averaged recall: {} +- {}\".format(rec.mean(), rec.std()) )\n",
    "\n",
    "print(\"Precision:\\n {}\".format(prec))\n",
    "print(\"averaged precision: {} +- {}\".format(prec.mean(), prec.std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
