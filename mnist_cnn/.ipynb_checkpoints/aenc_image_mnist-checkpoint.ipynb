{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot create a consistent method resolution\norder (MRO) for bases Module, AutoEncoder",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-287f054e682a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_class_gsimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0maenc_torch_net_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/qcd_ml/neural_networks/mnist_cnn/aenc_torch_net_class.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mso\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mone\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mreutilize\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mboth\u001b[0m\u001b[0;31m!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \"\"\"\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot create a consistent method resolution\norder (MRO) for bases Module, AutoEncoder"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import itertools\n",
    "\n",
    "import PIL\n",
    "\n",
    "import dataset_class_gsimage\n",
    "import aenc_torch_net_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizing CUDA\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Utilizing CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Utilizing CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function for training loop\n",
    "\"\"\"\n",
    "\n",
    "def step(model, input_data, batch_size, loss_func, optimizer, epoch, batch_nr, device, log_file, mode=\"val\"):\n",
    "        if mode == \"train\":\n",
    "            model.train()\n",
    "        elif mode == \"val\":\n",
    "            model.eval()\n",
    "        \n",
    "        #input data splitted into features and labels\n",
    "        feat_batch = input_data[0].to(device)\n",
    "        label_batch = input_data[1].to(device)\n",
    "        \n",
    "        \"\"\"\n",
    "        input_size = model.get_input_size()\n",
    "        output_size = model.get_output_size()\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "        \"\"\"ALWAYS SET GRADIENT TO ZERO  FOR STANDARD NN (NOT RNNs)\"\"\"\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        the peculiar shape (-1, sample_size) is needed, because an entire mini batch is passed on to the network\n",
    "        initially it is not clear how large such a mini batch is\n",
    "        the -1 acts as a placeholder in order to keep the number of processed items in one mini batch flexible\n",
    "        \"\"\"\n",
    "        #print(\"Input {}, batch: {} : {}\".format(epoch, batch_nr, feat_batch))\n",
    "        #log_file.write(\"Input {}, batch: {} : {}\\n\".format(epoch, batch_nr, feat_batch))\n",
    "        #plt.imshow( input_data[0].view((28,28)) )\n",
    "        \n",
    "        model_input_shape = tuple([-1] + list(input_size))\n",
    "        #print(\"Reshaping to {}\".format( feat_batch.view(model_input_shape).double().size() ))\n",
    "        output = model(feat_batch.view(model_input_shape).float())\n",
    "        output = output.to(device)\n",
    "    \n",
    "        #print(\"Output {}, batch: {} : {}\".format(epoch, batch_nr, output))\n",
    "        #print(\"Label {}, batch: {} : {}\".format(epoch, batch_nr, label_batch))\n",
    "        #log_file.write(\"Output {}, batch: {} : {}\\n\".format(epoch, batch_nr, output))\n",
    "        \n",
    "        #print(\"Input shape {}\".format(feat_batch.size()))\n",
    "        #print(\"Label shape {}\".format(label_batch.size()))\n",
    "        #print(\"Output shape {}\".format(output.size()))\n",
    "    \n",
    "        #print(\"Feeding forward epoch: {}, batch: {}\".format(epoch, batch_nr))\n",
    "        #log_file.write(\"Feeding forward epoch: {}, batch: {}\\n\".format(epoch, batch_nr))\n",
    "    \n",
    "        #print(\"Calculating \" + mode + \" loss epoch: {}, batch: {}\".format(epoch, batch_nr))\n",
    "        #log_file.write(\"Calculating \" + mode + \" loss epoch: {}, batch: {}\\n\".format(epoch, batch_nr))\n",
    "        model_output_shape = tuple([-1,output_size])\n",
    "        \"\"\"MSE\"\"\"\n",
    "        #loss = loss_func(output.view(-1, output_size).float(), label_batch.view(-1, output_size).float())\n",
    "        \"\"\"Cross Entropy\"\"\"\n",
    "        loss = loss_func(output.view(model_output_shape).float(), label_batch.view(-1).long())\n",
    "        \n",
    "        \n",
    "        if mode == \"train\":\n",
    "            #print(\"epoch: {}, batch: {}, loss: {}\".format(epoch, batch_nr, loss.item()))\n",
    "            #print(\"Performing backprop ...\")\n",
    "            #log_file.write(\"epoch: {}, batch: {}, loss: {}\\n\".format(epoch, batch_nr, loss.item()))\n",
    "            #log_file.write(\"Performing backprop ...\\n\")\n",
    "            loss.backward()\n",
    "    \n",
    "            #print(\"Adjusting weights ...\")\n",
    "            #log_file.write(\"Adjusting weights ...\\n\")\n",
    "            optimizer.step()\n",
    "    \n",
    "        return loss, output\n",
    "\n",
    "\"\"\"\n",
    "function for calculating neuron activation layer sizes.\n",
    "needed for torch_net_class (has been copied there)\n",
    "\"\"\"\n",
    "    \n",
    "def calc_layer_sizes(input_shape, net_struct):\n",
    "    layer_sizes = [input_shape]\n",
    "    \n",
    "    for i in range(len(net_struct)):\n",
    "        \n",
    "        new_layer_size = []\n",
    "        if net_struct[i][\"type\"] == nn.Linear:\n",
    "            #print(net_struct[i][\"type\"])\n",
    "            new_layer_size = net_struct[i][\"layer_pars\"][\"out_features\"]\n",
    "            \n",
    "        elif net_struct[i][\"type\"] == nn.Conv2d:\n",
    "            kernel_shape = net_struct[i][\"layer_pars\"][\"kernel_size\"]\n",
    "            stride = net_struct[i][\"layer_pars\"][\"stride\"]\n",
    "            \n",
    "            new_layer_size = []\n",
    "            #print(\"layer \" + str(i))\n",
    "            for d in range(len(kernel_shape)):\n",
    "                prev_layer_l = int(layer_sizes[-1][d+1])\n",
    "                kernel_l = int(kernel_shape[d])\n",
    "                new_layer_size.append( (prev_layer_l - kernel_l)//stride + 1 )\n",
    "            new_layer_size = [net_struct[i][\"layer_pars\"][\"out_channels\"]] + new_layer_size\n",
    "              \n",
    "        elif net_struct[i][\"type\"] == nn.MaxPool2d:\n",
    "            kernel_shape = net_struct[i][\"layer_pars\"][\"kernel_size\"]\n",
    "            stride = net_struct[i][\"layer_pars\"][\"stride\"]\n",
    "            \n",
    "            new_layer_size = []\n",
    "            for d in range(len(kernel_shape)):\n",
    "                prev_layer_l = int(layer_sizes[-1][d+1])\n",
    "                kernel_l = int(kernel_shape[d])\n",
    "                new_layer_size.append(int( (prev_layer_l - kernel_l) + 1 )//stride)\n",
    "            \n",
    "            #new_layer_size = [(layer_sizes[-1][d+1] - kernel_shape[d])/stride + 1 for d in range(len(kernel_shape))]\n",
    "            \n",
    "            prev_channels = layer_sizes[-1][0]\n",
    "            new_layer_size = [prev_channels] + new_layer_size\n",
    "        \n",
    "        elif net_struct[i][\"type\"] == nn.BatchNorm1d or net_struct[i][\"type\"] == nn.Dropout or net_struct[i][\"type\"] == nn.Softmax:\n",
    "                new_layer_size = layer_sizes[-1]\n",
    "        \n",
    "        layer_sizes.append(new_layer_size)\n",
    "    \n",
    "    return layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_image_folder = \"mnist\"\n",
    "mnist_image_names = os.listdir(mnist_image_folder)\n",
    "mnist_image_paths = glob.glob(\"mnist/*\")\n",
    "#mnist_image_paths = []\n",
    "#for mnist_image_name in mnist_image_names:\n",
    "#    mnist_image_paths.append(mnist_image_folder + \"/\" + mnist_image_name)\n",
    "#print(mnist_image_paths)\n",
    "image_size = [1,28,28]\n",
    "label_path_csv = \"mnist_labels.csv\"\n",
    "dataset = dataset_class_gsimage.image_dataset(mnist_image_folder, mnist_image_paths, image_size, label_path_csv)\n",
    "dataset.label_df.head()\n",
    "target_attributes = [\"number\"]\n",
    "output_attributes = [str(i) for i in range(0,10)]\n",
    "pred_attributes = [str(i) for i in range(np.prod(image_size))]\n",
    "#dataset.set_label_names(target_attributes)\n",
    "dataset.label_names = target_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset.get_image(50)[0].reshape([28,28]))\n",
    "print(dataset.get_image(50)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 28, 28], [32, 26, 26], [32, 13, 13], [64, 11, 11], [64, 5, 5], [64, 3, 3], 64, 64, 64, 10]\n",
      "size of train set :8000\n",
      "size of val set :2000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HYPERPARAMETERS\n",
    "\"\"\"\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "val_epochs = [2,16,32,48,64,80]\n",
    "val_epochs = [2]\n",
    "save_state_epochs = [100]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Manually set network structure\"\"\"\n",
    "\"\"\"\n",
    "    This list can be loaded into the constructor of the Net neural network class, to automatically generate the network structure\n",
    "    type = pointer to the layer function'\n",
    "    layer_pars = parameters which must be given to the layer function in order to initialize it\n",
    "    act_func = activation function to be applied directly after feeding to the corresponding layer\n",
    "    dropout = certain neurons cna be dropped out if specified\n",
    "\"\"\"\n",
    "\n",
    "fixed_net_struct = []\n",
    "image_size = dataset.get_image_size()\n",
    "input_size = image_size\n",
    "target_size = len(target_attributes)\n",
    "output_size = target_size\n",
    "output_size = len(output_attributes)\n",
    "\n",
    "#[ [[in_channels, out_channels],[kernel_size], ...]\n",
    "kernel_pars = [ [[input_size[0],32],[3,3]], [[32,32],[2,2]], [[32,64],[3,3]], [[64,64],[2,2]], [[64,64],[3,3]] ]\n",
    "act_func = torch.relu\n",
    "\n",
    "for i, kernel_par in enumerate(kernel_pars):\n",
    "    if i%2 == 0:\n",
    "        layer_type = nn.Conv2d\n",
    "        fixed_net_struct.append( {\"type\": layer_type, \"layer_pars\": {\"in_channels\": kernel_par[0][0], \"out_channels\": kernel_par[0][1], \"kernel_size\": kernel_par[1], \"stride\": 1,  \"bias\": True}} )\n",
    "    else:\n",
    "        layer_type = nn.MaxPool2d\n",
    "        fixed_net_struct.append( {\"type\": layer_type, \"layer_pars\": {\"kernel_size\": kernel_par[1], \"stride\": kernel_par[1][1]}} )\n",
    "    \n",
    "    #fixed_net_struct.append( {\"type\": layer_type, \"layer_pars\": {\"in_channels\": kernel_par[0][0], \"out_channels\": kernel_par[0][1], \"kernel_size\": kernel_par[1], \"bias\": True}} )\n",
    "\n",
    "conv_sizes = calc_layer_sizes(input_size, fixed_net_struct)\n",
    "fc_input_size = np.product(conv_sizes[-1])\n",
    "\n",
    "fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": fc_input_size, \"out_features\": 64}, \"bias\": True, \"act_func\": act_func} )\n",
    "fixed_net_struct.append( {\"type\": nn.BatchNorm1d, \"layer_pars\": {\"num_features\": 64}} )\n",
    "fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": 64, \"out_features\": 64}, \"bias\": True, \"act_func\": act_func} )\n",
    "fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": 64, \"out_features\": output_size}, \"bias\": True, \"act_func\": act_func} )\n",
    "\n",
    "conv_sizes = calc_layer_sizes(input_size, fixed_net_struct)\n",
    "print(conv_sizes)\n",
    "\n",
    "#print(fixed_net_struct)\n",
    "\n",
    "\"\"\"If required create list of parameters manually\"\"\"\n",
    "\n",
    "parameter_option = {}\n",
    "parameter_option[\"task\"] = \"classification\"\n",
    "parameter_option[\"loss_func\"] = nn.CrossEntropyLoss\n",
    "parameter_option[\"optimizer\"] = optim.Adam\n",
    "parameter_option[\"batch_size\"] = 10 \n",
    "parameter_option[\"lr\"] = 0.001\n",
    "parameter_option[\"net_struct\"] = fixed_net_struct\n",
    "\n",
    "parameter_option[\"val\"] = \"holdout\"\n",
    "parameter_option[\"split\"] = {\"train\" : 0.8, \"val\" : 0.2, \"test\" : 0.0}\n",
    "#parameter_option[\"val\"] = \"k_fold\"\n",
    "#parameter_option[\"ksplits\"] = 5\n",
    "\n",
    "hyper_parameters = parameter_option\n",
    "\n",
    "print(\"size of train set :{}\".format(int(parameter_option[\"split\"][\"train\"]*dataset.get_length())))\n",
    "print(\"size of val set :{}\".format(int(parameter_option[\"split\"][\"val\"]*dataset.get_length())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Adding {'type': <class 'torch.nn.modules.conv.Conv2d'>, 'layer_pars': {'in_channels': 1, 'out_channels': 32, 'kernel_size': [3, 3], 'stride': 1, 'bias': True}}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.pooling.MaxPool2d'>, 'layer_pars': {'kernel_size': [2, 2], 'stride': 2}}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.conv.Conv2d'>, 'layer_pars': {'in_channels': 32, 'out_channels': 64, 'kernel_size': [3, 3], 'stride': 1, 'bias': True}}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.pooling.MaxPool2d'>, 'layer_pars': {'kernel_size': [2, 2], 'stride': 2}}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.conv.Conv2d'>, 'layer_pars': {'in_channels': 64, 'out_channels': 64, 'kernel_size': [3, 3], 'stride': 1, 'bias': True}}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.linear.Linear'>, 'layer_pars': {'in_features': 576, 'out_features': 64}, 'bias': True, 'act_func': <built-in method relu of type object at 0x7f2935352be0>}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.batchnorm.BatchNorm1d'>, 'layer_pars': {'num_features': 64}}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.linear.Linear'>, 'layer_pars': {'in_features': 64, 'out_features': 64}, 'bias': True, 'act_func': <built-in method relu of type object at 0x7f2935352be0>}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.linear.Linear'>, 'layer_pars': {'in_features': 64, 'out_features': 10}, 'bias': True, 'act_func': <built-in method relu of type object at 0x7f2935352be0>}\n",
      "\n",
      "Conv2d(1, 32, kernel_size=[3, 3], stride=(1, 1))\n",
      "MaxPool2d(kernel_size=[2, 2], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(32, 64, kernel_size=[3, 3], stride=(1, 1))\n",
      "MaxPool2d(kernel_size=[2, 2], stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1))\n",
      "Linear(in_features=576, out_features=64, bias=True)\n",
      "BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Linear(in_features=64, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=10, bias=True)\n",
      "mean epoch 0 loss: 0.6637281630490907\n",
      "mean epoch 1 loss: 0.21887661878834477\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'functools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9bfeb01be007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;31m#val_label_df = pd.DataFrame(np.hstack(val_label))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0mval_pred_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miconcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0mval_label_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miconcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'functools' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "All errors from each validation epoch will be saved\n",
    "this list contains them\n",
    "Saving them in memory is not always viable, which is why they are also saved on the hard drive\n",
    "\"\"\"\n",
    "#second is fold\n",
    "#third is epoch\n",
    "#fourth is prediction or label \n",
    "model_errors = []\n",
    "\"\"\"\n",
    "All errors from each validation epoch will be saved as a file\n",
    "this list contains the path to these files\n",
    "\"\"\"\n",
    "#second is fold\n",
    "#third is epoch\n",
    "#fourth is prediction or label \n",
    "model_errors_path_list = []\n",
    "\n",
    "\"\"\"\n",
    "The average training loss for each epoch is recorded here\n",
    "\"\"\"\n",
    "#second is fold\n",
    "loss_curves = []\n",
    "loss_path_list = []\n",
    "\n",
    "\"\"\"\n",
    "States of the neural network are saved as a file\n",
    "filename is part of this list\n",
    "\"\"\"\n",
    "#second is fold\n",
    "#third is epoch\n",
    "saved_states_file_path_list = []\n",
    "\n",
    "\"\"\"\n",
    "Set/copy the hyper_parameters\n",
    "\"\"\"\n",
    "epochs = max(val_epochs)\n",
    "#input_size = len(pred_attributes)\n",
    "#target_size = len(target_attributes)\n",
    "#output_size = len(output_attributes)\n",
    "\n",
    "lr=hyper_parameters[\"lr\"]\n",
    "batch_size = hyper_parameters[\"batch_size\"]\n",
    "loss_func = hyper_parameters[\"loss_func\"]()\n",
    "\n",
    "net_struct = hyper_parameters[\"net_struct\"]\n",
    "\n",
    "\"\"\"Choose between holdout validation and k-fold cross validation\"\"\"\n",
    "if hyper_parameters[\"val\"] == \"holdout\":\n",
    "    all_indices = list(range(dataset.get_length()))\n",
    "    indices = [None, None]\n",
    "    split_ratio = hyper_parameters[\"split\"]\n",
    "    indices[0], indices[1] = train_test_split(all_indices, test_size=split_ratio[\"val\"], shuffle=True, random_state=random_seed)\n",
    "    indices = [indices]\n",
    "elif hyper_parameters[\"val\"] == \"k_fold\":\n",
    "    \"\"\"NOT WORKING ATM\"\"\"\n",
    "    n_splits = hyper_parameters[\"k_splits\"]\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    indices = kf.split(dataset.df)\n",
    "\n",
    "    #if dataset is split into train test and val, use only train and val for KFold\n",
    "    #split_indices[\"train_val\"] = split_indices[\"train\"] + split_indices[\"val\"]\n",
    "    #indices = kf.split(dataset.df.iloc[split_indices[\"train_val\"]])\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "\n",
    "fold_model_errors = []\n",
    "fold_model_errors_path_list = []\n",
    "fold_saved_states_path_list = []\n",
    "\n",
    "n_split = 0\n",
    "\"\"\"iterate through all folds (1 for holdout, k for kfold)\"\"\"\n",
    "for fold_indices in indices:\n",
    "\n",
    "    train_indices = fold_indices[0]\n",
    "    val_indices = fold_indices[1]\n",
    "\n",
    "    fold_loss_curve = []\n",
    "    print(\"fold {}\".format(n_split))\n",
    "    fold_dir = \"fold_{}\".format(str(n_split))\n",
    "    try:\n",
    "        os.makedirs(fold_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    \"\"\"TRANSFER LEARNING TRIAL START\"\"\"\n",
    "    \"\"\"\n",
    "    custom_net = models.vgg16(pretrained=True)\n",
    "    for param in custom_net.parameters():\n",
    "        param.requires_autograd = False\n",
    "    n_inputs = 4096\n",
    "    my_classifier = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 256), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.1),\n",
    "                      nn.Linear(256, output_size),                   \n",
    "                      nn.Softmax(dim=1))\n",
    "    \n",
    "    custom_net.classifier[6] = my_classifier\n",
    "    \n",
    "    net = custom_net\n",
    "    \"\"\"\n",
    "    \"\"\"TRANSFER LEARNING TRIAL STOP\"\"\"\n",
    "    \n",
    "    #initialize network and move to GPU\n",
    "    \n",
    "    net = torch_net_class.Net(net_struct, dataset.get_image_size())\n",
    "    \n",
    "    net.init_weights(torch.nn.init.xavier_normal_)\n",
    "    net.set_batch_size(batch_size)\n",
    "    #net.cuda()\n",
    "    net.show_layers()\n",
    "    #train_log_file.write(str(net.get_net_struct()))\n",
    "    \n",
    "    net.to(device)\n",
    "    \n",
    "    \n",
    "\n",
    "    net_parameters = net.parameters()\n",
    "    optimizer = hyper_parameters[\"optimizer\"](net_parameters, lr=lr)\n",
    "\n",
    "    #create training log\n",
    "    train_log_file_name = fold_dir +\"/train_log.txt\"\n",
    "    train_log_file = open(train_log_file_name, \"w\")\n",
    "    #train_log_file.write( \"Training log fold {} :\\n\".format(str(n_split)) )\n",
    "    \n",
    "    \n",
    "    \"\"\"split training in train and val and load data\"\"\"\n",
    "    train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n",
    "    #test_sampler = torch.utils.data.sampler.SubsetRandomSampler(test_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "    #val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "    #test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "\n",
    "    train_state_dir = fold_dir + \"/net_states\"\n",
    "    try:\n",
    "        os.makedirs(train_state_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    train_loss_curve = []\n",
    "    val_loss_curve = []\n",
    "\n",
    "    fold_epoch_model_errors = []\n",
    "    fold_epoch_model_errors_path_list = []\n",
    "    fold_epoch_saved_states_path_list = []\n",
    "    for epoch in range(0, epochs):\n",
    "\n",
    "        batch_nr = 0\n",
    "        epoch_loss = 0.\n",
    "\n",
    "        \"\"\"Actual training step\"\"\"\n",
    "        for train_mini_batch in train_loader:\n",
    "            batch_nr += 1\n",
    "            batch_loss, train_output = step(net, train_mini_batch, batch_size, loss_func, optimizer, epoch, batch_nr, device, train_log_file, mode=\"train\")\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "        \"\"\"Averaging training loss\"\"\"\n",
    "        epoch_loss = epoch_loss/len(train_loader)\n",
    "        train_loss_curve.append(epoch_loss)\n",
    "        fold_loss_curve.append(epoch_loss)\n",
    "\n",
    "        print(\"mean epoch {} loss: {}\".format(epoch, epoch_loss))\n",
    "        #train_log_file.write(\"mean epoch loss: {}\\n\".format(epoch_loss))\n",
    "\n",
    "        epoch_val_loss = 0\n",
    "\n",
    "        \"\"\"save the neural networks state\"\"\"\n",
    "        if (epoch+1) in save_state_epochs or epoch == epochs:\n",
    "            train_state_epoch_file_name = \"state_epoch_{}\".format(epoch)\n",
    "            train_state = {\"epoch\" : epoch, \"state_dict\": net.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "            torch.save(train_state, train_state_dir + \"/\" + train_state_epoch_file_name )\n",
    "            fold_epoch_saved_states_path_list.append(train_state_dir + \"/\" + train_state_epoch_file_name)\n",
    "            print(\"saved model from epoch {}\".format(epoch))\n",
    "            train_log_file.write(\"saved model from epoch {}\\n\".format(epoch))\n",
    "\n",
    "        \"\"\"\n",
    "        Valdation\n",
    "        \"\"\"\n",
    "        #validate for each epoch reached in val_epochs\n",
    "        if (epoch+1) in val_epochs:\n",
    "        #if (epoch) in val_epochs:\n",
    "\n",
    "            val_loss = []\n",
    "            val_pred = []\n",
    "            val_label = []\n",
    "            val_i = 0\n",
    "            for val_mini_batch in val_loader:\n",
    "\n",
    "                feat_batch = val_mini_batch[0]\n",
    "                label_batch = val_mini_batch[1]\n",
    "                val_label.append(label_batch.detach().cpu().numpy())\n",
    "                val_batch_loss, val_output = step(net, val_mini_batch, batch_size, loss_func, optimizer, epoch, batch_nr, device, train_log_file, mode=\"val\")\n",
    "\n",
    "                if hyper_parameters[\"task\"] == \"classification\":\n",
    "                    \"\"\"for a classification task\"\"\"\n",
    "                    class_batch_pred = []\n",
    "                    for val in val_output:\n",
    "                        class_index = val.argmax().detach().cpu()\n",
    "                        class_batch_pred.append(class_index)\n",
    "                    val_pred.append(class_batch_pred)\n",
    "                elif hyper_parameters[\"task\"] == \"regression\":\n",
    "                    \"\"\"for a regression task\"\"\"\n",
    "                    val_pred.append(val_output.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "                val_loss.append(val_batch_loss.item())\n",
    "                #print(val_batch_loss.item())\n",
    "                val_i += 1\n",
    "\n",
    "            \"\"\"SAVE NUMPY ARRAY INSTEAD OF DF\"\"\"\n",
    "            #val_pred_df = pd.DataFrame(np.hstack(val_pred))\n",
    "            #val_label_df = pd.DataFrame(np.hstack(val_label))\n",
    "            \n",
    "            val_pred_df = pd.DataFrame(functools.reduce(operator.iconcat, val_pred, []))\n",
    "            val_label_df = pd.DataFrame(functools.reduce(operator.iconcat, val_label, []))\n",
    "\n",
    "\n",
    "            val_error_df = pd.DataFrame()\n",
    "\n",
    "            val_error_df[\"train_label\"] = val_label_df[0]\n",
    "            val_error_df[\"train_prediction\"] = val_pred_df[0]\n",
    "\n",
    "\n",
    "            fold_epoch_model_errors.append(val_error_df.copy())\n",
    "            fold_epoch_model_pred_path = fold_dir + \"/\" +\"val_epoch_{}_pred\".format(epoch)\n",
    "            fold_epoch_model_labels_path = fold_dir + \"/\" +\"val_epoch_{}_labels\".format(epoch)\n",
    "            val_pred_df.to_pickle(fold_epoch_model_pred_path)\n",
    "            val_label_df.to_pickle(fold_epoch_model_labels_path)\n",
    "            fold_epoch_model_errors_path_list.append([fold_epoch_model_pred_path, fold_epoch_model_labels_path])\n",
    "    \n",
    "    \"\"\"With this line the pred and labels for all validation epochs cna be saved -> space consuming!!!\"\"\"\n",
    "    \"\"\"fold_model_errors.append(fold_epoch_model_errors.copy())\"\"\"\n",
    "    fold_model_errors_path_list.append(fold_epoch_model_errors_path_list)\n",
    "    fold_saved_states_path_list.append(fold_epoch_saved_states_path_list)\n",
    "    loss_curves.append(fold_loss_curve)\n",
    "\n",
    "    n_split += 1\n",
    "\n",
    "    del net\n",
    "    del optimizer\n",
    "    \n",
    "\"\"\"With this line the pred and labels for all validation epochs cna be saved -> space consuming!!!\"\"\"\n",
    "\"\"\"model_errors.append(fold_model_errors.copy())\"\"\"\n",
    "model_errors_path_list.append(fold_model_errors_path_list)\n",
    "saved_states_file_path_list.append(fold_saved_states_path_list)\n",
    "#loss_curves.append(par_loss_curves)\n",
    "\n",
    "\"\"\"Plot training loss curve and save as image\"\"\"\n",
    "train_loss_img_file_name = \"train_loss.png\"\n",
    "x_epochs = range(epochs)\n",
    "for fold_i in range(len(loss_curves)):\n",
    "    #plt.plot(x_epochs, loss_curves[par_i][fold_i])\n",
    "    plt.plot(x_epochs, loss_curves[fold_i])\n",
    "#plt.title()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"training loss\")\n",
    "plt.savefig(train_loss_img_file_name)\n",
    "plt.close()\n",
    "train_loss_txt_file_name = \"train_loss.txt\"\n",
    "np.savetxt(train_loss_txt_file_name, loss_curves)\n",
    "\n",
    "train_log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first index is parameter run\n",
    "#second is fold\n",
    "#third is epoch\n",
    "#model_errors[0][0][0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first index is parameter run\n",
    "#second is fold\n",
    "#third is epoch\n",
    "#fourth is prediction or label\n",
    "test_pickle_pred_df = pd.read_pickle(model_errors_path_list[0][0][-1][0])\n",
    "test_pickle_label_df = pd.read_pickle(model_errors_path_list[0][0][-1][1])\n",
    "test_pickle_label_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pickle_pred_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pickle_label_df.columns = [\"train_label\"]\n",
    "test_pickle_pred_classes = test_pickle_pred_df.max(axis=1)\n",
    "test_pickle_pred_df[\"train_prediction\"] = pd.DataFrame(test_pickle_pred_classes)\n",
    "test_pickle_errors_df = pd.DataFrame()\n",
    "test_pickle_errors_df[\"train_prediction\"] = test_pickle_pred_df[\"train_prediction\"]\n",
    "test_pickle_errors_df[\"train_label\"] = test_pickle_label_df[\"train_label\"]\n",
    "\n",
    "test_pickle_errors_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For classification\n",
    "plot the confusion matrix to evaluate model\n",
    "\"\"\"\n",
    "conf_mat = pd.crosstab(test_pickle_errors_df[\"train_label\"], test_pickle_errors_df[\"train_prediction\"], rownames=[\"Label\"], colnames=[\"Predicted\"], margins=True)\n",
    "print(conf_mat)\n",
    "np_conf_mat = conf_mat.values.copy()\n",
    "print(np_conf_mat)\n",
    "conf_mat_shape = list(np_conf_mat.shape)\n",
    "\n",
    "pad_extend = ((0,0),(0,output_size-conf_mat_shape[1]+1))\n",
    "print(pad_extend)\n",
    "#print(np_conf_mat.shape)\n",
    "diag_indices = [i for i in range(0,output_size)]\n",
    "diag_indices = [diag_indices, diag_indices]\n",
    "np_conf_mat = np.pad(np_conf_mat, pad_extend, mode=\"constant\", constant_values=0)\n",
    "np_conf_mat[:,-1] = np_conf_mat[:,conf_mat_shape[1]-1]\n",
    "np_conf_mat[:,conf_mat_shape[1]-1] = 0.\n",
    "#print(np_conf_mat)\n",
    "print(np_conf_mat[diag_indices].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
