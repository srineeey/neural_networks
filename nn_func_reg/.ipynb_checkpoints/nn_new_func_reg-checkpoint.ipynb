{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import itertools\n",
    "\n",
    "import dataset_class\n",
    "import torch_net_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizing CUDA\n",
      "Utilizing CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Utilizing CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Utilizing CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create train, val, test index list dictionary\n",
    "\"\"\"\n",
    "\n",
    "def create_index_split(dataset_size=10, split_ratio={\"train\":0.0, \"val\":0.0, \"test\":0.1}, shuffle=False, np_random_seed=42):\n",
    "    \n",
    "    ratio_norm = sum(split_ratio.values())\n",
    "    \"\"\"\n",
    "    if ratio_norm is not 1.0:\n",
    "        train_ratio = split_ratio[\"train\"]/ratio_norm\n",
    "        val_ratio = split_ratio[\"val\"]/ratio_norm\n",
    "        test_ratio = split_ratio[\"val\"]/ratio_norm\n",
    "    \"\"\"\n",
    "    \n",
    "    train_ratio = split_ratio[\"train\"]\n",
    "    val_ratio = split_ratio[\"val\"]\n",
    "    test_ratio = split_ratio[\"test\"]\n",
    "    \n",
    "    indices = list(range(dataset_size))\n",
    "    if shuffle is True:\n",
    "        np.random.seed(np_random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    \n",
    "    split_indices = {}\n",
    "    split_indices[\"train\"] = indices[:int(train_ratio*dataset_size)]\n",
    "    split_indices[\"val\"] = indices[int(train_ratio*dataset_size) : int((train_ratio+val_ratio)*dataset_size)]\n",
    "    split_indices[\"test\"] = indices[int((train_ratio+val_ratio)*dataset_size) : int((train_ratio+val_ratio+test_ratio)*dataset_size)]\n",
    "    \n",
    "    #print(split_indices)\n",
    "    return split_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function for training loop\n",
    "\"\"\"\n",
    "                \n",
    "def step(model, input_data, batch_size, loss_func, optimizer, epoch, batch_nr, device, log_file, mode=\"val\"):\n",
    "        #input data splitted into features and labels\n",
    "        feat_batch = input_data[0].to(device)\n",
    "        label_batch = input_data[1].to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        input_size = model.get_input_size()\n",
    "        output_size = model.get_output_size()\n",
    "        \n",
    "        \"\"\"\n",
    "        the peculiar shape (-1, sample_size) is needed, because an entire mini batch is passed on to the network\n",
    "        initially it is not clear how large such a mini batch is\n",
    "        the -1 acts as a placeholder in order to keep the number of processed items in one mini batch flexible\n",
    "        \"\"\"\n",
    "        #print(\"Input {}, batch: {} : {}\".format(epoch, batch_nr, feat_batch))\n",
    "        #log_file.write(\"Input {}, batch: {} : {}\\n\".format(epoch, batch_nr, feat_batch))\n",
    "        \n",
    "        #print(\"Reshaping to {}\".format( feat_batch.view(-1, input_size).double().size() ))\n",
    "        output = model(feat_batch.view(-1, input_size).float())\n",
    "        output = output.to(device)\n",
    "    \n",
    "        #print(\"Output {}, batch: {} : {}\".format(epoch, batch_nr, output))\n",
    "        #print(\"Label {}, batch: {} : {}\".format(epoch, batch_nr, label_batch))\n",
    "        #log_file.write(\"Output {}, batch: {} : {}\\n\".format(epoch, batch_nr, output))\n",
    "        \n",
    "        #print(\"Input shape {}\".format(feat_batch.size()))\n",
    "        #print(\"Label shape {}\".format(label_batch.size()))\n",
    "        #print(\"Output shape {}\".format(output.size()))\n",
    "    \n",
    "        #print(\"Feeding forward epoch: {}, batch: {}\".format(epoch, batch_nr))\n",
    "        #log_file.write(\"Feeding forward epoch: {}, batch: {}\\n\".format(epoch, batch_nr))\n",
    "    \n",
    "        #print(\"Calculating \" + mode + \" loss epoch: {}, batch: {}\".format(epoch, batch_nr))\n",
    "        #log_file.write(\"Calculating \" + mode + \" loss epoch: {}, batch: {}\\n\".format(epoch, batch_nr))\n",
    "        loss = loss_func(output.view(-1, output_size).float(), label_batch.view(-1, output_size).float())\n",
    "    \n",
    "        \n",
    "        \n",
    "        if mode == \"train\":\n",
    "            #print(\"epoch: {}, batch: {}, loss: {}\".format(epoch, batch_nr, loss.item()))\n",
    "            #print(\"Performing backprop ...\")\n",
    "            #log_file.write(\"epoch: {}, batch: {}, loss: {}\\n\".format(epoch, batch_nr, loss.item()))\n",
    "            #log_file.write(\"Performing backprop ...\\n\")\n",
    "            loss.backward()\n",
    "    \n",
    "            #print(\"Adjusting weights ...\")\n",
    "            #log_file.write(\"Adjusting weights ...\\n\")\n",
    "            optimizer.step()\n",
    "    \n",
    "        return loss, output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95892427  0.96164864  0.96428131 ... -0.96682201 -0.96428131\n",
      " -0.96164864]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data preparation\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"#choose interval of function as well as discrete step size\"\"\"\n",
    "x_min = -5.\n",
    "x_max = 5.\n",
    "x_num =  2**10\n",
    "x_delta = ( x_max - x_min ) / x_num\n",
    "\n",
    "train_xs = np.arange(x_min, x_max, x_delta)\n",
    "\n",
    "id_list = range(len(train_xs))\n",
    "\n",
    "func_dict = {}\n",
    "func_dict[\"exp\"] =  np.exp\n",
    "func_dict[\"nexp\"] =  lambda x: np.exp(-x)\n",
    "func_dict[\"gauss\"] = lambda x: np.exp(-x*x)\n",
    "func_dict[\"x2\"] =  lambda x: x*x\n",
    "func_dict[\"x3\"] =  lambda x: x*x*x\n",
    "func_dict[\"x3pos\"] =  lambda x: x*x*x/8. + 2\n",
    "func_dict[\"cauchy\"] =  lambda x: 1./(1.+x*x)\n",
    "func_dict[\"sin\"] =  np.sin\n",
    "func_dict[\"cos\"] =  np.cos\n",
    "func_dict[\"cbrt\"] =  np.cbrt\n",
    "func_dict[\"abs\"] =  np.abs\n",
    "func_dict[\"floor\"] =  np.floor\n",
    "\n",
    "\"\"\"\n",
    "choose function to approximate\n",
    "generate dataset class\n",
    "\"\"\"\n",
    "\n",
    "func_name = \"sin\"\n",
    "func = func_dict[func_name]\n",
    "\n",
    "func_array = np.zeros( shape=(2, len(train_xs)) )\n",
    "func_array[0] = train_xs\n",
    "func_array[1] = np.array([func(arg) for arg in func_array[0]])\n",
    "print(func_array[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_df = pd.DataFrame(func_array.T, columns=[\"arg\", \"func\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arg']\n",
      "['func']\n",
      "['Unnamed: 0', 'arg', 'func']\n"
     ]
    }
   ],
   "source": [
    "func_df.to_csv(\"func_data.csv\")\n",
    "dataset = dataset_class.dataset(\"func_data.csv\")\n",
    "\n",
    "selected_pred_attributes = [\"arg\"]\n",
    "target_attributes = [\"func\"]\n",
    "print(selected_pred_attributes)\n",
    "print(target_attributes)\n",
    "\n",
    "print(list(dataset.df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arg']\n",
      "['func']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-0.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.888161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-2.502441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-0.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2.492676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>4.990234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               arg\n",
       "count  1024.000000\n",
       "mean     -0.004883\n",
       "std       2.888161\n",
       "min      -5.000000\n",
       "25%      -2.502441\n",
       "50%      -0.004883\n",
       "75%       2.492676\n",
       "max       4.990234"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_attributes = selected_pred_attributes\n",
    "\n",
    "dataset.set_pred_attributes(pred_attributes)\n",
    "dataset.set_target_attribute(target_attributes)\n",
    "print(pred_attributes)\n",
    "print(target_attributes)\n",
    "\n",
    "dataset.df[pred_attributes].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.000936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.726440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-0.738479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.001469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.740616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              func\n",
       "count  1024.000000\n",
       "mean      0.000936\n",
       "std       0.726440\n",
       "min      -0.999999\n",
       "25%      -0.738479\n",
       "50%       0.001469\n",
       "75%       0.740616\n",
       "max       0.999999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df[target_attributes].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>arg</th>\n",
       "      <th>func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.958924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.990234</td>\n",
       "      <td>0.961649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.980469</td>\n",
       "      <td>0.964281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.970703</td>\n",
       "      <td>0.966822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.960938</td>\n",
       "      <td>0.969271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.951172</td>\n",
       "      <td>0.971627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.941406</td>\n",
       "      <td>0.973890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.931641</td>\n",
       "      <td>0.976060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>-4.921875</td>\n",
       "      <td>0.978138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>-4.912109</td>\n",
       "      <td>0.980122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       arg      func\n",
       "0           0 -5.000000  0.958924\n",
       "1           1 -4.990234  0.961649\n",
       "2           2 -4.980469  0.964281\n",
       "3           3 -4.970703  0.966822\n",
       "4           4 -4.960938  0.969271\n",
       "5           5 -4.951172  0.971627\n",
       "6           6 -4.941406  0.973890\n",
       "7           7 -4.931641  0.976060\n",
       "8           8 -4.921875  0.978138\n",
       "9           9 -4.912109  0.980122"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HYPERPARAMETERS\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\"\"\"\n",
    "parameter_options = {}\n",
    "parameter_options[\"act_func\"] = [torch.relu, torch.sigmoid, , torch.tanh]\n",
    "parameter_options[\"loss_func\"] = [torch.sigmoid, torch.relu, torch.tanh]\n",
    "parameter_options[\"dropout\"] = [nn.Dropout, None]\n",
    "parameter_options[\"optimizer\"] = [optim.Adam, optim.SGD]\n",
    "\"\"\"\n",
    "\n",
    "parameter_options = {}\n",
    "parameter_options[\"batch_size\"] = [32]\n",
    "parameter_options[\"lr\"] = [0.001]\n",
    "parameter_options[\"k_fold\"] = [1]\n",
    "parameter_options[\"hidden_layers\"] = [1,2,3,4]\n",
    "parameter_options[\"layer_width\"] = [1,2,3,4]\n",
    "parameter_options[\"act_func\"] = [torch.sigmoid]\n",
    "parameter_options[\"loss_func\"] = [F.mse_loss]\n",
    "parameter_options[\"dropout\"] = [None]\n",
    "parameter_options[\"p_dropout\"] = [0.4]\n",
    "parameter_options[\"bias\"] = [True]\n",
    "parameter_options[\"optimizer\"] = [optim.Adam]\n",
    "\n",
    "\"\"\"At which epochs should validation be performed?\"\"\"\n",
    "\"\"\"The maximum number of training epochs is automatically set to max(val_epochs)\"\"\"\n",
    "#val_epochs = [1, 2, 4, 6, 10, 16]\n",
    "val_epochs = range(0,1000,5)\n",
    "\n",
    "\"\"\"Create list of all parameteroptions -> cartesian product!\"\"\"\n",
    "def cart_product(dict_options):\n",
    "    return ( dict(zip(dict_options.keys(), values)) for values in itertools.product(*dict_options.values()) )\n",
    "\n",
    "parameter_selector = cart_product(parameter_options)\n",
    "\n",
    "\n",
    "\"\"\"If required create list of paramters randomly\"\"\"\n",
    "\n",
    "parameter_selector = []\n",
    "parameter_option = {\"batch_size\":16,\"lr\":0.0001, \"k_fold\":1,\"hidden_layers\":1,\"layer_width\":4,\"act_func\":torch.sigmoid,\"loss_func\":F.mse_loss,\"dropout\":None,\"p_dropout\":0.4,\"bias\":True,\"optimizer\":optim.Adam}\n",
    "parameter_option[\"hidden_layers\"] = 1\n",
    "parameter_option[\"layer_width\"] = 100\n",
    "parameter_options[\"act_func\"] = [torch.relu]\n",
    "parameter_selector.append(parameter_option)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "{'in_features': 1, 'out_features': 100}\n",
      "{'in_features': 100, 'out_features': 1}\n",
      "Linear(in_features=1, out_features=100, bias=True)\n",
      "Linear(in_features=100, out_features=1, bias=True)\n",
      "mean epoch loss: 0.750423710876041\n",
      "saved model from epoch 0\n",
      "mean epoch loss: 0.6186606579356724\n",
      "mean epoch loss: 0.560833485921224\n",
      "mean epoch loss: 0.5406116121345096\n",
      "saved model from epoch 3\n",
      "mean epoch loss: 0.5294057501686944\n",
      "mean epoch loss: 0.5249204006459978\n",
      "mean epoch loss: 0.5211884604560004\n",
      "saved model from epoch 6\n",
      "mean epoch loss: 0.5177962958812714\n",
      "mean epoch loss: 0.5134081284205119\n",
      "mean epoch loss: 0.5122821072737376\n",
      "saved model from epoch 9\n",
      "mean epoch loss: 0.510396444135242\n",
      "mean epoch loss: 0.5070579012235006\n",
      "mean epoch loss: 0.5052998695108626\n",
      "saved model from epoch 12\n",
      "mean epoch loss: 0.5024843560324774\n",
      "mean epoch loss: 0.5010005036989847\n",
      "mean epoch loss: 0.4980964203675588\n",
      "saved model from epoch 15\n",
      "mean epoch loss: 0.496190153559049\n",
      "mean epoch loss: 0.4929025729497274\n",
      "mean epoch loss: 0.48837338586648305\n",
      "saved model from epoch 18\n",
      "mean epoch loss: 0.4880376815795898\n",
      "mean epoch loss: 0.48535969356695813\n",
      "mean epoch loss: 0.48257074223624336\n",
      "saved model from epoch 21\n",
      "mean epoch loss: 0.47922759387228225\n",
      "mean epoch loss: 0.47760546737247045\n",
      "mean epoch loss: 0.4735309031274584\n",
      "saved model from epoch 24\n",
      "mean epoch loss: 0.47245910167694094\n",
      "mean epoch loss: 0.46889779832628037\n",
      "mean epoch loss: 0.46688778864012825\n",
      "saved model from epoch 27\n",
      "mean epoch loss: 0.46370583441522384\n",
      "mean epoch loss: 0.4610019425551097\n",
      "mean epoch loss: 0.4581496232085758\n",
      "saved model from epoch 30\n",
      "mean epoch loss: 0.45555870963467493\n",
      "mean epoch loss: 0.45269092387623255\n",
      "mean epoch loss: 0.450651748975118\n",
      "saved model from epoch 33\n",
      "mean epoch loss: 0.4485813028282589\n",
      "mean epoch loss: 0.4450549132294125\n",
      "mean epoch loss: 0.441968658235338\n",
      "saved model from epoch 36\n",
      "mean epoch loss: 0.43874270485507116\n",
      "mean epoch loss: 0.4359499646557702\n",
      "mean epoch loss: 0.4336200382974413\n",
      "saved model from epoch 39\n",
      "mean epoch loss: 0.42969609962569344\n",
      "mean epoch loss: 0.4276102642218272\n",
      "mean epoch loss: 0.4242345498667823\n",
      "saved model from epoch 42\n",
      "mean epoch loss: 0.4213963270187378\n",
      "mean epoch loss: 0.4195717453956604\n",
      "mean epoch loss: 0.41615604956944785\n",
      "saved model from epoch 45\n",
      "mean epoch loss: 0.4132675114605162\n",
      "mean epoch loss: 0.40976964367760554\n",
      "mean epoch loss: 0.4073117170068953\n",
      "saved model from epoch 48\n",
      "mean epoch loss: 0.4039205961757236\n",
      "mean epoch loss: 0.40094423095385234\n",
      "mean epoch loss: 0.39780718915992314\n",
      "saved model from epoch 51\n",
      "mean epoch loss: 0.39548079040315415\n",
      "mean epoch loss: 0.3919211917453342\n",
      "mean epoch loss: 0.38906360997094047\n",
      "saved model from epoch 54\n",
      "mean epoch loss: 0.3867111043797599\n",
      "mean epoch loss: 0.3816918396287494\n",
      "mean epoch loss: 0.37957386175791424\n",
      "saved model from epoch 57\n",
      "mean epoch loss: 0.37693192031648426\n",
      "mean epoch loss: 0.37368980083200665\n",
      "mean epoch loss: 0.3704196876949734\n",
      "saved model from epoch 60\n",
      "mean epoch loss: 0.3672267152203454\n",
      "mean epoch loss: 0.36420862045552993\n",
      "mean epoch loss: 0.36179457273748183\n",
      "saved model from epoch 63\n",
      "mean epoch loss: 0.3579670555061764\n",
      "mean epoch loss: 0.3551467627286911\n",
      "mean epoch loss: 0.3517104208469391\n",
      "saved model from epoch 66\n",
      "mean epoch loss: 0.3485395444764031\n",
      "mean epoch loss: 0.3447260591718886\n",
      "mean epoch loss: 0.34194133480389916\n",
      "saved model from epoch 69\n",
      "mean epoch loss: 0.33937218851513334\n",
      "mean epoch loss: 0.3349040299654007\n",
      "mean epoch loss: 0.33206641872723897\n",
      "saved model from epoch 72\n",
      "mean epoch loss: 0.3295011901193195\n",
      "mean epoch loss: 0.32566452556186254\n",
      "mean epoch loss: 0.32320416371027627\n",
      "saved model from epoch 75\n",
      "mean epoch loss: 0.3198692841662301\n",
      "mean epoch loss: 0.31633205546273124\n",
      "mean epoch loss: 0.3128956076171663\n",
      "saved model from epoch 78\n",
      "mean epoch loss: 0.3105499681499269\n",
      "mean epoch loss: 0.3062087992827098\n",
      "mean epoch loss: 0.3027569403251012\n",
      "saved model from epoch 81\n",
      "mean epoch loss: 0.29966454439693024\n",
      "mean epoch loss: 0.2964270012246238\n",
      "mean epoch loss: 0.29367115795612336\n",
      "saved model from epoch 84\n",
      "mean epoch loss: 0.2897126472658581\n",
      "mean epoch loss: 0.28657960328790877\n",
      "mean epoch loss: 0.28399291071626875\n",
      "saved model from epoch 87\n",
      "mean epoch loss: 0.2798987027671602\n",
      "mean epoch loss: 0.2770737843381034\n",
      "mean epoch loss: 0.27362157702445983\n",
      "saved model from epoch 90\n",
      "mean epoch loss: 0.27026580770810443\n",
      "mean epoch loss: 0.267625629901886\n",
      "mean epoch loss: 0.26388626032405427\n",
      "saved model from epoch 93\n",
      "mean epoch loss: 0.2603999849822786\n",
      "mean epoch loss: 0.2568858795695835\n",
      "mean epoch loss: 0.2534912990199195\n",
      "saved model from epoch 96\n",
      "mean epoch loss: 0.2507718635929955\n",
      "mean epoch loss: 0.24801133506827885\n",
      "mean epoch loss: 0.24423754413922627\n",
      "saved model from epoch 99\n",
      "mean epoch loss: 0.24091303712791867\n",
      "mean epoch loss: 0.23752476937241024\n",
      "mean epoch loss: 0.23447201947371166\n",
      "saved model from epoch 102\n",
      "mean epoch loss: 0.2311693830622567\n",
      "mean epoch loss: 0.22882438798745472\n",
      "mean epoch loss: 0.2246944593058692\n",
      "saved model from epoch 105\n",
      "mean epoch loss: 0.22202980717023213\n",
      "mean epoch loss: 0.2187160485320621\n",
      "mean epoch loss: 0.21575081116623349\n",
      "saved model from epoch 108\n",
      "mean epoch loss: 0.21251864499515957\n",
      "mean epoch loss: 0.20977793435255687\n",
      "mean epoch loss: 0.2062970783975389\n",
      "saved model from epoch 111\n",
      "mean epoch loss: 0.20330860316753388\n",
      "mean epoch loss: 0.20009375380145178\n",
      "mean epoch loss: 0.1974742035071055\n",
      "saved model from epoch 114\n",
      "mean epoch loss: 0.19450006898906497\n",
      "mean epoch loss: 0.19141357176833682\n",
      "mean epoch loss: 0.18837787326839234\n",
      "saved model from epoch 117\n",
      "mean epoch loss: 0.1850925202171008\n",
      "mean epoch loss: 0.1824083631237348\n",
      "mean epoch loss: 0.17958364023102655\n",
      "saved model from epoch 120\n",
      "mean epoch loss: 0.17655593355496724\n",
      "mean epoch loss: 0.17381155490875244\n",
      "mean epoch loss: 0.17082007163100774\n",
      "saved model from epoch 123\n",
      "mean epoch loss: 0.16831719047493404\n",
      "mean epoch loss: 0.16523558050394058\n",
      "mean epoch loss: 0.16201309859752655\n",
      "saved model from epoch 126\n",
      "mean epoch loss: 0.15933544089396795\n",
      "mean epoch loss: 0.15685207115279304\n",
      "mean epoch loss: 0.1538423337870174\n",
      "saved model from epoch 129\n",
      "mean epoch loss: 0.15140143086512883\n",
      "mean epoch loss: 0.14826644112666448\n",
      "mean epoch loss: 0.14603996409310235\n",
      "saved model from epoch 132\n",
      "mean epoch loss: 0.14311118572950363\n",
      "mean epoch loss: 0.1406011669172181\n",
      "mean epoch loss: 0.13835975014501148\n",
      "saved model from epoch 135\n",
      "mean epoch loss: 0.1355573602848583\n",
      "mean epoch loss: 0.1328968917330106\n",
      "mean epoch loss: 0.13027145796351963\n",
      "saved model from epoch 138\n",
      "mean epoch loss: 0.12779179314772288\n",
      "mean epoch loss: 0.12518136815892325\n",
      "mean epoch loss: 0.1228045834435357\n",
      "saved model from epoch 141\n",
      "mean epoch loss: 0.12046525213453504\n",
      "mean epoch loss: 0.11790070045325492\n",
      "mean epoch loss: 0.11542418301105499\n",
      "saved model from epoch 144\n",
      "mean epoch loss: 0.11327426301108466\n",
      "mean epoch loss: 0.11108978771501117\n",
      "mean epoch loss: 0.10855340758959452\n",
      "saved model from epoch 147\n",
      "mean epoch loss: 0.10614265534612867\n",
      "mean epoch loss: 0.10410861869653067\n",
      "mean epoch loss: 0.10196273508999083\n",
      "saved model from epoch 150\n",
      "mean epoch loss: 0.09980266640583674\n",
      "mean epoch loss: 0.0972995308538278\n",
      "mean epoch loss: 0.0952237439652284\n",
      "saved model from epoch 153\n",
      "mean epoch loss: 0.09301501148276858\n",
      "mean epoch loss: 0.09102640797694524\n",
      "mean epoch loss: 0.08909866337974866\n",
      "saved model from epoch 156\n",
      "mean epoch loss: 0.08701187753015094\n",
      "mean epoch loss: 0.08520323178834385\n",
      "mean epoch loss: 0.08299443845947584\n",
      "saved model from epoch 159\n",
      "mean epoch loss: 0.08111841355760892\n",
      "mean epoch loss: 0.07903886660933494\n",
      "mean epoch loss: 0.0776441365480423\n",
      "saved model from epoch 162\n",
      "mean epoch loss: 0.07535115331411361\n",
      "mean epoch loss: 0.07358273549212349\n",
      "mean epoch loss: 0.07172935696111785\n",
      "saved model from epoch 165\n",
      "mean epoch loss: 0.07015705174869961\n",
      "mean epoch loss: 0.06860170579618878\n",
      "mean epoch loss: 0.06685301926400926\n",
      "saved model from epoch 168\n",
      "mean epoch loss: 0.06504004249970118\n",
      "mean epoch loss: 0.06338784578773711\n",
      "mean epoch loss: 0.061578737861580315\n",
      "saved model from epoch 171\n",
      "mean epoch loss: 0.05999819226562977\n",
      "mean epoch loss: 0.058556287404563694\n",
      "mean epoch loss: 0.05733430965079202\n",
      "saved model from epoch 174\n",
      "mean epoch loss: 0.055656977949870956\n",
      "mean epoch loss: 0.05424552890989515\n",
      "mean epoch loss: 0.05276897135708067\n",
      "saved model from epoch 177\n",
      "mean epoch loss: 0.05128238333596124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean epoch loss: 0.05001828339364794\n",
      "mean epoch loss: 0.048704957258370186\n",
      "saved model from epoch 180\n",
      "mean epoch loss: 0.04732051967746682\n",
      "mean epoch loss: 0.04603560889760653\n",
      "mean epoch loss: 0.044933332751194634\n",
      "saved model from epoch 183\n",
      "mean epoch loss: 0.04376012881596883\n",
      "mean epoch loss: 0.04244095517529382\n",
      "mean epoch loss: 0.04130334080093437\n",
      "saved model from epoch 186\n",
      "mean epoch loss: 0.04021943300548527\n",
      "mean epoch loss: 0.03923980784085062\n",
      "mean epoch loss: 0.0380671205619971\n",
      "saved model from epoch 189\n",
      "mean epoch loss: 0.03730869669881132\n",
      "mean epoch loss: 0.03609199354218112\n",
      "mean epoch loss: 0.035157503767146006\n",
      "saved model from epoch 192\n",
      "mean epoch loss: 0.03423252974947293\n",
      "mean epoch loss: 0.03334589410159323\n",
      "mean epoch loss: 0.03238540088964833\n",
      "saved model from epoch 195\n",
      "mean epoch loss: 0.03159262848397096\n",
      "mean epoch loss: 0.030781247922115857\n",
      "mean epoch loss: 0.029927222679058712\n",
      "saved model from epoch 198\n",
      "mean epoch loss: 0.02931186705827713\n",
      "mean epoch loss: 0.028507432258791394\n",
      "mean epoch loss: 0.027634069178667335\n",
      "saved model from epoch 201\n",
      "mean epoch loss: 0.027176920821269355\n",
      "mean epoch loss: 0.026355856677724256\n",
      "mean epoch loss: 0.025663390714261266\n",
      "saved model from epoch 204\n",
      "mean epoch loss: 0.02510738122380442\n",
      "mean epoch loss: 0.024553910373813576\n",
      "mean epoch loss: 0.02398652732372284\n",
      "saved model from epoch 207\n",
      "mean epoch loss: 0.023503639010919467\n",
      "mean epoch loss: 0.022931095192001927\n",
      "mean epoch loss: 0.022462733338276544\n",
      "saved model from epoch 210\n",
      "mean epoch loss: 0.021942596861885655\n",
      "mean epoch loss: 0.02149573461049133\n",
      "mean epoch loss: 0.021016709547903804\n",
      "saved model from epoch 213\n",
      "mean epoch loss: 0.020526855149202876\n",
      "mean epoch loss: 0.02034222777518961\n",
      "mean epoch loss: 0.019853764544758533\n",
      "saved model from epoch 216\n",
      "mean epoch loss: 0.01944054402410984\n",
      "mean epoch loss: 0.019160289793378776\n",
      "mean epoch loss: 0.01879241776963075\n",
      "saved model from epoch 219\n",
      "mean epoch loss: 0.018456643923289245\n",
      "mean epoch loss: 0.018141905114882523\n",
      "mean epoch loss: 0.01791924877713124\n",
      "saved model from epoch 222\n",
      "mean epoch loss: 0.017713523904482522\n",
      "mean epoch loss: 0.01734109137000309\n",
      "mean epoch loss: 0.017198565002116892\n",
      "saved model from epoch 225\n",
      "mean epoch loss: 0.016979957351254092\n",
      "mean epoch loss: 0.016696426996754277\n",
      "mean epoch loss: 0.016551090735528205\n",
      "saved model from epoch 228\n",
      "mean epoch loss: 0.01624911032203171\n",
      "mean epoch loss: 0.016139750700030063\n",
      "mean epoch loss: 0.015975505837963686\n",
      "saved model from epoch 231\n",
      "mean epoch loss: 0.015843725928829776\n",
      "mean epoch loss: 0.015675633586943148\n",
      "mean epoch loss: 0.015562450513243675\n",
      "saved model from epoch 234\n",
      "mean epoch loss: 0.015352804099933968\n",
      "mean epoch loss: 0.015326595803101858\n",
      "mean epoch loss: 0.015060133611162504\n",
      "saved model from epoch 237\n",
      "mean epoch loss: 0.015009001787337993\n",
      "mean epoch loss: 0.014872450340125297\n",
      "mean epoch loss: 0.014767062726120155\n",
      "saved model from epoch 240\n",
      "mean epoch loss: 0.014787441160943772\n",
      "mean epoch loss: 0.014563901205029752\n",
      "mean epoch loss: 0.014542792406347062\n",
      "saved model from epoch 243\n",
      "mean epoch loss: 0.014368838423656093\n",
      "mean epoch loss: 0.014450504899852806\n",
      "mean epoch loss: 0.01430128560298019\n",
      "saved model from epoch 246\n",
      "mean epoch loss: 0.014210412237379287\n",
      "mean epoch loss: 0.014187758788466454\n",
      "mean epoch loss: 0.014027826136185063\n",
      "saved model from epoch 249\n",
      "mean epoch loss: 0.014092879928648471\n",
      "mean epoch loss: 0.013907618417094151\n",
      "mean epoch loss: 0.013858912098738883\n",
      "saved model from epoch 252\n",
      "mean epoch loss: 0.013874122272762987\n",
      "mean epoch loss: 0.013777034926331706\n",
      "mean epoch loss: 0.013701009284704923\n",
      "saved model from epoch 255\n",
      "mean epoch loss: 0.013643242294589679\n",
      "mean epoch loss: 0.013639712840732602\n",
      "mean epoch loss: 0.013610619285868274\n",
      "saved model from epoch 258\n",
      "mean epoch loss: 0.013508126532865896\n",
      "mean epoch loss: 0.013529503573146131\n",
      "mean epoch loss: 0.01341170592026578\n",
      "saved model from epoch 261\n",
      "mean epoch loss: 0.013466197583410475\n",
      "mean epoch loss: 0.013302331790328026\n",
      "mean epoch loss: 0.01327481921762228\n",
      "saved model from epoch 264\n",
      "mean epoch loss: 0.013256024817625682\n",
      "mean epoch loss: 0.013190100755956438\n",
      "mean epoch loss: 0.013214349105126328\n",
      "saved model from epoch 267\n",
      "mean epoch loss: 0.013164126645359727\n",
      "mean epoch loss: 0.013118119372261896\n",
      "mean epoch loss: 0.013050383888185024\n",
      "saved model from epoch 270\n",
      "mean epoch loss: 0.01303909875245558\n",
      "mean epoch loss: 0.012995779617793031\n",
      "mean epoch loss: 0.012967935307986206\n",
      "saved model from epoch 273\n",
      "mean epoch loss: 0.012890720046642754\n",
      "mean epoch loss: 0.012827003147039148\n",
      "mean epoch loss: 0.012908567984898886\n",
      "saved model from epoch 276\n",
      "mean epoch loss: 0.012836963817891147\n",
      "mean epoch loss: 0.01277244837126798\n",
      "mean epoch loss: 0.012727683368656371\n",
      "saved model from epoch 279\n",
      "mean epoch loss: 0.012779316678643227\n",
      "mean epoch loss: 0.012675026711076499\n",
      "mean epoch loss: 0.012598468508157466\n",
      "saved model from epoch 282\n",
      "mean epoch loss: 0.012561491028302245\n",
      "mean epoch loss: 0.012595270801749494\n",
      "mean epoch loss: 0.012562155599395435\n",
      "saved model from epoch 285\n",
      "mean epoch loss: 0.012505502440035343\n",
      "mean epoch loss: 0.01244809820006291\n",
      "mean epoch loss: 0.012413054994410939\n",
      "saved model from epoch 288\n",
      "mean epoch loss: 0.012411232934229903\n",
      "mean epoch loss: 0.012256673050837384\n",
      "mean epoch loss: 0.012503068925191959\n",
      "saved model from epoch 291\n",
      "mean epoch loss: 0.012311934327913655\n",
      "mean epoch loss: 0.012210869075109562\n",
      "mean epoch loss: 0.012202665344294575\n",
      "saved model from epoch 294\n",
      "mean epoch loss: 0.012183304907133182\n",
      "mean epoch loss: 0.012127177510410547\n",
      "mean epoch loss: 0.012109028661830558\n",
      "saved model from epoch 297\n",
      "mean epoch loss: 0.01210758632255925\n",
      "mean epoch loss: 0.012031273088521428\n",
      "mean epoch loss: 0.011975631469653712\n",
      "saved model from epoch 300\n",
      "mean epoch loss: 0.012082687930928336\n",
      "mean epoch loss: 0.01199234693000714\n",
      "mean epoch loss: 0.011974385318656763\n",
      "saved model from epoch 303\n",
      "mean epoch loss: 0.011891493915269773\n",
      "mean epoch loss: 0.011861617707957824\n",
      "mean epoch loss: 0.011779828307529291\n",
      "saved model from epoch 306\n",
      "mean epoch loss: 0.011925957165658474\n",
      "mean epoch loss: 0.01172473830067449\n",
      "mean epoch loss: 0.011805659667071368\n",
      "saved model from epoch 309\n",
      "mean epoch loss: 0.011716626077476476\n",
      "mean epoch loss: 0.01176122311088774\n",
      "mean epoch loss: 0.011660354925940435\n",
      "saved model from epoch 312\n",
      "mean epoch loss: 0.011649277744193871\n",
      "mean epoch loss: 0.011640374383164776\n",
      "mean epoch loss: 0.011607522186305787\n",
      "saved model from epoch 315\n",
      "mean epoch loss: 0.011689221755497985\n",
      "mean epoch loss: 0.011635398657785522\n",
      "mean epoch loss: 0.011472397639105717\n",
      "saved model from epoch 318\n",
      "mean epoch loss: 0.01147456903838449\n",
      "mean epoch loss: 0.011460830954213937\n",
      "mean epoch loss: 0.011499376243187321\n",
      "saved model from epoch 321\n",
      "mean epoch loss: 0.011424042801890109\n",
      "mean epoch loss: 0.011382611913399563\n",
      "mean epoch loss: 0.011419590790238646\n",
      "saved model from epoch 324\n",
      "mean epoch loss: 0.011454953336053425\n",
      "mean epoch loss: 0.011351974950068526\n",
      "mean epoch loss: 0.011288683126784034\n",
      "saved model from epoch 327\n",
      "mean epoch loss: 0.011414758612712224\n",
      "mean epoch loss: 0.011278472271644406\n",
      "mean epoch loss: 0.011326108438273272\n",
      "saved model from epoch 330\n",
      "mean epoch loss: 0.011201845657908254\n",
      "mean epoch loss: 0.011173391776780287\n",
      "mean epoch loss: 0.011263581375694937\n",
      "saved model from epoch 333\n",
      "mean epoch loss: 0.011247927240199513\n",
      "mean epoch loss: 0.01113311198229591\n",
      "mean epoch loss: 0.011077080335881975\n",
      "saved model from epoch 336\n",
      "mean epoch loss: 0.011060714204278257\n",
      "mean epoch loss: 0.01109315153832237\n",
      "mean epoch loss: 0.011089726909995079\n",
      "saved model from epoch 339\n",
      "mean epoch loss: 0.011090759705338214\n",
      "mean epoch loss: 0.011069423260374201\n",
      "mean epoch loss: 0.011006736538062493\n",
      "saved model from epoch 342\n",
      "mean epoch loss: 0.011065139352447457\n",
      "mean epoch loss: 0.010912190274231964\n",
      "mean epoch loss: 0.010934104584157467\n",
      "saved model from epoch 345\n",
      "mean epoch loss: 0.010905622463259433\n",
      "mean epoch loss: 0.010843812032706207\n",
      "mean epoch loss: 0.010844235153247913\n",
      "saved model from epoch 348\n",
      "mean epoch loss: 0.01084148521638579\n",
      "mean epoch loss: 0.010877050231728289\n",
      "mean epoch loss: 0.010786828967846102\n",
      "saved model from epoch 351\n",
      "mean epoch loss: 0.010747525468468666\n",
      "mean epoch loss: 0.010780096995747751\n",
      "mean epoch loss: 0.010799633980625205\n",
      "saved model from epoch 354\n",
      "mean epoch loss: 0.010794147186809116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean epoch loss: 0.010722411641230186\n",
      "mean epoch loss: 0.010727108652806945\n",
      "saved model from epoch 357\n",
      "mean epoch loss: 0.010696306410763\n",
      "mean epoch loss: 0.010687658563256264\n",
      "mean epoch loss: 0.010642167108340397\n",
      "saved model from epoch 360\n",
      "mean epoch loss: 0.010762632244990931\n",
      "mean epoch loss: 0.010680002429419093\n",
      "mean epoch loss: 0.010653852557556496\n",
      "saved model from epoch 363\n",
      "mean epoch loss: 0.010649234201345179\n",
      "mean epoch loss: 0.01058117544485463\n",
      "mean epoch loss: 0.010545747727155686\n",
      "saved model from epoch 366\n",
      "mean epoch loss: 0.010508506124218305\n",
      "mean epoch loss: 0.010509968445532852\n",
      "mean epoch loss: 0.01049867868423462\n",
      "saved model from epoch 369\n",
      "mean epoch loss: 0.010530112228459782\n",
      "mean epoch loss: 0.010506783756944868\n",
      "mean epoch loss: 0.010498608390076294\n",
      "saved model from epoch 372\n",
      "mean epoch loss: 0.010427874885499478\n",
      "mean epoch loss: 0.010416282568540838\n",
      "mean epoch loss: 0.010423656925559044\n",
      "saved model from epoch 375\n",
      "mean epoch loss: 0.010382417723950413\n",
      "mean epoch loss: 0.010483406111598014\n",
      "mean epoch loss: 0.010436395193553633\n",
      "saved model from epoch 378\n",
      "mean epoch loss: 0.01037826623974575\n",
      "mean epoch loss: 0.010324884723458026\n",
      "mean epoch loss: 0.010347202947984139\n",
      "saved model from epoch 381\n",
      "mean epoch loss: 0.010313162683612771\n",
      "mean epoch loss: 0.010325412100387944\n",
      "mean epoch loss: 0.010301639481137196\n",
      "saved model from epoch 384\n",
      "mean epoch loss: 0.010291783408158355\n",
      "mean epoch loss: 0.010313258113132582\n",
      "mean epoch loss: 0.01047895500022504\n",
      "saved model from epoch 387\n",
      "mean epoch loss: 0.010234280396252871\n",
      "mean epoch loss: 0.010274844006117848\n",
      "mean epoch loss: 0.010262467267198695\n",
      "saved model from epoch 390\n",
      "mean epoch loss: 0.010239161106033458\n",
      "mean epoch loss: 0.010189903144621187\n",
      "mean epoch loss: 0.010336136352270842\n",
      "saved model from epoch 393\n",
      "mean epoch loss: 0.010218997413499489\n",
      "mean epoch loss: 0.0101530354987416\n",
      "mean epoch loss: 0.010244422281781832\n",
      "saved model from epoch 396\n",
      "mean epoch loss: 0.010180455611811743\n",
      "mean epoch loss: 0.010157860380907853\n",
      "mean epoch loss: 0.010195666820638709\n",
      "saved model from epoch 399\n",
      "mean epoch loss: 0.010073854981197252\n",
      "mean epoch loss: 0.010098785772505734\n",
      "mean epoch loss: 0.010139888369788725\n",
      "saved model from epoch 402\n",
      "mean epoch loss: 0.01014021338067121\n",
      "mean epoch loss: 0.010113115432775682\n",
      "mean epoch loss: 0.010079688195967012\n",
      "saved model from epoch 405\n",
      "mean epoch loss: 0.010138286432872215\n",
      "mean epoch loss: 0.010025721415877343\n",
      "mean epoch loss: 0.010121289651013082\n",
      "saved model from epoch 408\n",
      "mean epoch loss: 0.010066009571568833\n",
      "mean epoch loss: 0.010060379271292025\n",
      "mean epoch loss: 0.010008302941504453\n",
      "saved model from epoch 411\n",
      "mean epoch loss: 0.010000822796589799\n",
      "mean epoch loss: 0.009960913016564316\n",
      "mean epoch loss: 0.009996622314469681\n",
      "saved model from epoch 414\n",
      "mean epoch loss: 0.009980339443104135\n",
      "mean epoch loss: 0.009993122186925676\n",
      "mean epoch loss: 0.010004870645287964\n",
      "saved model from epoch 417\n",
      "mean epoch loss: 0.01002392340451479\n",
      "mean epoch loss: 0.009865909918314882\n",
      "mean epoch loss: 0.00996750978132089\n",
      "saved model from epoch 420\n",
      "mean epoch loss: 0.00996649663688408\n",
      "mean epoch loss: 0.009929810257421599\n",
      "mean epoch loss: 0.009898181073367596\n",
      "saved model from epoch 423\n",
      "mean epoch loss: 0.009923894320511155\n",
      "mean epoch loss: 0.009894184312886661\n",
      "mean epoch loss: 0.009886002261191606\n",
      "saved model from epoch 426\n",
      "mean epoch loss: 0.009888381252272262\n",
      "mean epoch loss: 0.009895525417394108\n",
      "mean epoch loss: 0.009838253870192501\n",
      "saved model from epoch 429\n",
      "mean epoch loss: 0.009952803276893166\n",
      "mean epoch loss: 0.009843475764824285\n",
      "mean epoch loss: 0.009920747764408589\n",
      "saved model from epoch 432\n",
      "mean epoch loss: 0.009848135844286945\n",
      "mean epoch loss: 0.009809696281121837\n",
      "mean epoch loss: 0.009838359316604005\n",
      "saved model from epoch 435\n",
      "mean epoch loss: 0.009772717259410355\n",
      "mean epoch loss: 0.009783101381940974\n",
      "mean epoch loss: 0.00978648741212156\n",
      "saved model from epoch 438\n",
      "mean epoch loss: 0.009824461614092192\n",
      "mean epoch loss: 0.009767276938590738\n",
      "mean epoch loss: 0.009837623002628486\n",
      "saved model from epoch 441\n",
      "mean epoch loss: 0.009811041887021726\n",
      "mean epoch loss: 0.009704194580101305\n",
      "mean epoch loss: 0.009769834567689234\n",
      "saved model from epoch 444\n",
      "mean epoch loss: 0.009706598810023732\n",
      "mean epoch loss: 0.009750891549305783\n",
      "mean epoch loss: 0.00967264525178406\n",
      "saved model from epoch 447\n",
      "mean epoch loss: 0.009756116289645433\n",
      "mean epoch loss: 0.009698941599991587\n",
      "mean epoch loss: 0.00977735807084375\n",
      "saved model from epoch 450\n",
      "mean epoch loss: 0.009662177434398069\n",
      "mean epoch loss: 0.009719334221962425\n",
      "mean epoch loss: 0.009661570657044649\n",
      "saved model from epoch 453\n",
      "mean epoch loss: 0.009683410378379954\n",
      "mean epoch loss: 0.009741227380517456\n",
      "mean epoch loss: 0.009636280302786165\n",
      "saved model from epoch 456\n",
      "mean epoch loss: 0.009658541902899742\n",
      "mean epoch loss: 0.00969006706857019\n",
      "mean epoch loss: 0.009639779043694337\n",
      "saved model from epoch 459\n",
      "mean epoch loss: 0.009596542589780358\n",
      "mean epoch loss: 0.00958084398880601\n",
      "mean epoch loss: 0.009615724181963338\n",
      "saved model from epoch 462\n",
      "mean epoch loss: 0.009619532422059112\n",
      "mean epoch loss: 0.0096224178146157\n",
      "mean epoch loss: 0.009670990146696567\n",
      "saved model from epoch 465\n",
      "mean epoch loss: 0.0096046544611454\n",
      "mean epoch loss: 0.009561913067268\n",
      "mean epoch loss: 0.009576094119499128\n",
      "saved model from epoch 468\n",
      "mean epoch loss: 0.009576999189125166\n",
      "mean epoch loss: 0.00957053318205807\n",
      "mean epoch loss: 0.009685227616379658\n",
      "saved model from epoch 471\n",
      "mean epoch loss: 0.009573120892875724\n",
      "mean epoch loss: 0.009540543436176246\n",
      "mean epoch loss: 0.009705056808888913\n",
      "saved model from epoch 474\n",
      "mean epoch loss: 0.009559912793338298\n",
      "mean epoch loss: 0.009535495429817173\n",
      "mean epoch loss: 0.009494620975520876\n",
      "saved model from epoch 477\n",
      "mean epoch loss: 0.009653522933108939\n",
      "mean epoch loss: 0.009497259412374762\n",
      "mean epoch loss: 0.009466103919678264\n",
      "saved model from epoch 480\n",
      "mean epoch loss: 0.00957323167886999\n",
      "mean epoch loss: 0.00954494515640868\n",
      "mean epoch loss: 0.009468841428558031\n",
      "saved model from epoch 483\n",
      "mean epoch loss: 0.009524950167785089\n",
      "mean epoch loss: 0.009538296584246887\n",
      "mean epoch loss: 0.00945282553633054\n",
      "saved model from epoch 486\n",
      "mean epoch loss: 0.00949847675446007\n",
      "mean epoch loss: 0.009496943507757451\n",
      "mean epoch loss: 0.009459454110927051\n",
      "saved model from epoch 489\n",
      "mean epoch loss: 0.00944979093554947\n",
      "mean epoch loss: 0.009521101870470576\n",
      "mean epoch loss: 0.009528286330815818\n",
      "saved model from epoch 492\n",
      "mean epoch loss: 0.00953299164151152\n",
      "mean epoch loss: 0.009444307246141963\n",
      "mean epoch loss: 0.009452534135844973\n",
      "saved model from epoch 495\n",
      "mean epoch loss: 0.009384743869304657\n",
      "mean epoch loss: 0.009418353779862325\n",
      "mean epoch loss: 0.00941028254520562\n",
      "saved model from epoch 498\n",
      "mean epoch loss: 0.009399565981907977\n",
      "mean epoch loss: 0.00939773377031088\n",
      "mean epoch loss: 0.009384113902019129\n",
      "saved model from epoch 501\n",
      "mean epoch loss: 0.00943059383167161\n",
      "mean epoch loss: 0.009424587504731284\n",
      "mean epoch loss: 0.009401274032683836\n",
      "saved model from epoch 504\n",
      "mean epoch loss: 0.009447147800690598\n",
      "mean epoch loss: 0.00934869238278932\n",
      "mean epoch loss: 0.009372772824847036\n",
      "saved model from epoch 507\n",
      "mean epoch loss: 0.00932696879737907\n",
      "mean epoch loss: 0.0094256647138132\n",
      "mean epoch loss: 0.00941518603099717\n",
      "saved model from epoch 510\n",
      "mean epoch loss: 0.009435663382626242\n",
      "mean epoch loss: 0.009453478838420577\n",
      "mean epoch loss: 0.009349045240216784\n",
      "saved model from epoch 513\n",
      "mean epoch loss: 0.00937607969260878\n",
      "mean epoch loss: 0.009316725180380875\n",
      "mean epoch loss: 0.00933788429117865\n",
      "saved model from epoch 516\n",
      "mean epoch loss: 0.009441102678991026\n",
      "mean epoch loss: 0.009368821274903086\n",
      "mean epoch loss: 0.00933583891019225\n",
      "saved model from epoch 519\n",
      "mean epoch loss: 0.009369581482476658\n",
      "mean epoch loss: 0.009267220242569844\n",
      "mean epoch loss: 0.009318018715000815\n",
      "saved model from epoch 522\n",
      "mean epoch loss: 0.0092950156579415\n",
      "mean epoch loss: 0.009256297091229094\n",
      "mean epoch loss: 0.009330199845135213\n",
      "saved model from epoch 525\n",
      "mean epoch loss: 0.009331666678190232\n",
      "mean epoch loss: 0.009287998711483347\n",
      "mean epoch loss: 0.009258784022596148\n",
      "saved model from epoch 528\n",
      "mean epoch loss: 0.009255155807154046\n",
      "mean epoch loss: 0.009247324439800447\n",
      "mean epoch loss: 0.009281772561371327\n",
      "saved model from epoch 531\n",
      "mean epoch loss: 0.00923628548367156\n",
      "mean epoch loss: 0.009256882096330325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean epoch loss: 0.009222914164678919\n",
      "saved model from epoch 534\n",
      "mean epoch loss: 0.009235671855923203\n",
      "mean epoch loss: 0.009260261369248231\n",
      "mean epoch loss: 0.009195922791130013\n",
      "saved model from epoch 537\n",
      "mean epoch loss: 0.009251668687082\n",
      "mean epoch loss: 0.009223961550742388\n",
      "mean epoch loss: 0.009250957736124594\n",
      "saved model from epoch 540\n",
      "mean epoch loss: 0.009259795237125622\n",
      "mean epoch loss: 0.009278522245585919\n",
      "mean epoch loss: 0.009209729710386859\n",
      "saved model from epoch 543\n",
      "mean epoch loss: 0.00920348097052839\n",
      "mean epoch loss: 0.009235041909333733\n",
      "mean epoch loss: 0.00921476637530658\n",
      "saved model from epoch 546\n",
      "mean epoch loss: 0.009188914630148147\n",
      "mean epoch loss: 0.009151173952139087\n",
      "mean epoch loss: 0.009148820882870091\n",
      "saved model from epoch 549\n",
      "mean epoch loss: 0.00913297679896156\n",
      "mean epoch loss: 0.009166377948390113\n",
      "mean epoch loss: 0.009239842287368245\n",
      "saved model from epoch 552\n",
      "mean epoch loss: 0.009162627512382136\n",
      "mean epoch loss: 0.009179369712041485\n",
      "mean epoch loss: 0.009179223204652469\n",
      "saved model from epoch 555\n",
      "mean epoch loss: 0.009181658778753545\n",
      "mean epoch loss: 0.009107955690059398\n",
      "mean epoch loss: 0.009191515700270733\n",
      "saved model from epoch 558\n",
      "mean epoch loss: 0.009176178131666449\n",
      "mean epoch loss: 0.00914446300206085\n",
      "mean epoch loss: 0.009158220913054214\n",
      "saved model from epoch 561\n",
      "mean epoch loss: 0.009116920394202073\n",
      "mean epoch loss: 0.009103836015694672\n",
      "mean epoch loss: 0.0091457675728533\n",
      "saved model from epoch 564\n",
      "mean epoch loss: 0.00909819577096237\n",
      "mean epoch loss: 0.009178238444858128\n",
      "mean epoch loss: 0.009121800007091629\n",
      "saved model from epoch 567\n",
      "mean epoch loss: 0.009099141053027577\n",
      "mean epoch loss: 0.009144775512524777\n",
      "mean epoch loss: 0.009306155207256476\n",
      "saved model from epoch 570\n",
      "mean epoch loss: 0.009088788502332237\n",
      "mean epoch loss: 0.009049111925479438\n",
      "mean epoch loss: 0.009128270101630025\n",
      "saved model from epoch 573\n",
      "mean epoch loss: 0.009166990665511953\n",
      "mean epoch loss: 0.009102049583776129\n",
      "mean epoch loss: 0.009130745422508982\n",
      "saved model from epoch 576\n",
      "mean epoch loss: 0.009055620028326909\n",
      "mean epoch loss: 0.009127956659843525\n",
      "mean epoch loss: 0.009101687278598548\n",
      "saved model from epoch 579\n",
      "mean epoch loss: 0.009029337453345459\n",
      "mean epoch loss: 0.009015325053284565\n",
      "mean epoch loss: 0.009092539911054902\n",
      "saved model from epoch 582\n",
      "mean epoch loss: 0.009039166683538092\n",
      "mean epoch loss: 0.009056178759783507\n",
      "mean epoch loss: 0.009042493781695764\n",
      "saved model from epoch 585\n",
      "mean epoch loss: 0.009089934939725531\n",
      "mean epoch loss: 0.00901077693949143\n",
      "mean epoch loss: 0.009069995313054986\n",
      "saved model from epoch 588\n",
      "mean epoch loss: 0.009113759454339742\n",
      "mean epoch loss: 0.009032277007483774\n",
      "mean epoch loss: 0.009011344063199228\n",
      "saved model from epoch 591\n",
      "mean epoch loss: 0.00915454975846741\n",
      "mean epoch loss: 0.009006237145513296\n",
      "mean epoch loss: 0.009064846196108395\n",
      "saved model from epoch 594\n",
      "mean epoch loss: 0.009040238242596388\n",
      "mean epoch loss: 0.00902612783635656\n",
      "mean epoch loss: 0.009015994674215714\n",
      "saved model from epoch 597\n",
      "mean epoch loss: 0.009015102239532603\n",
      "mean epoch loss: 0.008995407240258322\n",
      "mean epoch loss: 0.009008581672484675\n",
      "saved model from epoch 600\n",
      "mean epoch loss: 0.009000238755510913\n",
      "mean epoch loss: 0.009008473044054376\n",
      "mean epoch loss: 0.008996003700627222\n",
      "saved model from epoch 603\n",
      "mean epoch loss: 0.009034047436176074\n",
      "mean epoch loss: 0.008972860789961285\n",
      "mean epoch loss: 0.008992582932114601\n",
      "saved model from epoch 606\n",
      "mean epoch loss: 0.009016211392978828\n",
      "mean epoch loss: 0.008984859484351343\n",
      "mean epoch loss: 0.009014259527126948\n",
      "saved model from epoch 609\n",
      "mean epoch loss: 0.008928905251539415\n",
      "mean epoch loss: 0.009040742020847068\n",
      "mean epoch loss: 0.009042980961708559\n",
      "saved model from epoch 612\n",
      "mean epoch loss: 0.008939602950380907\n",
      "mean epoch loss: 0.009026969545003441\n",
      "mean epoch loss: 0.008947929915868574\n",
      "saved model from epoch 615\n",
      "mean epoch loss: 0.008956168167706993\n",
      "mean epoch loss: 0.008926878000299137\n",
      "mean epoch loss: 0.008958469269176324\n",
      "saved model from epoch 618\n",
      "mean epoch loss: 0.008886935903380315\n",
      "mean epoch loss: 0.00897833224799898\n",
      "mean epoch loss: 0.008994076597607798\n",
      "saved model from epoch 621\n",
      "mean epoch loss: 0.00888195074059897\n",
      "mean epoch loss: 0.008976293282790317\n",
      "mean epoch loss: 0.008900749134934612\n",
      "saved model from epoch 624\n",
      "mean epoch loss: 0.008924123106731309\n",
      "mean epoch loss: 0.008887814720057778\n",
      "mean epoch loss: 0.008916441164910794\n",
      "saved model from epoch 627\n",
      "mean epoch loss: 0.00899066376603312\n",
      "mean epoch loss: 0.008897256271706688\n",
      "mean epoch loss: 0.008908866920198004\n",
      "saved model from epoch 630\n",
      "mean epoch loss: 0.008973994199186564\n",
      "mean epoch loss: 0.00885131747668816\n",
      "mean epoch loss: 0.008857347619616323\n",
      "saved model from epoch 633\n",
      "mean epoch loss: 0.008914765550030603\n",
      "mean epoch loss: 0.0089994918451541\n",
      "mean epoch loss: 0.008837283744166294\n",
      "saved model from epoch 636\n",
      "mean epoch loss: 0.008861895040091541\n",
      "mean epoch loss: 0.008825076764656438\n",
      "mean epoch loss: 0.00887546045705676\n",
      "saved model from epoch 639\n",
      "mean epoch loss: 0.008910930963853996\n",
      "mean epoch loss: 0.008883743593469263\n",
      "mean epoch loss: 0.008891411943154202\n",
      "saved model from epoch 642\n",
      "mean epoch loss: 0.008826484546686213\n",
      "mean epoch loss: 0.00891777320454518\n",
      "mean epoch loss: 0.008869066358440453\n",
      "saved model from epoch 645\n",
      "mean epoch loss: 0.008895348731635345\n",
      "mean epoch loss: 0.008790925621158546\n",
      "mean epoch loss: 0.008962615807023313\n",
      "saved model from epoch 648\n",
      "mean epoch loss: 0.008838532782263226\n",
      "mean epoch loss: 0.008791512628603313\n",
      "mean epoch loss: 0.00885778996679518\n",
      "saved model from epoch 651\n",
      "mean epoch loss: 0.008806948963966634\n",
      "mean epoch loss: 0.00881856790640288\n",
      "mean epoch loss: 0.008783931668019957\n",
      "saved model from epoch 654\n",
      "mean epoch loss: 0.008879168466147449\n",
      "mean epoch loss: 0.008820242207083438\n",
      "mean epoch loss: 0.008844468504604366\n",
      "saved model from epoch 657\n",
      "mean epoch loss: 0.008804362318995927\n",
      "mean epoch loss: 0.0087829586946302\n",
      "mean epoch loss: 0.008853459420303503\n",
      "saved model from epoch 660\n",
      "mean epoch loss: 0.00887729462960528\n",
      "mean epoch loss: 0.008820208048241006\n",
      "mean epoch loss: 0.00879108476349049\n",
      "saved model from epoch 663\n",
      "mean epoch loss: 0.008790142171912723\n",
      "mean epoch loss: 0.008735842444002629\n",
      "mean epoch loss: 0.008861384220007392\n",
      "saved model from epoch 666\n",
      "mean epoch loss: 0.008762265317555931\n",
      "mean epoch loss: 0.008768055246522029\n",
      "mean epoch loss: 0.0087345399065978\n",
      "saved model from epoch 669\n",
      "mean epoch loss: 0.008781570579028793\n",
      "mean epoch loss: 0.008752039675083425\n",
      "mean epoch loss: 0.008748802159809404\n",
      "saved model from epoch 672\n",
      "mean epoch loss: 0.00879060152090258\n",
      "mean epoch loss: 0.008738420686374109\n",
      "mean epoch loss: 0.0088221184288462\n",
      "saved model from epoch 675\n",
      "mean epoch loss: 0.008748404888643159\n",
      "mean epoch loss: 0.008794786956989103\n",
      "mean epoch loss: 0.008711348856902786\n",
      "saved model from epoch 678\n",
      "mean epoch loss: 0.008764375777294239\n",
      "mean epoch loss: 0.008728956457020508\n",
      "mean epoch loss: 0.008794028643104764\n",
      "saved model from epoch 681\n",
      "mean epoch loss: 0.008707483309424585\n",
      "mean epoch loss: 0.008721172644032372\n",
      "mean epoch loss: 0.008717791394641001\n",
      "saved model from epoch 684\n",
      "mean epoch loss: 0.008785566956632667\n",
      "mean epoch loss: 0.008684613503929642\n",
      "mean epoch loss: 0.008760018201751842\n",
      "saved model from epoch 687\n",
      "mean epoch loss: 0.008780408029754957\n",
      "mean epoch loss: 0.00877517925368415\n",
      "mean epoch loss: 0.008687161152354544\n",
      "saved model from epoch 690\n",
      "mean epoch loss: 0.008694616229169899\n",
      "mean epoch loss: 0.00870837862085965\n",
      "mean epoch loss: 0.00868483030030297\n",
      "saved model from epoch 693\n",
      "mean epoch loss: 0.008724558001591099\n",
      "mean epoch loss: 0.008732972030217449\n",
      "mean epoch loss: 0.008736561963127719\n",
      "saved model from epoch 696\n",
      "mean epoch loss: 0.008651372831728723\n",
      "mean epoch loss: 0.008672223954151074\n",
      "mean epoch loss: 0.008689376960198085\n",
      "saved model from epoch 699\n",
      "mean epoch loss: 0.008638298242456384\n",
      "mean epoch loss: 0.008685316942218278\n",
      "mean epoch loss: 0.008639906988375717\n",
      "saved model from epoch 702\n",
      "mean epoch loss: 0.00868044574227598\n",
      "mean epoch loss: 0.008661832401735915\n",
      "mean epoch loss: 0.00865524597465992\n",
      "saved model from epoch 705\n",
      "mean epoch loss: 0.008605923855470286\n",
      "mean epoch loss: 0.00863530081179407\n",
      "mean epoch loss: 0.008649802994396952\n",
      "saved model from epoch 708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean epoch loss: 0.00862951824027631\n",
      "mean epoch loss: 0.008594753577684362\n",
      "mean epoch loss: 0.008670948399230837\n",
      "saved model from epoch 711\n",
      "mean epoch loss: 0.008616173236320416\n",
      "mean epoch loss: 0.008618015775250064\n",
      "mean epoch loss: 0.008634878068955408\n",
      "saved model from epoch 714\n",
      "mean epoch loss: 0.008608641289174556\n",
      "mean epoch loss: 0.00863408525991771\n",
      "mean epoch loss: 0.008633736365785202\n",
      "saved model from epoch 717\n",
      "mean epoch loss: 0.00866698483005166\n",
      "mean epoch loss: 0.008605866382519404\n",
      "mean epoch loss: 0.008681784637479319\n",
      "saved model from epoch 720\n",
      "mean epoch loss: 0.008604281871683068\n",
      "mean epoch loss: 0.00864293161365721\n",
      "mean epoch loss: 0.008638703942091928\n",
      "saved model from epoch 723\n",
      "mean epoch loss: 0.00857188833049602\n",
      "mean epoch loss: 0.008583212892214457\n",
      "mean epoch loss: 0.008686789425296916\n",
      "saved model from epoch 726\n",
      "mean epoch loss: 0.008540285233822133\n",
      "mean epoch loss: 0.00862231209046311\n",
      "mean epoch loss: 0.008586344360891316\n",
      "saved model from epoch 729\n",
      "mean epoch loss: 0.008589768761561976\n",
      "mean epoch loss: 0.008617040504597955\n",
      "mean epoch loss: 0.008591024805274275\n",
      "saved model from epoch 732\n",
      "mean epoch loss: 0.008575345306760735\n",
      "mean epoch loss: 0.008563099056482315\n",
      "mean epoch loss: 0.008591120183053944\n",
      "saved model from epoch 735\n",
      "mean epoch loss: 0.008620813933925496\n",
      "mean epoch loss: 0.008568635624316003\n",
      "mean epoch loss: 0.008556594916929802\n",
      "saved model from epoch 738\n",
      "mean epoch loss: 0.008580357902165917\n",
      "mean epoch loss: 0.008591726029084788\n",
      "mean epoch loss: 0.008522758384545644\n",
      "saved model from epoch 741\n",
      "mean epoch loss: 0.008569930581789878\n",
      "mean epoch loss: 0.008484341856092214\n",
      "mean epoch loss: 0.008525101726667749\n",
      "saved model from epoch 744\n",
      "mean epoch loss: 0.008577445656475094\n",
      "mean epoch loss: 0.008662706075443161\n",
      "mean epoch loss: 0.008537719357344839\n",
      "saved model from epoch 747\n",
      "mean epoch loss: 0.008593447185638878\n",
      "mean epoch loss: 0.008554245397034619\n",
      "mean epoch loss: 0.008509352875666485\n",
      "saved model from epoch 750\n",
      "mean epoch loss: 0.008508546189922426\n",
      "mean epoch loss: 0.00852330837191807\n",
      "mean epoch loss: 0.008501307485211227\n",
      "saved model from epoch 753\n",
      "mean epoch loss: 0.008536608558562067\n",
      "mean epoch loss: 0.00859390672089325\n",
      "mean epoch loss: 0.008509927325778537\n",
      "saved model from epoch 756\n",
      "mean epoch loss: 0.008529858477413655\n",
      "mean epoch loss: 0.008481764074208007\n",
      "mean epoch loss: 0.008467530645430089\n",
      "saved model from epoch 759\n",
      "mean epoch loss: 0.008404463808983565\n",
      "mean epoch loss: 0.008481403952464462\n",
      "mean epoch loss: 0.00843378566722903\n",
      "saved model from epoch 762\n",
      "mean epoch loss: 0.008516533703853687\n",
      "mean epoch loss: 0.008514913688931201\n",
      "mean epoch loss: 0.008508425811305642\n",
      "saved model from epoch 765\n",
      "mean epoch loss: 0.008462627252770794\n",
      "mean epoch loss: 0.008405749779194593\n",
      "mean epoch loss: 0.008470332948490977\n",
      "saved model from epoch 768\n",
      "mean epoch loss: 0.008570052403956651\n",
      "mean epoch loss: 0.008448607288300991\n",
      "mean epoch loss: 0.00842383002034492\n",
      "saved model from epoch 771\n",
      "mean epoch loss: 0.00841242540627718\n",
      "mean epoch loss: 0.008434394798758958\n",
      "mean epoch loss: 0.008412262052297592\n",
      "saved model from epoch 774\n",
      "mean epoch loss: 0.00853990644423498\n",
      "mean epoch loss: 0.008443255153381162\n",
      "mean epoch loss: 0.008410688437935378\n",
      "saved model from epoch 777\n",
      "mean epoch loss: 0.008393028637187348\n",
      "mean epoch loss: 0.008528662783404192\n",
      "mean epoch loss: 0.008425499814459019\n",
      "saved model from epoch 780\n",
      "mean epoch loss: 0.008430342076139317\n",
      "mean epoch loss: 0.008451059859039056\n",
      "mean epoch loss: 0.008430196619075205\n",
      "saved model from epoch 783\n",
      "mean epoch loss: 0.008454563489390745\n",
      "mean epoch loss: 0.008392161979443497\n",
      "mean epoch loss: 0.008445720840245485\n",
      "saved model from epoch 786\n",
      "mean epoch loss: 0.008415717910975219\n",
      "mean epoch loss: 0.008404647476143307\n",
      "mean epoch loss: 0.008413821976217959\n",
      "saved model from epoch 789\n",
      "mean epoch loss: 0.008409929503169324\n",
      "mean epoch loss: 0.008457558146781391\n",
      "mean epoch loss: 0.008413140217049255\n",
      "saved model from epoch 792\n",
      "mean epoch loss: 0.008410917563984792\n",
      "mean epoch loss: 0.008462656930916839\n",
      "mean epoch loss: 0.008419157399071588\n",
      "saved model from epoch 795\n",
      "mean epoch loss: 0.00845482392857472\n",
      "mean epoch loss: 0.008369460184541013\n",
      "mean epoch loss: 0.008461013482883573\n",
      "saved model from epoch 798\n",
      "mean epoch loss: 0.008375826912621656\n",
      "mean epoch loss: 0.008490199414599274\n",
      "mean epoch loss: 0.00840027556858129\n",
      "saved model from epoch 801\n",
      "mean epoch loss: 0.008399180809242858\n",
      "mean epoch loss: 0.0083189334306452\n",
      "mean epoch loss: 0.0083274576968203\n",
      "saved model from epoch 804\n",
      "mean epoch loss: 0.00835528869388832\n",
      "mean epoch loss: 0.00833110147052341\n",
      "mean epoch loss: 0.008412088050196569\n",
      "saved model from epoch 807\n",
      "mean epoch loss: 0.008385776345514588\n",
      "mean epoch loss: 0.008352235182084972\n",
      "mean epoch loss: 0.008310700326951014\n",
      "saved model from epoch 810\n",
      "mean epoch loss: 0.008283086079690192\n",
      "mean epoch loss: 0.00832836709709631\n",
      "mean epoch loss: 0.008370710164308548\n",
      "saved model from epoch 813\n",
      "mean epoch loss: 0.008287736866623163\n",
      "mean epoch loss: 0.008344344846490357\n",
      "mean epoch loss: 0.008333086791551775\n",
      "saved model from epoch 816\n",
      "mean epoch loss: 0.008341769780963659\n",
      "mean epoch loss: 0.008334126747730706\n",
      "mean epoch loss: 0.008283131642060147\n",
      "saved model from epoch 819\n",
      "mean epoch loss: 0.008309063718964655\n",
      "mean epoch loss: 0.00838674453811513\n",
      "mean epoch loss: 0.008327376397533549\n",
      "saved model from epoch 822\n",
      "mean epoch loss: 0.008359286499520143\n",
      "mean epoch loss: 0.008266447091268168\n",
      "mean epoch loss: 0.008263946179714468\n",
      "saved model from epoch 825\n",
      "mean epoch loss: 0.008312598429620266\n",
      "mean epoch loss: 0.008295778205825223\n",
      "mean epoch loss: 0.008311066590249539\n",
      "saved model from epoch 828\n",
      "mean epoch loss: 0.008349413786911302\n",
      "mean epoch loss: 0.008372971922573117\n",
      "mean epoch loss: 0.0083398318849504\n",
      "saved model from epoch 831\n",
      "mean epoch loss: 0.008338280643026033\n",
      "mean epoch loss: 0.008350118942972686\n",
      "mean epoch loss: 0.008293230976495479\n",
      "saved model from epoch 834\n",
      "mean epoch loss: 0.008291427563461993\n",
      "mean epoch loss: 0.008291148125297493\n",
      "mean epoch loss: 0.008290661457512115\n",
      "saved model from epoch 837\n",
      "mean epoch loss: 0.008240612265136506\n",
      "mean epoch loss: 0.008288754957417648\n",
      "mean epoch loss: 0.00830025436460144\n",
      "saved model from epoch 840\n",
      "mean epoch loss: 0.008256352920499112\n",
      "mean epoch loss: 0.008283190046333605\n",
      "mean epoch loss: 0.008284985982916422\n",
      "saved model from epoch 843\n",
      "mean epoch loss: 0.008216744371586376\n",
      "mean epoch loss: 0.00830317699453897\n",
      "mean epoch loss: 0.008348076459434297\n",
      "saved model from epoch 846\n",
      "mean epoch loss: 0.008206297653830713\n",
      "mean epoch loss: 0.008201780118462112\n",
      "mean epoch loss: 0.008290666497002046\n",
      "saved model from epoch 849\n",
      "mean epoch loss: 0.008300295751541852\n",
      "mean epoch loss: 0.008226195003630386\n",
      "mean epoch loss: 0.008175889309495688\n",
      "saved model from epoch 852\n",
      "mean epoch loss: 0.008209470100700856\n",
      "mean epoch loss: 0.00818139613709516\n",
      "mean epoch loss: 0.008327802958794766\n",
      "saved model from epoch 855\n",
      "mean epoch loss: 0.008191038978596528\n",
      "mean epoch loss: 0.008198175387870934\n",
      "mean epoch loss: 0.008159643670337068\n",
      "saved model from epoch 858\n",
      "mean epoch loss: 0.00820386495648159\n",
      "mean epoch loss: 0.008153023343119356\n",
      "mean epoch loss: 0.008239439657578866\n",
      "saved model from epoch 861\n",
      "mean epoch loss: 0.00820452148715655\n",
      "mean epoch loss: 0.008275400826500521\n",
      "mean epoch loss: 0.008215394171161784\n",
      "saved model from epoch 864\n",
      "mean epoch loss: 0.008191063596556584\n",
      "mean epoch loss: 0.008215272162730495\n",
      "mean epoch loss: 0.008177753004969823\n",
      "saved model from epoch 867\n",
      "mean epoch loss: 0.008137082515491379\n",
      "mean epoch loss: 0.00815501699431075\n",
      "mean epoch loss: 0.008189976349886921\n",
      "saved model from epoch 870\n",
      "mean epoch loss: 0.008129977279653151\n",
      "mean epoch loss: 0.008167933191483219\n",
      "mean epoch loss: 0.008219966685606374\n",
      "saved model from epoch 873\n",
      "mean epoch loss: 0.008284086335657371\n",
      "mean epoch loss: 0.008146753989987904\n",
      "mean epoch loss: 0.008158978405925962\n",
      "saved model from epoch 876\n",
      "mean epoch loss: 0.008124231629901462\n",
      "mean epoch loss: 0.008164013901518451\n",
      "mean epoch loss: 0.008183531530408395\n",
      "saved model from epoch 879\n",
      "mean epoch loss: 0.00823149848729372\n",
      "mean epoch loss: 0.008136653351700968\n",
      "mean epoch loss: 0.008171904262983136\n",
      "saved model from epoch 882\n",
      "mean epoch loss: 0.008097496804677778\n",
      "mean epoch loss: 0.008150117580468456\n",
      "mean epoch loss: 0.00816284556252261\n",
      "saved model from epoch 885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean epoch loss: 0.008145957812666893\n",
      "mean epoch loss: 0.008147001256131464\n",
      "mean epoch loss: 0.008166809700843361\n",
      "saved model from epoch 888\n",
      "mean epoch loss: 0.008104405345188246\n",
      "mean epoch loss: 0.008157303960373005\n",
      "mean epoch loss: 0.008114455112566551\n",
      "saved model from epoch 891\n",
      "mean epoch loss: 0.008061356951172154\n",
      "mean epoch loss: 0.008161701380999552\n",
      "mean epoch loss: 0.00808633465009431\n",
      "saved model from epoch 894\n",
      "mean epoch loss: 0.008100048990713225\n",
      "mean epoch loss: 0.008163053242282736\n",
      "mean epoch loss: 0.008106735669490365\n",
      "saved model from epoch 897\n",
      "mean epoch loss: 0.008128763952602943\n",
      "mean epoch loss: 0.008136103809293773\n",
      "mean epoch loss: 0.00806673120500313\n",
      "saved model from epoch 900\n",
      "mean epoch loss: 0.008161956992828184\n",
      "mean epoch loss: 0.008067754619858331\n",
      "mean epoch loss: 0.008100910712447432\n",
      "saved model from epoch 903\n",
      "mean epoch loss: 0.008053426341050201\n",
      "mean epoch loss: 0.00807325385717882\n",
      "mean epoch loss: 0.008119336132787995\n",
      "saved model from epoch 906\n",
      "mean epoch loss: 0.00808255501712362\n",
      "mean epoch loss: 0.008037965346334709\n",
      "mean epoch loss: 0.00811227200449341\n",
      "saved model from epoch 909\n",
      "mean epoch loss: 0.008021220492406025\n",
      "mean epoch loss: 0.008040568103185958\n",
      "mean epoch loss: 0.00803419320533673\n",
      "saved model from epoch 912\n",
      "mean epoch loss: 0.008005089261051682\n",
      "mean epoch loss: 0.008136919549562865\n",
      "mean epoch loss: 0.008029923443165091\n",
      "saved model from epoch 915\n",
      "mean epoch loss: 0.008095325006999903\n",
      "mean epoch loss: 0.008144745323807\n",
      "mean epoch loss: 0.00812149675976899\n",
      "saved model from epoch 918\n",
      "mean epoch loss: 0.008036801829520199\n",
      "mean epoch loss: 0.008067349882589446\n",
      "mean epoch loss: 0.008051976954771414\n",
      "saved model from epoch 921\n",
      "mean epoch loss: 0.008021960510975784\n",
      "mean epoch loss: 0.008150727488100529\n",
      "mean epoch loss: 0.008071267009816236\n",
      "saved model from epoch 924\n",
      "mean epoch loss: 0.008034071947137515\n",
      "mean epoch loss: 0.008087598904967307\n",
      "mean epoch loss: 0.008024304401543406\n",
      "saved model from epoch 927\n",
      "mean epoch loss: 0.008028952456596825\n",
      "mean epoch loss: 0.008060895625708832\n",
      "mean epoch loss: 0.008018703334447411\n",
      "saved model from epoch 930\n",
      "mean epoch loss: 0.008077111286628578\n",
      "mean epoch loss: 0.008051052135932777\n",
      "mean epoch loss: 0.008055440574470494\n",
      "saved model from epoch 933\n",
      "mean epoch loss: 0.008038046811189916\n",
      "mean epoch loss: 0.00803684118307299\n",
      "mean epoch loss: 0.007948345835838052\n",
      "saved model from epoch 936\n",
      "mean epoch loss: 0.00808537771097488\n",
      "mean epoch loss: 0.007968001698868143\n",
      "mean epoch loss: 0.007987568501590027\n",
      "saved model from epoch 939\n",
      "mean epoch loss: 0.008043680288311508\n",
      "mean epoch loss: 0.00797774600279\n",
      "mean epoch loss: 0.007991682996766435\n",
      "saved model from epoch 942\n",
      "mean epoch loss: 0.007996913775180777\n",
      "mean epoch loss: 0.008032245613220666\n",
      "mean epoch loss: 0.007985232056428988\n",
      "saved model from epoch 945\n",
      "mean epoch loss: 0.00802333876490593\n",
      "mean epoch loss: 0.007941813798000415\n",
      "mean epoch loss: 0.008051445588676466\n",
      "saved model from epoch 948\n",
      "mean epoch loss: 0.007917359797284007\n",
      "mean epoch loss: 0.007923859130177234\n",
      "mean epoch loss: 0.007963098901220494\n",
      "saved model from epoch 951\n",
      "mean epoch loss: 0.00799607838400536\n",
      "mean epoch loss: 0.007944592186767194\n",
      "mean epoch loss: 0.00794327679193682\n",
      "saved model from epoch 954\n",
      "mean epoch loss: 0.00795621624112957\n",
      "mean epoch loss: 0.007972321912853254\n",
      "mean epoch loss: 0.007988562807440758\n",
      "saved model from epoch 957\n",
      "mean epoch loss: 0.007910690208276113\n",
      "mean epoch loss: 0.007946197248788343\n",
      "mean epoch loss: 0.007942989701405168\n",
      "saved model from epoch 960\n",
      "mean epoch loss: 0.007911822060123086\n",
      "mean epoch loss: 0.007901964781598911\n",
      "mean epoch loss: 0.007936646080472403\n",
      "saved model from epoch 963\n",
      "mean epoch loss: 0.008002754704405864\n",
      "mean epoch loss: 0.007911743570326103\n",
      "mean epoch loss: 0.00787720434471137\n",
      "saved model from epoch 966\n",
      "mean epoch loss: 0.00797874407014913\n",
      "mean epoch loss: 0.00787859462822477\n",
      "mean epoch loss: 0.007907072444342904\n",
      "saved model from epoch 969\n",
      "mean epoch loss: 0.007909510915891992\n",
      "mean epoch loss: 0.007925826259371308\n",
      "mean epoch loss: 0.007898100310315688\n",
      "saved model from epoch 972\n",
      "mean epoch loss: 0.007906758764551745\n",
      "mean epoch loss: 0.007996287652187878\n",
      "mean epoch loss: 0.007965039772291979\n",
      "saved model from epoch 975\n",
      "mean epoch loss: 0.00786056252092951\n",
      "mean epoch loss: 0.008002852027614912\n",
      "mean epoch loss: 0.007865179061061807\n",
      "saved model from epoch 978\n",
      "mean epoch loss: 0.007769254667477475\n",
      "mean epoch loss: 0.007926561683416367\n",
      "mean epoch loss: 0.00785800147180756\n",
      "saved model from epoch 981\n",
      "mean epoch loss: 0.007842786310033666\n",
      "mean epoch loss: 0.007845747688164314\n",
      "mean epoch loss: 0.007865620839099089\n",
      "saved model from epoch 984\n",
      "mean epoch loss: 0.007857036549184057\n",
      "mean epoch loss: 0.007842528344028526\n",
      "mean epoch loss: 0.007873354303754038\n",
      "saved model from epoch 987\n",
      "mean epoch loss: 0.007884475205921464\n",
      "mean epoch loss: 0.007929236436676647\n",
      "mean epoch loss: 0.007945009331322379\n",
      "saved model from epoch 990\n",
      "mean epoch loss: 0.007856216167824136\n",
      "mean epoch loss: 0.00786497900262475\n",
      "mean epoch loss: 0.007855559093877673\n",
      "saved model from epoch 993\n",
      "mean epoch loss: 0.007842756254184577\n"
     ]
    }
   ],
   "source": [
    "#first index is parameter run\n",
    "#second is fold\n",
    "#third is epoch\n",
    "model_errors = []\n",
    "model_errors_path_list = []\n",
    "\n",
    "#first index is parameter run\n",
    "#second is fold\n",
    "loss_curves = []\n",
    "loss_path_list = []\n",
    "par_i = 0\n",
    "\"\"\"Perform training for each parameter option in parameter_selector\"\"\"\n",
    "for hyper_parameters in parameter_selector:\n",
    "    \n",
    "    epochs = max(val_epochs)\n",
    "    input_size = len(pred_attributes)\n",
    "    output_size = len(target_attributes)\n",
    "    \n",
    "    \"\"\"Read in parameters from parameter options\"\"\"\n",
    "    lr=hyper_parameters[\"lr\"]\n",
    "    batch_size = hyper_parameters[\"batch_size\"]\n",
    "    act_func = hyper_parameters[\"act_func\"]\n",
    "    loss_func = hyper_parameters[\"loss_func\"]\n",
    "    dropout = hyper_parameters[\"dropout\"]\n",
    "    p = hyper_parameters[\"p_dropout\"]\n",
    "    bias = hyper_parameters[\"bias\"]\n",
    "\n",
    "    lw = hyper_parameters[\"layer_width\"]\n",
    "    hl = hyper_parameters[\"hidden_layers\"]\n",
    "    layer = nn.Linear\n",
    "\n",
    "    \"\"\"\n",
    "    This list \"net_struct\" can be loaded into the constructor of the Net neural network class, to automatically generate the network structure\n",
    "    type = pointer to the layer function'\n",
    "    layer_pars = parameters which must be given to the layer function in order to initialize it\n",
    "    act_func = activation function to be applied directly after feeding to the corresponding layer\n",
    "    dropout = certain neurons can be dropped out if specified\n",
    "    \"\"\"\n",
    "    \n",
    "    net_struct = []\n",
    "    net_struct.append( {\"type\": layer, \"layer_pars\": {\"in_features\": input_size, \"out_features\": lw}, \"act_func\": act_func, \"bias\": bias} )\n",
    "    if dropout is not None:    \n",
    "        net_struct.append( {\"type\": dropout, \"layer_pars\": {\"p\": p }} )\n",
    "    if hl > 1:\n",
    "        for num_layer in range(hl-1):\n",
    "                net_struct.append( {\"type\": layer, \"layer_pars\": {\"in_features\": lw, \"out_features\": lw}, \"act_func\": act_func, \"bias\": bias} )\n",
    "    net_struct.append( {\"type\": layer, \"layer_pars\": {\"in_features\": lw, \"out_features\": output_size}, \"bias\": bias} )\n",
    "    \n",
    "    \"\"\"Choose between k-fold cross validation and hold out validation\"\"\"\n",
    "    \"\"\"Sections below the !!!HOLDOUT!!! or !!!KFOLD!!! marker should be commented in or out respectively\"\"\"\n",
    "    \"\"\"For this problem k-fold woiuld be overkill/redundant\"\"\"\n",
    "    \n",
    "    \"\"\"!!!HOLDOUT!!!\"\"\"\n",
    "    \"\"\"Randomize training and validation data points\"\"\"\n",
    "    split_ratio = {\"train\" : 0.7, \"val\" : 0.3, \"test\" : 0.0}\n",
    "    split_indices = create_index_split(dataset_size=dataset.get_length(), split_ratio=split_ratio, shuffle=True, np_random_seed=42)\n",
    "    \n",
    "    #for functional regression\n",
    "    \"\"\"Order training and validation data points\"\"\"\n",
    "    #split_indices = {}\n",
    "    #split_indices[\"train\"] = range(0,dataset.get_length(),2)\n",
    "    #split_indices[\"val\"] = range(1,dataset.get_length()+1,2)\n",
    "    \"\"\"\n",
    "    Training\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"!!!HOLDOUT!!!\"\"\"\n",
    "    \n",
    "    indices = []\n",
    "    indices.append([split_indices[\"train\"], split_indices[\"val\"]])\n",
    "    \n",
    "    \"\"\"!!!KFOLD!!!\"\"\"\n",
    "    \"\"\"\n",
    "    n_splits = hyper_parameters[\"k_fold\"]\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    indices = kf.split(dataset.df)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #par_dir = str(\"par_{}\".format(par_i))\n",
    "    #for functional regression\n",
    "    par_dir = str(\"par_{}_\".format(par_i)) + str(hyper_parameters[\"hidden_layers\"]) + \"l\" + str(hyper_parameters[\"layer_width\"]) + \"n\" \n",
    "    \n",
    "    fold_model_errors = []\n",
    "    fold_model_errors_path_list = []\n",
    "    par_loss_curves = []\n",
    "    n_split = 0\n",
    "    \n",
    "    \"\"\"Loop for each fold in k-fold\"\"\"\n",
    "    \"\"\"Otherwise this loop only runs once in holdout validation\"\"\"\n",
    "    for fold_indices in indices:\n",
    "        \n",
    "        train_indices = fold_indices[0]\n",
    "        val_indices = fold_indices[1]\n",
    "        \n",
    "        fold_loss_curve = []\n",
    "        print(\"fold {}\".format(n_split))\n",
    "        fold_dir = par_dir + \"/\" + \"fold_{}\".format(str(n_split))\n",
    "        try:\n",
    "            os.makedirs(fold_dir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "        net = torch_net_class.Net(net_struct)\n",
    "        net.set_batch_size(batch_size)\n",
    "        net.to(device)\n",
    "\n",
    "        net_parameters = net.parameters()\n",
    "        optimizer = hyper_parameters[\"optimizer\"](net_parameters, lr=lr)\n",
    "        \n",
    "        #create training log\n",
    "        train_log_file_name = fold_dir +\"/train_log.txt\"\n",
    "        train_log_file = open(train_log_file_name, \"w\")\n",
    "        train_log_file.write( \"Training log fold {} :\\n\".format(str(n_split)) )\n",
    "        net.show_layers()\n",
    "        train_log_file.write(str(net.get_net_struct()))\n",
    "\n",
    "        \"\"\"split training in train and val\"\"\"\n",
    "        train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "        val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n",
    "        #test_sampler = torch.utils.data.sampler.SubsetRandomSampler(test_indices)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "        val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "        #test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "\n",
    "        train_state_dir = fold_dir + \"/net_states\"\n",
    "        try:\n",
    "            os.makedirs(train_state_dir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "        #save_freq = 10\n",
    "        save_freq = 3\n",
    "        saved_epochs = []\n",
    "\n",
    "        train_loss_curve = []\n",
    "        val_loss_curve = []\n",
    "        \n",
    "        fold_epoch_model_errors = []\n",
    "        fold_epoch_model_errors_path_list = []\n",
    "        \"\"\"Epoch training loop\"\"\"\n",
    "        for epoch in range(0, epochs):\n",
    "            \n",
    "            batch_nr = 0\n",
    "            epoch_loss = 0.\n",
    "\n",
    "            net.train()\n",
    "            \"\"\"Feeding each minibatch\"\"\"\n",
    "            for train_mini_batch in train_loader:\n",
    "                batch_nr += 1\n",
    "                \"\"\"Actual training! See step function defined above\"\"\"\n",
    "                batch_loss, train_output = step(net, train_mini_batch, batch_size, loss_func, optimizer, epoch, batch_nr, device, train_log_file, mode=\"train\")\n",
    "                epoch_loss += batch_loss.item()\n",
    "\n",
    "            epoch_loss = epoch_loss/len(train_loader)\n",
    "            train_loss_curve.append(epoch_loss)\n",
    "            fold_loss_curve.append(epoch_loss)\n",
    "\n",
    "            print(\"mean epoch loss: {}\".format(epoch_loss))\n",
    "            train_log_file.write(\"mean epoch loss: {}\\n\".format(epoch_loss))\n",
    "\n",
    "            epoch_val_loss = 0\n",
    "\n",
    "            \"\"\"save network weights as backup\"\"\"\n",
    "            if np.mod(epoch,save_freq) == 0 or epoch == epochs:\n",
    "                train_state_epoch_file_name = \"state_epoch_{}\".format(epoch)\n",
    "                train_state = {\"epoch\" : epoch, \"state_dict\": net.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "                torch.save(train_state, train_state_dir + \"/\" + train_state_epoch_file_name )\n",
    "                saved_epochs.append(epoch)\n",
    "                print(\"saved model from epoch {}\".format(epoch))\n",
    "                train_log_file.write(\"saved model from epoch {}\\n\".format(epoch))\n",
    "        \n",
    "            \"\"\"\n",
    "            Valdation\n",
    "            \"\"\"\n",
    "            #validate for each epoch reached in val_epochs\n",
    "            #if (epoch+1) in val_epochs:\n",
    "            if (epoch) in val_epochs:\n",
    "                \n",
    "                net.eval()\n",
    "                \n",
    "                #for functional regression\n",
    "                val_feat = []\n",
    "\n",
    "                val_loss = []\n",
    "                val_pred = []\n",
    "                val_label = []\n",
    "                i = 0\n",
    "                for val_mini_batch in val_loader:\n",
    "\n",
    "                    feat_batch = val_mini_batch[0]\n",
    "                    label_batch = val_mini_batch[1]\n",
    "                    val_label.append(label_batch.numpy())\n",
    "                    \n",
    "                    #for functional regression\n",
    "                    val_feat.append(feat_batch.numpy())\n",
    "                    \"\"\"Actual validation performed here\"\"\"\n",
    "                    val_batch_loss, val_output = step(net, val_mini_batch, batch_size, loss_func, optimizer, epoch, batch_nr, device, train_log_file, mode=\"val\")\n",
    "                    val_pred.append(val_output.detach().cpu().numpy())\n",
    "                    #print(val_output)\n",
    "\n",
    "                    val_loss.append(val_batch_loss.item())\n",
    "                    #print(val_batch_loss.item())\n",
    "                    i += 1\n",
    "            \n",
    "                #for functional regression\n",
    "                val_feat_df = pd.DataFrame(np.concatenate(np.asarray(val_feat)))\n",
    "            \n",
    "                val_pred_df = pd.DataFrame(np.concatenate(np.asarray(val_pred)))\n",
    "                val_label_df = pd.DataFrame(np.concatenate(np.asarray(val_label)))\n",
    "                val_dev_df = val_label_df - val_pred_df\n",
    "                \n",
    "                \"\"\"\n",
    "                if type(inv_scaling_func) is not None:\n",
    "                    scaled_val_pred_df = inv_scaling_func(val_pred_df.copy())\n",
    "                    scaled_val_label_df = inv_scaling_func(val_label_df.copy())\n",
    "                    dev_df = scaled_val_label_df - scaled_val_pred_df\n",
    "                \"\"\"\n",
    "                val_error_df = pd.DataFrame()\n",
    "                \n",
    "                \"\"\"Create pandas dataframe with validation results\"\"\"\n",
    "                val_error_df[\"train label\"] = val_label_df[0]\n",
    "                val_error_df[\"train prediction\"] = val_pred_df[0]\n",
    "                val_error_df[\"train deviation\"] = val_dev_df[0]\n",
    "                val_error_df[\"train squared deviation\"] = val_dev_df[0] * val_dev_df[0]\n",
    "                \n",
    "                \"\"\"If necessary line can be commented out to save the validatio nerror dataframe for each parameter run, epoch, and fold\"\"\"\n",
    "                \"\"\"fold_epoch_model_errors.append(val_error_df.copy())\"\"\"\n",
    "                fold_epoch_model_errors_path = fold_dir + \"/\" +\"val_epoch_{}_pred\".format(epoch)\n",
    "                val_error_df.to_pickle(fold_epoch_model_errors_path)\n",
    "                fold_epoch_model_errors_path_list.append(fold_epoch_model_errors_path)\n",
    "                \n",
    "                #for functional regression\n",
    "                plot_dir = fold_dir + \"/\" + \"plots\"\n",
    "                try:\n",
    "                    os.makedirs(plot_dir)\n",
    "                except FileExistsError:\n",
    "                    pass\n",
    "                title = func_name + \"_act_\" + act_func.__name__ + \"_l\" + str(hl) + \"_n\" + str(lw) + \"_ep\" + str(epoch)\n",
    "                func_plot_img_file_name = plot_dir + \"/\" + title + \".png\"\n",
    "                \n",
    "                \"\"\"#plot prediction and label graphs\"\"\"\n",
    "                fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10,20))\n",
    "                \n",
    "                plt.title(title)\n",
    "                ax[0].scatter(val_feat_df.values, val_label_df.values)\n",
    "                ax[0].grid()\n",
    "                #ax[0].set_yticks(np.arange(0,25.0,0.1))\n",
    "                ax[1].scatter(val_feat_df.values, val_pred_df.values)\n",
    "                ax[1].grid()\n",
    "                #ax[1].set_yticks(np.arange(0,25.0,0.1))\n",
    "                fig.savefig(func_plot_img_file_name)\n",
    "                #plt.show(fig)\n",
    "                plt.close(fig)\n",
    "        \n",
    "        \"\"\"If necessary line can be commented out to save the validation error dataframe for each parameter run, epoch, and fold\"\"\"\n",
    "        \"\"\"fold_model_errors.append(fold_epoch_model_errors.copy())\"\"\"\n",
    "        fold_model_errors_path_list.append(fold_epoch_model_errors_path_list)\n",
    "        par_loss_curves.append(fold_loss_curve)\n",
    "        \n",
    "        n_split += 1\n",
    "    \n",
    "    \"\"\"If necessary line can be commented out to save the validation error dataframe for each parameter run, epoch, and fold\"\"\"\n",
    "    \"\"\"model_errors.append(fold_model_errors.copy())\"\"\"\n",
    "    model_errors_path_list.append(fold_model_errors_path_list)\n",
    "    loss_curves.append(par_loss_curves)\n",
    "    \n",
    "    \"\"\"Save training loss curve\"\"\"\n",
    "    train_loss_img_file_name = par_dir + \"/\" + \"train_loss_par_\" + str(par_i) + \".png\"\n",
    "    x_epochs = range(epochs)\n",
    "    for fold_i in range(len(loss_curves[par_i])):\n",
    "        plt.plot(x_epochs, loss_curves[par_i][fold_i])\n",
    "    #plt.title()\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"training loss\")\n",
    "    plt.savefig(train_loss_img_file_name)\n",
    "    plt.close()\n",
    "    train_loss_txt_file_name = par_dir + \"/\" + \"train_loss_par_\" + str(par_i) + \".txt\"\n",
    "    np.savetxt(train_loss_txt_file_name, loss_curves[par_i])\n",
    "    \n",
    "    par_i += 1\n",
    "    \n",
    "train_log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_selector = cart_product(parameter_options)\n",
    "parameter_selector_list = []\n",
    "par_list_file = open(\"par_list.txt\",\"w\")\n",
    "for cart in parameter_selector:\n",
    "    #print(cart)\n",
    "    par_list_file.write(str(cart) + \"\\n\")\n",
    "parameter_selector_list.append(cart)\n",
    "\n",
    "par_list_file.close()\n",
    "#for par_i in range(len(parameter_selector_list)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
