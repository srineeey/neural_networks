{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"data set class\"\"\"\n",
    "\n",
    "class dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "    class constructor\n",
    "    typically all class variables are initialized here, but the data itself does not have to be loaded!\n",
    "    the location of features (samples) and labels are stored as indices\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, conf_file_dir, file_format, lat_size, transform=None):\n",
    "        #initialize basic dataset variables\n",
    "        #file path to file which contains all configurations\n",
    "        #inside a line of numbers rperesents one configuration\n",
    "        \"\"\"SEPARATE FILES FOR SEPARATE CONFS?\"\"\"\n",
    "        self.conf_file_dir = conf_file_dir\n",
    "        self.file_format = file_format\n",
    "        #dimension of the lattice\n",
    "        self.dim = len(lat_size)\n",
    "        #latice size given as array [z_l,y_l,x_l] for example\n",
    "        \"\"\"INDEX ORDER CONFUSING\"\"\"\n",
    "        self.lat_size = lat_size\n",
    "        #if lat_size is given in regular order x,y,z,... -> reverse it\n",
    "        #self.lat_size = lat_size[::-1]\n",
    "\n",
    "        #number of total sites in the lattice\n",
    "        self.n_sites = int(np.array(self.lat_size).prod())\n",
    "\n",
    "        #one file contains multiple configurations! delimiter = \\n\n",
    "        self.conf_file_paths = glob.glob(self.conf_file_dir + self.file_format)\n",
    "        \n",
    "        \n",
    "        \"\"\"read in labels (=chemical potential) from filename\"\"\"\n",
    "        self.raw_labels = np.zeros(shape=(len(self.conf_file_paths)))\n",
    "        sample_i = 0\n",
    "        for i, conf_file_path in enumerate(self.conf_file_paths):\n",
    "            #separate entire path from filename\n",
    "            file_name = conf_file_path.split(\"/\")[-1]\n",
    "            if i == sample_i: print(file_name)\n",
    "            #isolate chemical potential out of filename.  delimiter = -\n",
    "            #config-mu-id-mu_label-.ext\n",
    "            label = float(file_name.split(\"-\")[-2])\n",
    "            self.raw_labels[i] = label\n",
    "        \n",
    "        print(self.conf_file_paths[sample_i])\n",
    "        print(self.raw_labels[sample_i])\n",
    "        \n",
    "        self.length = len(self.raw_labels)\n",
    "\n",
    "        #define custom transform\n",
    "        if transform == \"default\":\n",
    "            \"\"\"define custom transform\"\"\"\n",
    "            default_axes = list(range(1,len(lat_size)+1))\n",
    "            #self.transform = lambda x: self.lat_trans(self.lat_rot(x, axes=default_axes, random=True, rot_par=42), axes=default_axes, random=True, trans_par=42)\n",
    "            self.transform = lambda x: self.lat_trans(x, axes=default_axes, random=True, trans_par=42)\n",
    "        elif transform != None:\n",
    "            self.transform = transform\n",
    "\n",
    "    \"\"\"function that spits out the databases length\"\"\"\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    the getitem function typically takes in an sample/label index and returns them both as a tuple (feature, label)\n",
    "    this can be in the form of numpy arrays\n",
    "    the DataLoader functions calls the getitem function in order to create a train_sampler/test_sampler list!\n",
    "    \"\"\"\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        #load features\n",
    "        #load labels\n",
    "        #for one training example\n",
    "        #and return it\n",
    "        \n",
    "        conf_file_path = self.conf_file_paths[idx]\n",
    "        label = self.raw_labels[idx]\n",
    "        #print(conf_file_path)\n",
    "        #print(label)\n",
    "        \n",
    "        load_lat_size = [2] + self.lat_size\n",
    "        #print(load_lat_size)\n",
    "        \n",
    "        #lat_links_shape = tuple(self.lat_size)\n",
    "        lat_links_shape = tuple(load_lat_size)\n",
    "        links = np.fromfile(conf_file_path, sep=\" \", dtype=int)\n",
    "        #links = np.loadtxt(conf_file_name, dtype=int)\n",
    "                \n",
    "        conf_lat_links = links.reshape(lat_links_shape)\n",
    "        #conf_lat_links = self.lat_translation(conf_lat_links, axes = [1])\n",
    "        if self.transform is not None:\n",
    "            return (self.transform(conf_lat_links), label)\n",
    "            #return (self.lat_translation(conf_lat_links, axes = [1,2]), label)\n",
    "        else:\n",
    "            return (conf_lat_links, label)\n",
    "        \n",
    "    def get_conf(self, idx):\n",
    "\n",
    "        #load features\n",
    "        #load labels\n",
    "        #for one training example\n",
    "        #and return it\n",
    "        \n",
    "        conf_file_path = self.conf_file_paths[idx]\n",
    "        label = self.raw_labels[idx]\n",
    "        #print(conf_file_path)\n",
    "        #print(label)\n",
    "        \n",
    "        load_lat_size = [2] + self.lat_size\n",
    "        #print(load_lat_size)\n",
    "        \n",
    "        #lat_links_shape = tuple(self.lat_size)\n",
    "        lat_links_shape = tuple(load_lat_size)\n",
    "        links = np.fromfile(conf_file_path, sep=\" \", dtype=int)\n",
    "        #links = np.loadtxt(conf_file_name, dtype=int)\n",
    "                \n",
    "        conf_lat_links = links.reshape(lat_links_shape)\n",
    "        #conf_lat_links = self.lat_translation(conf_lat_links, axes = [1])\n",
    "        if self.transform is not None:\n",
    "            return (self.transform(conf_lat_links), label)\n",
    "            #return (self.lat_translation(conf_lat_links, axes = [1,2]), label)\n",
    "        else:\n",
    "            return (conf_lat_links, label)\n",
    "\n",
    "\n",
    "    def get_length(self):\n",
    "        return self.length\n",
    "    \n",
    "    \"\"\"converts array stream of lattice links to an array representing the lattice\"\"\"\n",
    "    \"\"\"shape is lat_links[link_dir,z,y,x], dimensions in reverse order\"\"\"\n",
    "    def conv_links_to_lat(links, lat_size=[]):\n",
    "        dim = len(lat_size)\n",
    "        n_sites = int(lat_size.prod())\n",
    "        sites = range(n_sites)\n",
    "        lat_links_shape = [dim] + lat_size\n",
    "        lat_links_shape = tuple(lat_links_shape)\n",
    "\n",
    "        #links pointing right and up\n",
    "        links_ru = np.array(links.reshape(lat_links_shape))\n",
    "\n",
    "        #links pointing left and down\n",
    "        #are determined by neighbours and periodic boundary conditions\n",
    "        links_ld = np.zeros(lat_links_shape)\n",
    "\n",
    "        #iterate through all dimensions\n",
    "        for d in range(dim):\n",
    "            #print(d)\n",
    "            #print(int(lat_size[int(d)]))\n",
    "\n",
    "            #links_ld is given by links_rd values, but shifted by a lattice constant\n",
    "            # + periodic boudnary conditions\n",
    "            #perm is and index array that specifies how array values should be permutated or swapped\n",
    "\n",
    "            #possible indices for a particular dimension\n",
    "            perm = list(range(int(lat_size[int(d)])))\n",
    "            #shift perm indices by a lattice site and impose periodic boundary conditions\n",
    "            perm = ([perm[-1]] + perm)[:-1]\n",
    "            #print(perm)\n",
    "            perm_indices = []\n",
    "            #the index arrays for the lattice need to be specified for every dimension\n",
    "            #for all dimensions other than d, dont perform any permutations (slice(None))\n",
    "            for b in range(dim):\n",
    "                if b == d:\n",
    "                    perm_indices.append(perm)\n",
    "                else:\n",
    "                    perm_indices.append(slice(None))\n",
    "\n",
    "            #perm_indices = perm_indices[::-1]\n",
    "            #print(perm_indices)\n",
    "\n",
    "            #lattice links for a given direction d.\n",
    "            #index is -(int(d)+1) because the order of that array is reversed (due to numpy reshaping procedure)\n",
    "            links = links_ru[-(int(d)+1)]\n",
    "            #print(links)\n",
    "            #print(links[tuple(perm_indices)])\n",
    "\n",
    "            #left and downward links are given by a permuation of original links\n",
    "            links_ld[d] = links[tuple(perm_indices)]\n",
    "            #print(links_ld[d])\n",
    "\n",
    "        #reverse order of directions in which links are stored\n",
    "        #this way the order of link directions in links_ru is identical to links_ld\n",
    "        \"\"\"CHANGE ORDER OF LINKS_LD, LINKS_RU?\"\"\"\n",
    "        links_ld = links_ld[::-1]\n",
    "\n",
    "        #join all links and return enmtire lattice\n",
    "        lat_links = np.concatenate((links_ru, links_ld))\n",
    "\n",
    "        return lat_links\n",
    "\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    Scaling procedures\n",
    "    \"\"\"\n",
    "\n",
    "    def lat_trans(self, lat_links, axes=[], random=True, trans_par=42):\n",
    "        \"\"\"\n",
    "        Data augmentation: lattice translation\n",
    "        \"\"\"\n",
    "        #print(\"performing translation\")\n",
    "        lat_links_shape = lat_links.shape\n",
    "        trans_lat_links = lat_links\n",
    "        \n",
    "        for axis in range(len(lat_links_shape)):\n",
    "            #print(f\"axis {axis}\")\n",
    "            perm_indices = [slice(None)]*len(lat_links_shape)\n",
    "            if axis in axes:\n",
    "                perm = list( range(int(lat_links_shape[axis])) )\n",
    "                shift = 0\n",
    "                if random == True:\n",
    "                    \"\"\"use trans_par as random_seed?\"\"\"\n",
    "                    #np.random.seed = trans_par\n",
    "                    shift = np.random.randint(0,lat_links_shape[axis])\n",
    "                else:\n",
    "                    \"\"\"use transpar as array for translation vector\"\"\"\n",
    "                    shift = trans_par[axis]\n",
    "                #print(f\"shift {shift}\")\n",
    "                #print(perm)\n",
    "                perm = (perm + perm)[shift:shift+len(perm)]\n",
    "                #print(perm)\n",
    "            \n",
    "                perm_indices[axis] = perm\n",
    "                #print(perm_indices)\n",
    "                trans_lat_links = trans_lat_links[tuple(perm_indices)]\n",
    "        \n",
    "        return trans_lat_links\n",
    "    \n",
    "    def lat_rot(self, lat_links, axes=[], random=True, rot_par=42):\n",
    "        \"\"\"\n",
    "        Data augmentation: lattice rotation\n",
    "        \"\"\"\n",
    "        num_rot = rot_par\n",
    "        if random == True:\n",
    "            num_rot = np.random.choice([1,2,3,4])\n",
    "        new_lat_links = lat_links\n",
    "        if num_rot > 0:\n",
    "            for i in range(num_rot):\n",
    "                new_lat_links = np.rot90(new_lat_links, axes=axes)\n",
    "        \n",
    "        return new_lat_links\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf-1.120000-2-97-1.12-.dat\n",
      "new_configs/conf-1.120000-2-97-1.12-.dat\n",
      "1.12\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "conf_dir = \"new_configs/\"\n",
    "dim = 2\n",
    "lat_size = [200,10]\n",
    "#def __init__(self, conf_file_dir, file_format, lat_size, transform=None):\n",
    "conf_dataset = dataset(conf_dir, file_format=\"*.dat\",lat_size=lat_size, transform=\"default\")\n",
    "print(conf_dataset.get_length())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]]), 1.12)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_dataset.get_conf(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
