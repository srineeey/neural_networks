{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import lat_dataset\n",
    "import torch_net_class\n",
    "import utils\n",
    "\n",
    "import functools\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizing CUDA\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Utilizing CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Utilizing CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf-1.150000-2-446-1.15-.dat\n",
      "new_configs/conf-1.150000-2-446-1.15-.dat\n",
      "1.15\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load Data\n",
    "\"\"\"\n",
    "conf_file_dir = \"new_configs/\"\n",
    "file_format= \"*.dat\"\n",
    "lat_size = [200,10]\n",
    "\n",
    "dataset = lat_dataset.kl_dataset(conf_file_dir, file_format, lat_size, transform=\"default\")\n",
    "target_attributes = [\"mu\"]\n",
    "#target_attributes = [\"phase\"]\n",
    "output_attributes = [\"mu\"]\n",
    "#output_attributes = [\"order\",\"disorder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd6d5b44d50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_conf, sample_label = dataset.get_conf(0)\n",
    "k_lat_links = sample_conf[0]\n",
    "l_lat_links = sample_conf[1]\n",
    "plt.imshow(k_lat_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd63c8d1810>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(l_lat_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 200, 10], [4, 192, 8], [4, 48, 8], [8, 36, 6], [8, 9, 6], [16, 6, 4], 384, 384, 1]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HYPERPARAMETERS\n",
    "\"\"\"\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "val_epochs = [10,20,30]\n",
    "#val_epochs = [1,2]\n",
    "save_state_epochs = [10000]\n",
    "\n",
    "\n",
    "\"\"\"Manually set network structure\"\"\"\n",
    "\"\"\"\n",
    "    This list can be loaded into the constructor of the Net neural network class, to automatically generate the network structure\n",
    "    type = pointer to the layer function'\n",
    "    layer_pars = parameters which must be given to the layer function in order to initialize it\n",
    "    act_func = activation function to be applied directly after feeding to the corresponding layer\n",
    "    dropout = certain neurons cna be dropped out if specified\n",
    "\"\"\"\n",
    "\n",
    "fixed_net_struct = []\n",
    "input_size = dataset.get_input_size()\n",
    "target_size = len(target_attributes)\n",
    "#output_size = target_size\n",
    "output_size = len(output_attributes)\n",
    "\n",
    "#[ [[in_channels, out_channels],[kernel_size], stride, padding], ... ]\n",
    "#kernel_pars = [ [[input_size[0],4],[12,3],1,0], [[4,8],[12,3],1,0], [[8,16],[12,3],1,0], [[16,16],[12,3],1,0], [[16,16],[8,2],1,0] ]\n",
    "kernel_pars = [ [[input_size[0],4],[9,3],1,0], [[4,4],[4,1],[4,1],0], [[4,8],[13,3],1,0], [[8,8],[4,1],[4,1],0], [[8,16],[4,3],1,0]]\n",
    "act_func = torch.relu\n",
    "#, \"act_func\": act_func\n",
    "for i, kernel_par in enumerate(kernel_pars):\n",
    "    if i%2 == 0:\n",
    "        layer_type = nn.Conv2d\n",
    "        fixed_net_struct.append( {\"type\": layer_type, \"layer_pars\": {\"in_channels\": kernel_par[0][0], \"out_channels\": kernel_par[0][1], \"kernel_size\": kernel_par[1], \"stride\": kernel_par[2], \"padding\": kernel_par[3], \"bias\": True}} )\n",
    "    else:\n",
    "        layer_type = nn.MaxPool2d\n",
    "        #layer_type = nn.AvgPool2d\n",
    "        fixed_net_struct.append( {\"type\": layer_type, \"layer_pars\": {\"kernel_size\": kernel_par[1], \"stride\": kernel_par[2], \"padding\": kernel_par[3]}} )\n",
    "\"\"\"\n",
    "for i, kernel_par in enumerate(kernel_pars):\n",
    "        layer_type = nn.Conv2d\n",
    "        fixed_net_struct.append( {\"type\": layer_type, \"layer_pars\": {\"in_channels\": kernel_par[0][0], \"out_channels\": kernel_par[0][1], \"kernel_size\": kernel_par[1], \"stride\": kernel_par[2], \"padding\": kernel_par[3], \"bias\": True}, \"act_func\": act_func} )\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "conv_sizes = utils.calc_layer_sizes(input_size, fixed_net_struct)\n",
    "fc_input_size = np.product(conv_sizes[-1])\n",
    "fixed_net_struct.append( {\"type\": nn.Flatten, \"layer_pars\": {\"start_dim\": 1}} )    \n",
    "#fixed_net_struct.append( {\"type\": utils.Reshape, \"layer_pars\": {\"new_shape\": [-1,fc_input_size]}} )\n",
    "#fixed_net_struct.append( {\"type\": nn.Dropout, \"layer_pars\": {\"p\": 0.3 }} )\n",
    "#fixed_net_struct.append( {\"type\": nn.BatchNorm1d, \"layer_pars\": {\"num_features\": fc_input_size}} )\n",
    "fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": fc_input_size, \"out_features\": fc_input_size}, \"bias\": True, \"act_func\": act_func} )\n",
    "#fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": fc_input_size, \"out_features\": fc_input_size}, \"bias\": True, \"act_func\": act_func} )\n",
    "fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": fc_input_size, \"out_features\": output_size}, \"bias\": True, \"act_func\": act_func} )\n",
    "#fixed_net_struct.append( {\"type\": nn.Softmax, \"layer_pars\": {\"dim\": 1}} )\n",
    "#dim 0 or 1???\n",
    "#fixed_net_struct.append( {\"type\": nn.ConvTranspose2d, \"layer_pars\": {\"in_channels\": 1, \"out_channels\": 1, \"kernel_size\": [1,1], \"stride\": 1, \"padding\": 1, \"bias\": True}, \"act_func\": act_func} )\n",
    "\n",
    "layer_sizes = utils.calc_layer_sizes(input_size, fixed_net_struct)\n",
    "print(layer_sizes)\n",
    "\n",
    "\"\"\"create list of parameters manually\"\"\"\n",
    "\n",
    "hyper_parameters = {}\n",
    "#hyper_parameters[\"loss_func\"] = nn.CrossEntropyLoss\n",
    "hyper_parameters[\"loss_func\"] = nn.MSELoss\n",
    "hyper_parameters[\"optimizer\"] = optim.Adam\n",
    "hyper_parameters[\"batch_size\"] = 1 \n",
    "hyper_parameters[\"lr\"] = 0.00001\n",
    "hyper_parameters[\"net_struct\"] = fixed_net_struct\n",
    "\n",
    "hyper_parameters[\"val_method\"] = \"holdout\"\n",
    "hyper_parameters[\"val_method_pars\"] = {\"train\" : 0.9, \"val\" : 0.1, \"test\" : 0.}\n",
    "#hyper_parameters[\"val_method\"] = \"k_fold\"\n",
    "#hyper_parameters[\"val_method_pars\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = max(val_epochs)+1\n",
    "\n",
    "lr=hyper_parameters[\"lr\"]\n",
    "batch_size = hyper_parameters[\"batch_size\"]\n",
    "loss_func = hyper_parameters[\"loss_func\"]()\n",
    "net_struct = hyper_parameters[\"net_struct\"]\n",
    "val_method = hyper_parameters[\"val_method\"]\n",
    "val_method_pars = hyper_parameters[\"val_method_pars\"]\n",
    "optimizer_type = hyper_parameters[\"optimizer\"]\n",
    "\n",
    "val_pred_paths = []\n",
    "val_label_paths = []\n",
    "\n",
    "train_loss = np.zeros(epochs)\n",
    "val_loss = np.zeros(len(val_epochs))\n",
    "\n",
    "net_state_paths = []\n",
    "\n",
    "#create training log\n",
    "log_file_name = \"log.txt\"\n",
    "log_file = open(log_file_name, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding {'type': <class 'torch.nn.modules.conv.Conv2d'>, 'layer_pars': {'in_channels': 2, 'out_channels': 4, 'kernel_size': [9, 3], 'stride': 1, 'padding': 0, 'bias': True}}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.pooling.MaxPool2d'>, 'layer_pars': {'kernel_size': [4, 1], 'stride': [4, 1], 'padding': 0}}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.conv.Conv2d'>, 'layer_pars': {'in_channels': 8, 'out_channels': 8, 'kernel_size': [13, 3], 'stride': 1, 'padding': 0, 'bias': True}}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.pooling.MaxPool2d'>, 'layer_pars': {'kernel_size': [4, 1], 'stride': [4, 1], 'padding': 0}}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.conv.Conv2d'>, 'layer_pars': {'in_channels': 16, 'out_channels': 16, 'kernel_size': [4, 3], 'stride': 1, 'padding': 0, 'bias': True}}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.flatten.Flatten'>, 'layer_pars': {'start_dim': 1}}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.linear.Linear'>, 'layer_pars': {'in_features': 384, 'out_features': 384}, 'bias': True, 'act_func': <built-in method relu of type object at 0x7fd694e18be0>}\n",
      "\n",
      "Adding {'type': <class 'torch.nn.modules.linear.Linear'>, 'layer_pars': {'in_features': 384, 'out_features': 1}, 'bias': True, 'act_func': <built-in method relu of type object at 0x7fd694e18be0>}\n",
      "\n",
      "size of val set :114\n",
      "\n",
      "size of train set :910\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size 8 8 13 3, expected input[1, 4, 48, 8] to have 8 channels, but got 4 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c6a5636c5b5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;34m\"\"\"Actual training step\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_mini_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mepoch_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_nr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mbatch_nr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/qcd_ml/neural_networks/lat_cnn/utils.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(model, input_batch, output_size, loss_func, optimizer, device, mode, log_file)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mmodel_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/qcd_ml/neural_networks/lat_cnn/torch_net_class.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m#                x = x.reshape( tuple([-1] + self.layer_sizes[layer_i]) )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;31m#print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"act_func\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_struct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_struct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"act_func\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 8 8 13 3, expected input[1, 4, 48, 8] to have 8 channels, but got 4 channels instead"
     ]
    }
   ],
   "source": [
    "#tb = SummaryWriter()\n",
    "\n",
    "net = torch_net_class.Net(net_struct, dataset.get_input_size())    \n",
    "net.init_weights(torch.nn.init.xavier_normal_)\n",
    "net.set_batch_size(batch_size)\n",
    "#net.set_layer_sizes(layer_sizes)\n",
    "net.to(device)\n",
    "#net.show_layers()\n",
    "net_parameters = net.parameters()\n",
    "\n",
    "optimizer = optimizer_type(net_parameters, lr=lr)\n",
    "\n",
    "\"\"\"SPECIFY OUTSIDE FOR K-FOLD VALIDATION\"\"\"\n",
    "data_loader = utils.load_split_data(dataset=dataset, batch_size=batch_size, method=val_method, method_pars=val_method_pars, random_seed=random_seed, log_file=log_file)\n",
    "\n",
    "if val_method == \"holdout\":\n",
    "    data_loader = data_loader[0]\n",
    "    test_loader = data_loader[2]\n",
    "val_loader = data_loader[1]\n",
    "train_loader = data_loader[0]\n",
    "\n",
    "val_dir = \"val/\"\n",
    "try:\n",
    "    os.makedirs(val_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "train_state_dir = \"net_states/\"\n",
    "try:\n",
    "    os.makedirs(train_state_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "epoch = 0\n",
    "val_i = 0\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    batch_nr = 0\n",
    "    epoch_loss = np.zeros(len(train_loader))\n",
    "    \n",
    "    \"\"\"Actual training step\"\"\"\n",
    "    for train_mini_batch in train_loader:\n",
    "        batch_loss, train_output = utils.step(net, train_mini_batch, output_size, loss_func, optimizer, device, mode=\"train\", log_file=log_file)\n",
    "        epoch_loss[batch_nr] = batch_loss.item()\n",
    "        batch_nr += 1\n",
    "    mean_epoch_loss = epoch_loss.mean()\n",
    "    train_loss[epoch] = mean_epoch_loss\n",
    "    print(f\"mean epoch {epoch} train loss: {mean_epoch_loss}\\n\")\n",
    "    \n",
    "    \n",
    "    \"\"\"save the neural networks state\"\"\"\n",
    "    if epoch in save_state_epochs:\n",
    "        train_state_epoch_file_path = train_state_dir + f\"state_epoch_{epoch}\"\n",
    "        train_state = {\"epoch\" : epoch, \"state_dict\": net.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "        torch.save(train_state, train_state_epoch_file_path)\n",
    "        net_state_paths.append(train_state_epoch_file_path)\n",
    "        print(f\"saved model from epoch {epoch}\")\n",
    "        \n",
    "    \"\"\"\n",
    "    Validation\n",
    "    \"\"\"\n",
    "    if epoch in val_epochs:\n",
    "        val_label = []\n",
    "        val_pred = []\n",
    "        \n",
    "        val_batch_nr = 0\n",
    "        val_epoch_loss = np.zeros(len(val_loader))\n",
    "        \n",
    "        for val_mini_batch in val_loader:\n",
    "            label_batch = val_mini_batch[1]\n",
    "            val_label.append(label_batch.detach().cpu().numpy())\n",
    "            val_batch_loss, val_output = utils.step(net, val_mini_batch, output_size, loss_func, optimizer, device, mode=\"val\", log_file=log_file)\n",
    "            val_epoch_loss[val_batch_nr] = val_batch_loss.item()\n",
    "            val_pred.append(val_output.detach().cpu().numpy())\n",
    "            \"\"\"\n",
    "            class_batch_pred = []\n",
    "            #print(val_output)\n",
    "            for val in val_output:\n",
    "                class_index = val.argmax().detach().cpu()\n",
    "                class_batch_pred.append(class_index)\n",
    "            #print(class_batch_pred)\n",
    "            val_pred.append(class_batch_pred)\n",
    "            \"\"\"\n",
    "            val_batch_nr += 1\n",
    "            \n",
    "        mean_val_epoch_loss = val_epoch_loss.mean()\n",
    "        val_loss[val_i] = mean_val_epoch_loss\n",
    "        print(f\"mean epoch {epoch} val loss: {mean_val_epoch_loss}\\n\")\n",
    "        \n",
    "        val_i += 1\n",
    "        \n",
    "        val_pred_path = val_dir + \"/\" + f\"val_epoch_{epoch}_pred\"\n",
    "        val_label_path = val_dir + \"/\" + f\"val_epoch_{epoch}_labels\"\n",
    "        #print(np.array(functools.reduce(operator.iconcat, val_pred, [])))\n",
    "        np.array(functools.reduce(operator.iconcat, val_pred, [])).tofile(val_pred_path, sep=\" \")\n",
    "        np.array(functools.reduce(operator.iconcat, val_label, [])).tofile(val_label_path, sep=\" \")\n",
    "        #np.array(val_pred).tofile(val_pred_path)\n",
    "        #np.array(val_label).tofile(val_pred_label)\n",
    "        \n",
    "        val_pred_paths.append(val_pred_path)\n",
    "        val_label_paths.append(val_label_path)\n",
    "        \n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot training loss curve and save as image\"\"\"\n",
    "train_loss_img_file_name = \"train_loss.png\"\n",
    "x_epochs = range(epochs)\n",
    "plt.plot(x_epochs, train_loss)\n",
    "#plt.title()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"training loss\")\n",
    "plt.savefig(train_loss_img_file_name)\n",
    "plt.show()\n",
    "plt.close()\n",
    "train_loss_txt_file_name = \"train_loss.txt\"\n",
    "np.savetxt(train_loss_txt_file_name, train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = np.fromfile(val_label_paths[-1], sep=\" \")\n",
    "val_pred = np.fromfile(val_pred_paths[-1], sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Print MSE\"\"\"\n",
    "print(np.array(val_labels).shape)\n",
    "print(np.array(val_pred).shape)\n",
    "val_df = pd.DataFrame(np.array([val_labels,val_pred]).T)\n",
    "val_df.columns = [\"label\", \"pred\"]\n",
    "val_df[\"dev\"] = abs(val_df[\"label\"] - val_df[\"pred\"]) \n",
    "val_df[\"mse\"] = (val_df[\"label\"] - val_df[\"pred\"])**2\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = sklearn.metrics.confusion_matrix(val_labels,val_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_conf_mat = conf_mat/conf_mat.sum(axis=1)\n",
    "norm_conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(norm_conf_mat,cmap=\"YlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = sklearn.metrics.accuracy_score(val_labels, val_pred)\n",
    "rec = sklearn.metrics.recall_score(val_labels, val_pred, average=None)\n",
    "prec = sklearn.metrics.precision_score(val_labels, val_pred, average=None)\n",
    "\n",
    "print(\"Accuracy:\\n {}\".format(acc))\n",
    "\n",
    "print(\"Recall:\\n {}\".format(rec))\n",
    "print(\"averaged recall: {} +- {}\".format(rec.mean(), rec.std()) )\n",
    "\n",
    "print(\"Precision:\\n {}\".format(prec))\n",
    "print(\"averaged precision: {} +- {}\".format(prec.mean(), prec.std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
