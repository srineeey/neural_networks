{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sklearn\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1,\"/home/sbulusu/qcd_ml/neural_networks/libs/\")\n",
    "\n",
    "import lat_dataset\n",
    "import aenc_torch_net_class\n",
    "import torch_net_class\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizing CUDA\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Utilizing CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Utilizing CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2   2  10 200]\n",
      "conf-1.030000-1-12-1.03-.dat\n",
      "/media/data/sbulusu/datasets/kl_config/conf-1.030000-1-12-1.03-.dat\n",
      "1.03\n",
      "setting default axes for transforms to [2, 3]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load Data\n",
    "\"\"\"\n",
    "conf_file_dir = \"/media/data/sbulusu/datasets/kl_config/\"\n",
    "file_format= \"*.dat\"\n",
    "lat_size = [10,200]\n",
    "dim = len(lat_size)\n",
    "conf_size = np.concatenate(([2],[dim],lat_size))\n",
    "print(conf_size)\n",
    "dataset = lat_dataset.kl_dataset(conf_file_dir, file_format, conf_size, transform=\"default\")\n",
    "target_attributes = [\"mu\"]\n",
    "#target_attributes = [\"phase\"]\n",
    "output_attributes = [\"mu\"]\n",
    "#output_attributes = [\"order\",\"disorder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f03b34385d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_conf, sample_label = dataset.get_conf(0)\n",
    "k_lat_links = sample_conf[0]\n",
    "l_lat_links = sample_conf[1]\n",
    "plt.imshow(k_lat_links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f031a22f0d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(l_lat_links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative layer size found in [8, -12, 0]!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f56aebbe1adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \"\"\"\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mconv_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_layer_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_net_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mfc_input_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mfixed_net_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"layer_pars\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"start_dim\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/qcd_ml/neural_networks/libs/utils.py\u001b[0m in \u001b[0;36mcalc_layer_sizes\u001b[0;34m(input_shape, net_struct, log_file)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m#append newly calculated neuron activation shape to layer_sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_layer_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Negative layer size found in {new_layer_size}!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0mlayer_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_layer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative layer size found in [8, -12, 0]!"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HYPERPARAMETERS\n",
    "\"\"\"\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "val_epochs = [5,10,20,30]\n",
    "#val_epochs = [1,2]\n",
    "save_state_epochs = [10000]\n",
    "\n",
    "\n",
    "\"\"\"Manually set network structure\"\"\"\n",
    "\"\"\"\n",
    "    This list can be loaded into the constructor of the Net neural network class, to automatically generate the network structure\n",
    "    type = pointer to the layer function'\n",
    "    layer_pars = parameters which must be given to the layer function in order to initialize it\n",
    "    act_func = activation function to be applied directly after feeding to the corresponding layer\n",
    "    dropout = certain neurons cna be dropped out if specified\n",
    "\"\"\"\n",
    "\n",
    "fixed_net_struct = []\n",
    "input_size = dataset.get_input_size()\n",
    "target_size = len(target_attributes)\n",
    "#output_size = target_size\n",
    "output_size = len(output_attributes)\n",
    "\n",
    "\"\"\"\n",
    "#[ [[in_channels, out_channels],[kernel_size], stride, padding], ... ]\n",
    "#kernel_pars = [ [[input_size[0],4],[12,3],1,0], [[4,8],[12,3],1,0], [[8,16],[12,3],1,0], [[16,16],[12,3],1,0], [[16,16],[8,2],1,0] ]\n",
    "kernel_pars = [ [[input_size[0],8],[9,3],1,0], [[4,4],[4,1],[4,1],0], [[4,8],[13,3],1,0], [[8,8],[4,1],[4,1],0], [[8,16],[4,3],1,0]]\n",
    "act_func = torch.relu\n",
    "#, \"act_func\": act_func\n",
    "for i, kernel_par in enumerate(kernel_pars):\n",
    "    if i%2 == 0:\n",
    "        layer_type = nn.Conv2d\n",
    "        fixed_net_struct.append( {\"type\": layer_type, \"layer_pars\": {\"in_channels\": kernel_par[0][0], \"out_channels\": kernel_par[0][1], \"kernel_size\": kernel_par[1], \"stride\": kernel_par[2], \"padding\": kernel_par[3], \"bias\": True}} )\n",
    "    else:\n",
    "        #layer_type = nn.MaxPool2d\n",
    "        layer_type = nn.AvgPool2d\n",
    "        fixed_net_struct.append( {\"type\": layer_type, \"layer_pars\": {\"kernel_size\": kernel_par[1], \"stride\": kernel_par[2], \"padding\": kernel_par[3]}} )\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "for i, kernel_par in enumerate(kernel_pars):\n",
    "        layer_type = nn.Conv2d\n",
    "        fixed_net_struct.append( {\"type\": layer_type, \"layer_pars\": {\"in_channels\": kernel_par[0][0], \"out_channels\": kernel_par[0][1], \"kernel_size\": kernel_par[1], \"stride\": kernel_par[2], \"padding\": kernel_par[3], \"bias\": True}, \"act_func\": act_func} )\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "conv_sizes = utils.calc_layer_sizes(input_size, fixed_net_struct)\n",
    "fc_input_size = np.product(conv_sizes[-1])\n",
    "\"\"\"\n",
    "\n",
    "#fixed_net_struct.append( {\"type\": nn.Flatten, \"layer_pars\": {\"start_dim\": 1}} )\n",
    "#fixed_net_struct.append( {\"type\": utils.Reshape, \"layer_pars\": {\"new_shape\": [-1,fc_input_size]}} )\n",
    "#fixed_net_struct.append( {\"type\": nn.Dropout, \"layer_pars\": {\"p\": 0.3 }} )\n",
    "#fixed_net_struct.append( {\"type\": nn.BatchNorm1d, \"layer_pars\": {\"num_features\": fc_input_size}} )\n",
    "#fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": fc_input_size, \"out_features\": fc_input_size}, \"bias\": True, \"act_func\": act_func} )\n",
    "#fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": fc_input_size, \"out_features\": fc_input_size}, \"bias\": True, \"act_func\": act_func} )\n",
    "#fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": fc_input_size, \"out_features\": output_size}, \"bias\": True, \"act_func\": act_func} )\n",
    "#fixed_net_struct.append( {\"type\": nn.Softmax, \"layer_pars\": {\"dim\": 1}} )\n",
    "#dim 0 or 1???\n",
    "#fixed_net_struct.append( {\"type\": nn.ConvTranspose2d, \"layer_pars\": {\"in_channels\": 1, \"out_channels\": 1, \"kernel_size\": [1,1], \"stride\": 1, \"padding\": 1, \"bias\": True}, \"act_func\": act_func} )\n",
    "\n",
    "fixed_net_struct.append( {\"type\": nn.Flatten, \"layer_pars\": {\"start_dim\": 1}} )\n",
    "fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": int(np.prod(input_size)), \"out_features\": 2000}, \"bias\": True, \"act_func\": act_func} )\n",
    "fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": 2000, \"out_features\": 1000}, \"bias\": True, \"act_func\": act_func} )\n",
    "fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": 1000, \"out_features\": 100}, \"bias\": True, \"act_func\": act_func} )\n",
    "fixed_net_struct.append( {\"type\": nn.Linear, \"layer_pars\": {\"in_features\": 100, \"out_features\": 1}, \"bias\": True, \"act_func\": act_func} )\n",
    "\n",
    "layer_sizes = utils.calc_layer_sizes(input_size, fixed_net_struct)\n",
    "print(layer_sizes)\n",
    "\n",
    "\"\"\"create list of parameters manually\"\"\"\n",
    "\n",
    "hyper_parameters = {}\n",
    "#hyper_parameters[\"loss_func\"] = nn.CrossEntropyLoss\n",
    "hyper_parameters[\"loss_func\"] = nn.MSELoss\n",
    "hyper_parameters[\"optimizer\"] = optim.Adam\n",
    "hyper_parameters[\"batch_size\"] = 1 \n",
    "hyper_parameters[\"lr\"] = 0.00001\n",
    "hyper_parameters[\"net_struct\"] = fixed_net_struct\n",
    "\n",
    "hyper_parameters[\"val_method\"] = \"holdout\"\n",
    "hyper_parameters[\"val_method_pars\"] = {\"train\" : 0.9, \"val\" : 0.1, \"test\" : 0.}\n",
    "#hyper_parameters[\"val_method\"] = \"k_fold\"\n",
    "#hyper_parameters[\"val_method_pars\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = max(val_epochs)+1\n",
    "\n",
    "lr=hyper_parameters[\"lr\"]\n",
    "batch_size = hyper_parameters[\"batch_size\"]\n",
    "loss_func = hyper_parameters[\"loss_func\"]()\n",
    "net_struct = hyper_parameters[\"net_struct\"]\n",
    "val_method = hyper_parameters[\"val_method\"]\n",
    "val_method_pars = hyper_parameters[\"val_method_pars\"]\n",
    "optimizer_type = hyper_parameters[\"optimizer\"]\n",
    "\n",
    "val_pred_paths = []\n",
    "val_label_paths = []\n",
    "\n",
    "train_loss = np.zeros(epochs)\n",
    "val_loss = np.zeros(len(val_epochs))\n",
    "\n",
    "net_state_paths = []\n",
    "\n",
    "#create training log\n",
    "log_file_name = \"log.txt\"\n",
    "log_file = open(log_file_name, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tb = SummaryWriter()\n",
    "\n",
    "net = torch_net_class.Net(net_struct, dataset.get_input_size())    \n",
    "net.init_weights(torch.nn.init.xavier_normal_)\n",
    "net.set_batch_size(batch_size)\n",
    "#net.set_layer_sizes(layer_sizes)\n",
    "net.to(device)\n",
    "#net.show_layers()\n",
    "net_parameters = net.parameters()\n",
    "\n",
    "optimizer = optimizer_type(net_parameters, lr=lr)\n",
    "\n",
    "\"\"\"SPECIFY OUTSIDE FOR K-FOLD VALIDATION\"\"\"\n",
    "data_loader = utils.load_split_data(dataset=dataset, batch_size=batch_size, method=val_method, method_pars=val_method_pars, random_seed=random_seed, log_file=log_file)\n",
    "\n",
    "if val_method == \"holdout\":\n",
    "    data_loader = data_loader[0]\n",
    "    test_loader = data_loader[2]\n",
    "val_loader = data_loader[1]\n",
    "train_loader = data_loader[0]\n",
    "\n",
    "val_dir = \"val/\"\n",
    "try:\n",
    "    os.makedirs(val_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "train_state_dir = \"net_states/\"\n",
    "try:\n",
    "    os.makedirs(train_state_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "epoch = 0\n",
    "val_i = 0\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    batch_nr = 0\n",
    "    epoch_loss = np.zeros(len(train_loader))\n",
    "    \n",
    "    \"\"\"Actual training step\"\"\"\n",
    "    for train_mini_batch in train_loader:\n",
    "        batch_loss, train_output = utils.step(net, train_mini_batch, output_size, loss_func, optimizer, device, mode=\"train\", log_file=log_file)\n",
    "        epoch_loss[batch_nr] = batch_loss.item()\n",
    "        batch_nr += 1\n",
    "    mean_epoch_loss = epoch_loss.mean()\n",
    "    train_loss[epoch] = mean_epoch_loss\n",
    "    print(f\"mean epoch {epoch} train loss: {mean_epoch_loss}\\n\")\n",
    "    \n",
    "    \n",
    "    \"\"\"save the neural networks state\"\"\"\n",
    "    if epoch in save_state_epochs:\n",
    "        train_state_epoch_file_path = train_state_dir + f\"state_epoch_{epoch}\"\n",
    "        train_state = {\"epoch\" : epoch, \"state_dict\": net.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "        torch.save(train_state, train_state_epoch_file_path)\n",
    "        net_state_paths.append(train_state_epoch_file_path)\n",
    "        print(f\"saved model from epoch {epoch}\")\n",
    "        \n",
    "    \"\"\"\n",
    "    Validation\n",
    "    \"\"\"\n",
    "    if epoch in val_epochs:\n",
    "        val_label = []\n",
    "        val_pred = []\n",
    "        \n",
    "        val_batch_nr = 0\n",
    "        val_epoch_loss = np.zeros(len(val_loader))\n",
    "        \n",
    "        for val_mini_batch in val_loader:\n",
    "            label_batch = val_mini_batch[1]\n",
    "            val_label.append(label_batch.detach().cpu().numpy())\n",
    "            val_batch_loss, val_output = utils.step(net, val_mini_batch, output_size, loss_func, optimizer, device, mode=\"val\", log_file=log_file)\n",
    "            val_epoch_loss[val_batch_nr] = val_batch_loss.item()\n",
    "            val_pred.append(val_output.detach().cpu().numpy())\n",
    "            \"\"\"\n",
    "            class_batch_pred = []\n",
    "            #print(val_output)\n",
    "            for val in val_output:\n",
    "                class_index = val.argmax().detach().cpu()\n",
    "                class_batch_pred.append(class_index)\n",
    "            #print(class_batch_pred)\n",
    "            val_pred.append(class_batch_pred)\n",
    "            \"\"\"\n",
    "            val_batch_nr += 1\n",
    "            \n",
    "        mean_val_epoch_loss = val_epoch_loss.mean()\n",
    "        val_loss[val_i] = mean_val_epoch_loss\n",
    "        print(f\"mean epoch {epoch} val loss: {mean_val_epoch_loss}\\n\")\n",
    "        \n",
    "        val_i += 1\n",
    "        \n",
    "        val_pred_path = val_dir + \"/\" + f\"val_epoch_{epoch}_pred\"\n",
    "        val_label_path = val_dir + \"/\" + f\"val_epoch_{epoch}_labels\"\n",
    "        #print(np.array(functools.reduce(operator.iconcat, val_pred, [])))\n",
    "        np.array(functools.reduce(operator.iconcat, val_pred, [])).tofile(val_pred_path, sep=\" \")\n",
    "        np.array(functools.reduce(operator.iconcat, val_label, [])).tofile(val_label_path, sep=\" \")\n",
    "        #np.array(val_pred).tofile(val_pred_path)\n",
    "        #np.array(val_label).tofile(val_pred_label)\n",
    "        \n",
    "        val_pred_paths.append(val_pred_path)\n",
    "        val_label_paths.append(val_label_path)\n",
    "        \n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot training loss curve and save as image\"\"\"\n",
    "loss_img_file_name = \"train_loss.png\"\n",
    "x_epochs = range(epochs)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_epochs, train_loss, label=\"train loss\")\n",
    "ax.plot(val_epochs, val_loss, label=\"val loss\")\n",
    "leg = ax.legend()\n",
    "#plt.title()\n",
    "plt.xlabel(\"epoch\")\n",
    "#plt.ylabel(\"loss\")\n",
    "plt.savefig(loss_img_file_name)\n",
    "plt.show()\n",
    "plt.close()\n",
    "train_loss_txt_file_name = \"train_loss.txt\"\n",
    "np.savetxt(train_loss_txt_file_name, train_loss)\n",
    "val_loss_txt_file_name = \"val_loss.txt\"\n",
    "np.savetxt(val_loss_txt_file_name, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = np.fromfile(val_label_paths[-1], sep=\" \")\n",
    "val_pred = np.fromfile(val_pred_paths[-1], sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Print MSE\"\"\"\n",
    "print(np.array(val_labels).shape)\n",
    "print(np.array(val_pred).shape)\n",
    "val_df = pd.DataFrame(np.array([val_labels,val_pred]).T)\n",
    "val_df.columns = [\"label\", \"pred\"]\n",
    "val_df[\"dev\"] = abs(val_df[\"label\"] - val_df[\"pred\"]) \n",
    "val_df[\"mse\"] = (val_df[\"label\"] - val_df[\"pred\"])**2\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = sklearn.metrics.confusion_matrix(val_labels,val_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_conf_mat = conf_mat/conf_mat.sum(axis=1)\n",
    "norm_conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(norm_conf_mat,cmap=\"YlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = sklearn.metrics.accuracy_score(val_labels, val_pred)\n",
    "rec = sklearn.metrics.recall_score(val_labels, val_pred, average=None)\n",
    "prec = sklearn.metrics.precision_score(val_labels, val_pred, average=None)\n",
    "\n",
    "print(\"Accuracy:\\n {}\".format(acc))\n",
    "\n",
    "print(\"Recall:\\n {}\".format(rec))\n",
    "print(\"averaged recall: {} +- {}\".format(rec.mean(), rec.std()) )\n",
    "\n",
    "print(\"Precision:\\n {}\".format(prec))\n",
    "print(\"averaged precision: {} +- {}\".format(prec.mean(), prec.std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
