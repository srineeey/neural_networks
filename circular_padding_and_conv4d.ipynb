{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1,\"/home/sbulusu/qcd_ml/neural_networks/libs/\")\n",
    "import custom_torch_net_class_lightning\n",
    "\n",
    "sys.path.insert(1,\"/home/sbulusu/qcd_ml/neural_networks/libs/pytorch-conv4d/\")\n",
    "from conv4d import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = -2\n",
    "i_max = 5\n",
    "np.mod(i, i_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8],\n",
      "         [ 9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14],\n",
      "         [15, 16, 17],\n",
      "         [18, 19, 20],\n",
      "         [21, 22, 23]],\n",
      "\n",
      "        [[24, 25, 26],\n",
      "         [27, 28, 29],\n",
      "         [30, 31, 32],\n",
      "         [33, 34, 35]],\n",
      "\n",
      "        [[36, 37, 38],\n",
      "         [39, 40, 41],\n",
      "         [42, 43, 44],\n",
      "         [45, 46, 47]],\n",
      "\n",
      "        [[48, 49, 50],\n",
      "         [51, 52, 53],\n",
      "         [54, 55, 56],\n",
      "         [57, 58, 59]]])\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(0,60)\n",
    "a = a.reshape((5,4,3))\n",
    "#np.pad(a,2,\"wrap\")\n",
    "\n",
    "torch_a = torch.tensor(a)\n",
    "torch_a.size()\n",
    "print(torch_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11]],\n",
       "\n",
       "        [[24, 25, 26],\n",
       "         [27, 28, 29],\n",
       "         [30, 31, 32],\n",
       "         [33, 34, 35]],\n",
       "\n",
       "        [[48, 49, 50],\n",
       "         [51, 52, 53],\n",
       "         [54, 55, 56],\n",
       "         [57, 58, 59]]])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride = 2\n",
    "row_list = range(0,len(torch_a), stride)\n",
    "\n",
    "torch_a[row_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_a.narrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n"
     ]
    }
   ],
   "source": [
    "torch_b = torch_a.narrow(0,0,2)\n",
    "print(torch_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch_a,torch_b), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_a.repeat(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19]])\n"
     ]
    }
   ],
   "source": [
    "torch_a = torch.arange(0,20)\n",
    "torch_a = torch_a.reshape(5,4)\n",
    "print(torch_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (6) must match the existing size (4) at non-singleton dimension 1.  Target sizes: [5, 6].  Tensor sizes: [5, 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2c4010ee2663>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (6) must match the existing size (4) at non-singleton dimension 1.  Target sizes: [5, 6].  Tensor sizes: [5, 4]"
     ]
    }
   ],
   "source": [
    "torch_a.expand(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "torch.Size([2, 3, 4])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19],\n",
      "        [20, 21, 22, 23]])\n",
      "torch.Size([6, 4])\n",
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "shape = [2,3,4]\n",
    "n_max = np.prod(shape)\n",
    "torch_range = torch.tensor(np.arange(n_max).reshape(shape))\n",
    "print(torch_range)\n",
    "print(torch_range.shape)\n",
    "torch_range = torch_range.reshape(-1,*shape[2:])\n",
    "print(torch_range)\n",
    "print(torch_range.shape)\n",
    "torch_range = torch_range.view(shape)\n",
    "print(torch_range)\n",
    "print(torch_range.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#conv4d_layer = conv4d.Conv4d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Circular Padding\"\"\"\n",
    "\n",
    "class CircularPadding(nn.Module):\n",
    "    \n",
    "    def __init__(self, padding=1):\n",
    "        super(CircularPadding, self).__init__()\n",
    "        \n",
    "        #self.padding = padding\n",
    "        #batch axis\n",
    "        self.padding = np.concatenate(([0],padding))\n",
    "        \n",
    "        self.dims = len(self.padding)\n",
    "\n",
    "            \n",
    "    def forward(self,x):\n",
    "        \n",
    "        padded_x = x\n",
    "        \n",
    "        #for d in dims:\n",
    "        for d in range(1,self.dims):\n",
    "            #print(d)\n",
    "            \n",
    "            pad_l = self.padding[d]\n",
    "            if self.padding[d] != 0:\n",
    "                end_strip = padded_x.narrow(d, 0, int(pad_l)).clone()\n",
    "                start_strip = padded_x.narrow(d, int(-pad_l), int(pad_l)).clone()\n",
    "                \n",
    "                #print(padded_x.size())\n",
    "                #print(end_strip.size())\n",
    "                #print(start_strip.size())\n",
    "                \n",
    "                padded_x = torch.cat((start_strip, padded_x, end_strip), dim=d)\n",
    "                \n",
    "                #print(padded_x.size())\n",
    "        \n",
    "        return padded_x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "circ_pad_layer = CircularPadding(padding=[2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15],\n",
      "         [16, 17, 18, 19]]])\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(0,20)\n",
    "a = a.reshape((1,5,4))\n",
    "torch_a = torch.tensor(a)\n",
    "print(torch_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[13, 14, 15, 12, 13, 14, 15, 12, 13, 14],\n",
      "         [17, 18, 19, 16, 17, 18, 19, 16, 17, 18],\n",
      "         [ 1,  2,  3,  0,  1,  2,  3,  0,  1,  2],\n",
      "         [ 5,  6,  7,  4,  5,  6,  7,  4,  5,  6],\n",
      "         [ 9, 10, 11,  8,  9, 10, 11,  8,  9, 10],\n",
      "         [13, 14, 15, 12, 13, 14, 15, 12, 13, 14],\n",
      "         [17, 18, 19, 16, 17, 18, 19, 16, 17, 18],\n",
      "         [ 1,  2,  3,  0,  1,  2,  3,  0,  1,  2],\n",
      "         [ 5,  6,  7,  4,  5,  6,  7,  4,  5,  6]]])\n"
     ]
    }
   ],
   "source": [
    "torch_a_pad = circ_pad_layer(torch_a)\n",
    "print(torch_a_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19]])\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(0,20)\n",
    "a = a.reshape((5,4))\n",
    "torch_a = torch.tensor(a)\n",
    "print(torch_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 3, 3, 3])\n",
      "torch.Size([1, 10, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "layer_pars = {\"in_channels\": 5,\n",
    "              \"out_channels\": 10,\n",
    "              \"kernel_size\": [2,2,2],\n",
    "              \"stride\": [1,1,1],\n",
    "              \"padding\": [0,0,0],\n",
    "              \"dilation\": [1,1,1],\n",
    "              \"bias\": True}\n",
    "conv3d_layer = nn.Conv3d(**layer_pars)\n",
    "#test_input = torch.ones(5,3,3,3)\n",
    "test_input = torch.ones(1,5,3,3,3)\n",
    "test_output = conv3d_layer(test_input)\n",
    "print(test_input.size())\n",
    "print(test_output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"4D Convolution\"\"\"\n",
    "\n",
    "class MyConv4d(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=1, out_channels=1,\n",
    "                 kernel_size=[1,1,1,1], stride=[1,1,1,1], padding=[0,0,0,0], padding_mode=\"zeros\",\n",
    "                 dilation=[1,1,1,1], groups=1,\n",
    "                 bias=True,\n",
    "                 kernel_initializer=None,\n",
    "                 bias_initializer=None):\n",
    "    \n",
    "        #torch.nn.init.xavier_normal_\n",
    "        super(MyConv4d, self).__init__()\n",
    "        \n",
    "        #save all arguments\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.padding_mode = padding_mode\n",
    "        \n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        self.bias = bias\n",
    "        \n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        \n",
    "        #(min_kernel_l, min_dims) = torch.min(self.kernel_size, 0, keepdim=True, out=None)\n",
    "        \n",
    "        #idea: separate a 4d convolution into a stack of 3d convolutions\n",
    "        #intially the 4d kernel is stack split is done in the first dimension\n",
    "        \"\"\"CHANGE TO SHORTEST DIMENSION\"\"\"\n",
    "        self.kernel_3d_num = self.kernel_size[0]\n",
    "        self.kernel_3d_size = self.kernel_size[1:]\n",
    "        \n",
    "        conv_3d_layer_pars = {}\n",
    "        conv_3d_layer_pars[\"in_channels\"] = self.in_channels\n",
    "        conv_3d_layer_pars[\"out_channels\"] = self.out_channels\n",
    "        \n",
    "        conv_3d_layer_pars[\"kernel_size\"] = self.kernel_3d_size\n",
    "        conv_3d_layer_pars[\"stride\"] = self.stride[1:]\n",
    "        conv_3d_layer_pars[\"padding\"] = self.padding[1:]\n",
    "        conv_3d_layer_pars[\"padding_mode\"] = self.padding_mode\n",
    "        \n",
    "        #conv3d_layer_pars[\"dilation\"] = self.dilation[1:]\n",
    "        #conv3d_layer_pars[\"groups\"] = self.groups\n",
    "        conv_3d_layer_pars[\"bias\"] = self.bias\n",
    "        \n",
    "        #initialize conv_3d stack\n",
    "        self.conv_3d_layers = nn.ModuleList()\n",
    "        for kernel_3d_i in range(self.kernel_3d_num):\n",
    "            #conv_3d_layer = nn.Conv3d(**conv3d_layer_pars)\n",
    "            self.conv_3d_layers.append(nn.Conv3d(**conv_3d_layer_pars))\n",
    "            \n",
    "            if self.kernel_initializer != None:\n",
    "                self.kernel_initializer(self.conv_3d_layers[-1].weight)\n",
    "            if self.bias_initializer != None:\n",
    "                self.bias_initializer(self.conv_3d_layers[-1].bias)\n",
    "                \n",
    "            \n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x_size = np.array(x.size())\n",
    "        print(f\"input_size: {x_size}\")\n",
    "        \n",
    "        #calculate the size of the output tensor\n",
    "        #output_size = np.zeros(len(x_size), dtype=int)\n",
    "        output_size = x_size.copy()\n",
    "        \"\"\"BATCH AXIS?\"\"\"\n",
    "        #output_size[0] = x_size[0]\n",
    "        #output_size[0] = self.out_channels\n",
    "        output_size[1] = self.out_channels\n",
    "        #new_layer_size_l = int(np.floor( (prev_layer_l + 2*padding_l - dilation_l*(kernel_l - 1) - 1)/(stride_l) + 1.))\n",
    "        \"\"\"GENERALIZE TO ARBITRARY DIMENSION\"\"\"\n",
    "        for d in range(len(self.kernel_size)):\n",
    "            #print(output_size[d+1])\n",
    "            #print(x_size[d+1])\n",
    "            #print(self.padding[d])\n",
    "            #print(self.dilation[d])\n",
    "            #print(self.kernel_size[d])\n",
    "            #print(self.stride)\n",
    "            output_size[d+2] = (x_size[d+2] + 2*self.padding[d] - self.dilation[d]*(self.kernel_size[d] - 1) - 1)/(self.stride[d]) + 1\n",
    "        \n",
    "        print(f\"output_size: {output_size}\")\n",
    "        \n",
    "        \n",
    "        #keep track of the input row number in 4th dimension\n",
    "        \"\"\"CHANGE TO ARBITRARY DIMENSION\"\"\"\n",
    "        #row_4d_num = x_size[1]\n",
    "        row_4d_num = x_size[2]\n",
    "        print(f\"row_4d_num: {row_4d_num}\")\n",
    "        \n",
    "        \n",
    "        #keep track of the output row number in 4th dimension\n",
    "        #output_row_4d_num = output_size[1]\n",
    "        output_row_4d_num = output_size[2]\n",
    "        print(f\"output_row_4d_num: {output_row_4d_num}\")\n",
    "        \n",
    "        \n",
    "        #initialize output tensor\n",
    "        output = torch.zeros(tuple(output_size))\n",
    "        \n",
    "        #iterate through every 3d slice of the 4d kernel\n",
    "        for kernel_3d_i in range(self.kernel_3d_num):\n",
    "            #print(f\"kernel_3d_i: {kernel_3d_i}\")\n",
    "            \n",
    "            \"\"\"CAN BE REDUCED?\"\"\"\n",
    "            #iterate through all rows in the fourth dimension\n",
    "            #for row_4d_i in range(row_4d_num-self.kernel_3d_num):\n",
    "            for row_4d_i in range(kernel_3d_i, row_4d_num - self.kernel_3d_num + kernel_3d_i):\n",
    "            #for row_4d_i in range(row_4d_num):\n",
    "                #print(f\"row_4d_i: {row_4d_i}\")\n",
    "                \n",
    "                print(f\"kernel_3d_i: {kernel_3d_i}, row_4d_i: {row_4d_i}\")\n",
    "            \n",
    "                \"\"\"CHECK FORMULA\"\"\"\n",
    "                output_row = row_4d_i - kernel_3d_i\n",
    "                print(f\"output_row: {output_row}\")\n",
    "                \n",
    "                #check whether kernel slice is outside of the input tensor\n",
    "                \"\"\"IF CHECK NECESSARY?\"\"\"\n",
    "\n",
    "                \n",
    "                \n",
    "                \"\"\"GENERALIZE TO ARBITRARY DIMENSION\"\"\"\n",
    "                #x_3d_slice = x[:,row_4d_i]\n",
    "                x_3d_slice = x[:,:,row_4d_i]\n",
    "                #print(f\"x_3d_slice shape: {x_3d_slice.size()}\")\n",
    "                \n",
    "                #compute the partial output row with the kernel slice\n",
    "                #first two dimensions of x are batch size and channels\n",
    "                \"\"\"VIEW NECESSARY?\"\"\"\n",
    "                partial_output_row = self.conv_3d_layers[kernel_3d_i](x_3d_slice)\n",
    "                #frame_conv3d = self.conv3d_layers[i](input[:, :, j, :].view(b, c_i, d_i, h_i, w_i))\n",
    "                \n",
    "                \"\"\"BATCH AND CHANNEL AXES?\"\"\"\n",
    "                #output[:,output_row] += partial_output_row\n",
    "                output[:,:,output_row] += partial_output_row\n",
    "        \n",
    "        \n",
    "        return output\n",
    "        \n",
    "        #return output_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_pars = {\"in_channels\": 5,\n",
    "              \"out_channels\": 10,\n",
    "              \"kernel_size\": [2,2,2,2],\n",
    "              \"stride\": [1,1,1,1],\n",
    "              \"padding\": [0,0,0,0],\n",
    "              \"dilation\": [1,1,1,1],\n",
    "              \"bias\": True}\n",
    "conv4d_layer = MyConv4d(**layer_pars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size: [1 5 4 5 6 7]\n",
      "output_size: [ 1 10  3  4  5  6]\n",
      "row_4d_num: 4\n",
      "output_row_4d_num: 3\n",
      "kernel_3d_i: 0, row_4d_i: 0\n",
      "output_row: 0\n",
      "kernel_3d_i: 0, row_4d_i: 1\n",
      "output_row: 1\n",
      "kernel_3d_i: 1, row_4d_i: 1\n",
      "output_row: 0\n",
      "kernel_3d_i: 1, row_4d_i: 2\n",
      "output_row: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = torch.ones(1,5,4,5,6,7)\n",
    "test_output = conv4d_layer(test_input)\n",
    "test_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"4D Convolution v2\"\"\"\n",
    "\"\"\"No padding support due to convolution algorithm\"\"\"\n",
    "\"\"\"\n",
    "Currently works only with [batch_index, channel_index, t, x, y, z] format\n",
    "the four last index blocks are convolved\n",
    "the 3d slices are cut with respect to the t-axis\n",
    "\"\"\"\n",
    "\n",
    "class MyConv4dv2(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=1, out_channels=1,\n",
    "                 kernel_size=[1,1,1,1], stride=[1,1,1,1],\n",
    "                 dilation=[1,1,1,1], groups=1, padding=[0,0,0,0], padding_mode=\"zeros\",\n",
    "                 bias=True,\n",
    "                 kernel_initializer=None,\n",
    "                 bias_initializer=None):\n",
    "    \n",
    "        #torch.nn.init.xavier_normal_\n",
    "        super(MyConv4dv2, self).__init__()\n",
    "        \n",
    "        #save all arguments\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.padding_mode = padding_mode\n",
    "        \n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        self.bias = bias\n",
    "        \n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "        \n",
    "        #(min_kernel_l, min_dims) = torch.min(self.kernel_size, 0, keepdim=True, out=None)\n",
    "        \n",
    "        #idea: separate a 4d convolution into a stack of 3d convolutions\n",
    "        #intially the 4d kernel is stack split is done in the first dimension\n",
    "        \"\"\"CHANGE TO SHORTEST DIMENSION\"\"\"\n",
    "        self.kernel_3d_num = self.kernel_size[0]\n",
    "        self.kernel_3d_size = self.kernel_size[1:]\n",
    "        \n",
    "        self.padding_4d = self.padding[0]\n",
    "        \n",
    "        conv_3d_layer_pars = {}\n",
    "        conv_3d_layer_pars[\"in_channels\"] = self.in_channels\n",
    "        conv_3d_layer_pars[\"out_channels\"] = self.out_channels\n",
    "        \n",
    "        conv_3d_layer_pars[\"kernel_size\"] = self.kernel_3d_size\n",
    "        \"\"\"NOT YET IMPLEMENTED\"\"\"\n",
    "        conv_3d_layer_pars[\"stride\"] = self.stride[1:]\n",
    "        conv_3d_layer_pars[\"padding\"] = self.padding[1:]\n",
    "        #conv_3d_layer_pars[\"padding_mode\"] = self.padding_mode\n",
    "        \n",
    "        \"\"\"NOT YET IMPLEMENTED\"\"\"\n",
    "        #conv_3d_layer_pars[\"dilation\"] = self.dilation[1:]\n",
    "        #conv_3d_layer_pars[\"groups\"] = self.groups\n",
    "        conv_3d_layer_pars[\"bias\"] = self.bias\n",
    "        \n",
    "        #initialize conv_3d stack\n",
    "        self.conv_3d_layers = nn.ModuleList()\n",
    "        for kernel_3d_i in range(self.kernel_3d_num):\n",
    "            #conv_3d_layer = nn.Conv3d(**conv3d_layer_pars)\n",
    "            self.conv_3d_layers.append(nn.Conv3d(**conv_3d_layer_pars))\n",
    "            \n",
    "            if self.kernel_initializer != None:\n",
    "                self.kernel_initializer(self.conv_3d_layers[-1].weight)\n",
    "            if self.bias_initializer != None:\n",
    "                self.bias_initializer(self.conv_3d_layers[-1].bias)\n",
    "                \n",
    "            \n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x_size = np.array(x.size())\n",
    "        print(f\"input_size: {x_size}\")\n",
    "        \n",
    "        #calculate the size of the output tensor\n",
    "        #output_size = np.zeros(len(x_size), dtype=int)\n",
    "        output_size = x_size.copy()\n",
    "        \"\"\"BATCH AXIS?\"\"\"\n",
    "        #output_size[0] = x_size[0]\n",
    "        #output_size[0] = self.out_channels\n",
    "        output_size[1] = self.out_channels\n",
    "        #new_layer_size_l = int(np.floor( (prev_layer_l + 2*padding_l - dilation_l*(kernel_l - 1) - 1)/(stride_l) + 1.))\n",
    "        \"\"\"GENERALIZE TO ARBITRARY DIMENSION\"\"\"\n",
    "        for d in range(len(self.kernel_size)):\n",
    "            #print(output_size[d+1])\n",
    "            #print(x_size[d+1])\n",
    "            #print(self.padding[d])\n",
    "            #print(self.dilation[d])\n",
    "            #print(self.kernel_size[d])\n",
    "            #print(self.stride)\n",
    "            output_size[d+2] = (x_size[d+2] + 2*self.padding[d] - self.dilation[d]*(self.kernel_size[d] - 1) - 1)/(self.stride[d]) + 1\n",
    "        \n",
    "        #print(f\"output_size: {output_size}\")\n",
    "        \n",
    "        \n",
    "        #keep track of the input row number in 4th dimension\n",
    "        #disregarding padding!\n",
    "        \"\"\"CHANGE TO ARBITRARY DIMENSION\"\"\"\n",
    "        #row_4d_num = x_size[1]\n",
    "        row_4d_num = x_size[2]\n",
    "        #print(f\"row_4d_num: {row_4d_num}\")\n",
    "        \n",
    "        \n",
    "        #keep track of the output row number in 4th dimension\n",
    "        #output_row_4d_num = output_size[1]\n",
    "        output_row_4d_num = output_size[2]\n",
    "        #print(f\"output_row_4d_num: {output_row_4d_num}\")\n",
    "        \n",
    "        \n",
    "        #initialize output tensor\n",
    "        output = torch.zeros(tuple(output_size))\n",
    "        \n",
    "        #iterate through every 3d slice of the 4d kernel\n",
    "        for kernel_3d_i in range(self.kernel_3d_num):\n",
    "            #print(f\"kernel_3d_i: {kernel_3d_i}\")\n",
    "            \n",
    "            \"\"\"CHECK FORMULA\"\"\"\n",
    "            #perform a convolution with current 3d kernel slice on ALL of these rows\n",
    "            rows = [kernel_3d_i, row_4d_num - self.kernel_3d_num + kernel_3d_i + 1]\n",
    "            \n",
    "            #print(f\"convolving rows: [{rows[0]},{rows[1]})\")\n",
    "            \n",
    "            #\"\"\"CHECK FORMULA\"\"\"\n",
    "            #output_row = row_4d_i - kernel_3d_i\n",
    "            #print(f\"output_row: {output_row}\")\n",
    "            \n",
    "            #the block with which the 3d conv slice should be convolved\n",
    "            \"\"\"GENERALIZE TO ARBITRARY DIMENSION\"\"\"\n",
    "            x_4d_block = x.narrow(2, int(rows[0]), int(rows[1] - rows[0]))\n",
    "            \n",
    "            #print(f\"slicing 4d block of size: {x_4d_block.size()}\")\n",
    "            \n",
    "            #swap row axis and channel axis\n",
    "            #so that convolution can sum up channels\n",
    "            #but leave rows in 4d untouched\n",
    "            #x_4d_block.transpose(2,1)\n",
    "            x_4d_block_t = torch.transpose(x_4d_block, 1, 2)\n",
    "            #print(f\"transposing 4d block to size: {x_4d_block_t.size()}\")\n",
    "            \n",
    "            #perform the actual operation\n",
    "            #the input tensor has to have 5 dimensions in order for conv3d to work\n",
    "            #squeeze the first two dimensions into the batch dimension\n",
    "            #unsqueezing has to be done later\n",
    "            #block_output = self.conv3d_layers[kernel_3d_i](x_4d_block_t.view(-1,*x_4d_block_t.size()[2:]))\n",
    "            #print(f\"convolving 4d block of size: {x_4d_block_t.view(-1,*x_4d_block_t.size()[2:]).size()}\")\n",
    "            \n",
    "            block_output = self.conv_3d_layers[kernel_3d_i](x_4d_block_t.reshape(-1,*x_4d_block_t.size()[2:]))\n",
    "            #print(f\"convolving 4d block of size: {x_4d_block_t.reshape(-1,*x_4d_block_t.size()[2:]).size()}\")\n",
    "\n",
    "            #aggregate the block_output\n",
    "            \"\"\"UNSQUEEZING BATCH AND ROW DIMENSION CORRECT?\"\"\"\n",
    "            #output[:,:] += block_output\n",
    "            output += block_output.view(*output_size)\n",
    "\n",
    "        \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_pars = {\"in_channels\": 5,\n",
    "              \"out_channels\": 10,\n",
    "              \"kernel_size\": [3,3,3,3],\n",
    "              \"stride\": [1,1,1,1],\n",
    "              \"dilation\": [1,1,1,1],\n",
    "              \"bias\": True}\n",
    "conv4dv2_layer = MyConv4dv2(**layer_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size: [2 5 6 8 8 8]\n",
      "output_size: [ 2 10  4  6  6  6]\n",
      "row_4d_num: 6\n",
      "output_row_4d_num: 4\n",
      "kernel_3d_i: 0\n",
      "convolving rows: [0,4)\n",
      "slicing 4d block of size: torch.Size([2, 5, 4, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([2, 4, 5, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([8, 5, 8, 8, 8])\n",
      "kernel_3d_i: 1\n",
      "convolving rows: [1,5)\n",
      "slicing 4d block of size: torch.Size([2, 5, 4, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([2, 4, 5, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([8, 5, 8, 8, 8])\n",
      "kernel_3d_i: 2\n",
      "convolving rows: [2,6)\n",
      "slicing 4d block of size: torch.Size([2, 5, 4, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([2, 4, 5, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([8, 5, 8, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 4, 6, 6, 6])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = torch.ones(2,5,6,8,8,8)\n",
    "#test_input.transpose()\n",
    "#test_input.reshape()\n",
    "test_output = conv4dv2_layer(test_input)\n",
    "test_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size: [1 1 6 8 8 8]\n",
      "output_size: [1 1 4 5 4 3]\n",
      "row_4d_num: 6\n",
      "output_row_4d_num: 4\n",
      "kernel_3d_i: 0\n",
      "convolving rows: [0,4)\n",
      "slicing 4d block of size: torch.Size([1, 1, 4, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([1, 4, 1, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([4, 1, 8, 8, 8])\n",
      "kernel_3d_i: 1\n",
      "convolving rows: [1,5)\n",
      "slicing 4d block of size: torch.Size([1, 1, 4, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([1, 4, 1, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([4, 1, 8, 8, 8])\n",
      "kernel_3d_i: 2\n",
      "convolving rows: [2,6)\n",
      "slicing 4d block of size: torch.Size([1, 1, 4, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([1, 4, 1, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([4, 1, 8, 8, 8])\n",
      "torch.Size([1, 1, 4, 5, 4, 3])\n",
      "tensor([[[[[[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]]],\n",
      "\n",
      "\n",
      "          [[[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]]],\n",
      "\n",
      "\n",
      "          [[[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]]],\n",
      "\n",
      "\n",
      "          [[[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]],\n",
      "\n",
      "           [[360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.],\n",
      "            [360., 360., 360.]]]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "kernel_size = [3,4,5,6]\n",
    "layer_pars = {\"in_channels\": 1,\n",
    "              \"out_channels\": 1,\n",
    "              \"kernel_size\": kernel_size,\n",
    "              \"stride\": [1,1,1,1],\n",
    "              \"dilation\": [1,1,1,1],\n",
    "              \"bias\": True,\n",
    "              \"kernel_initializer\" : lambda x: torch.nn.init.constant_(x, 1),\n",
    "              \"bias_initializer\" : lambda x: torch.nn.init.constant_(x, 0)\n",
    "             }\n",
    "#kernel_initializer=lambda x: torch.nn.init.constant_(x, 1),\n",
    "#bias_initializer=lambda x: torch.nn.init.constant_(x, 0))\n",
    "\n",
    "conv4dv2_layer = MyConv4dv2(**layer_pars)\n",
    "\n",
    "test_input_shape = [1,1,6,8,8,8]\n",
    "\n",
    "test_input = torch.ones(*test_input_shape)\n",
    "\n",
    "test_output = conv4dv2_layer(test_input)\n",
    "print(test_output.size())\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size: [1 3 6 8 8 8]\n",
      "output_size: [1 1 4 5 4 3]\n",
      "row_4d_num: 6\n",
      "output_row_4d_num: 4\n",
      "kernel_3d_i: 0\n",
      "convolving rows: [0,4)\n",
      "slicing 4d block of size: torch.Size([1, 3, 4, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([1, 4, 3, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([4, 3, 8, 8, 8])\n",
      "kernel_3d_i: 1\n",
      "convolving rows: [1,5)\n",
      "slicing 4d block of size: torch.Size([1, 3, 4, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([1, 4, 3, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([4, 3, 8, 8, 8])\n",
      "kernel_3d_i: 2\n",
      "convolving rows: [2,6)\n",
      "slicing 4d block of size: torch.Size([1, 3, 4, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([1, 4, 3, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([4, 3, 8, 8, 8])\n",
      "torch.Size([1, 1, 4, 5, 4, 3])\n",
      "tensor([[[[[[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]]],\n",
      "\n",
      "\n",
      "          [[[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]]],\n",
      "\n",
      "\n",
      "          [[[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]]],\n",
      "\n",
      "\n",
      "          [[[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]],\n",
      "\n",
      "           [[1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.],\n",
      "            [1080., 1080., 1080.]]]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "kernel_size = [3,4,5,6]\n",
    "layer_pars = {\"in_channels\": 3,\n",
    "              \"out_channels\": 1,\n",
    "              \"kernel_size\": kernel_size,\n",
    "              \"stride\": [1,1,1,1],\n",
    "              \"dilation\": [1,1,1,1],\n",
    "              \"bias\": True,\n",
    "              \"kernel_initializer\" : lambda x: torch.nn.init.constant_(x, 1),\n",
    "              \"bias_initializer\" : lambda x: torch.nn.init.constant_(x, 0)\n",
    "             }\n",
    "#kernel_initializer=lambda x: torch.nn.init.constant_(x, 1),\n",
    "#bias_initializer=lambda x: torch.nn.init.constant_(x, 0))\n",
    "\n",
    "conv4dv2_layer = MyConv4dv2(**layer_pars)\n",
    "\n",
    "test_input_shape = [1,3,6,8,8,8]\n",
    "\n",
    "test_input = torch.ones(*test_input_shape)\n",
    "\n",
    "\n",
    "test_output = conv4dv2_layer(test_input)\n",
    "print(test_output.size())\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size: [1 1 6 8 8 8]\n",
      "output_size: [1 1 4 5 4 3]\n",
      "row_4d_num: 6\n",
      "output_row_4d_num: 4\n",
      "kernel_3d_i: 0\n",
      "convolving rows: [0,4)\n",
      "slicing 4d block of size: torch.Size([1, 1, 4, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([1, 4, 1, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([4, 1, 8, 8, 8])\n",
      "kernel_3d_i: 1\n",
      "convolving rows: [1,5)\n",
      "slicing 4d block of size: torch.Size([1, 1, 4, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([1, 4, 1, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([4, 1, 8, 8, 8])\n",
      "kernel_3d_i: 2\n",
      "convolving rows: [2,6)\n",
      "slicing 4d block of size: torch.Size([1, 1, 4, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([1, 4, 1, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([4, 1, 8, 8, 8])\n",
      "torch.Size([1, 1, 4, 5, 4, 3])\n",
      "tensor([[[[[[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]]],\n",
      "\n",
      "\n",
      "          [[[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]]],\n",
      "\n",
      "\n",
      "          [[[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]]],\n",
      "\n",
      "\n",
      "          [[[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]],\n",
      "\n",
      "           [[720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.],\n",
      "            [720., 720., 720.]]]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "kernel_size = [3,4,5,6]\n",
    "layer_pars = {\"in_channels\": 1,\n",
    "              \"out_channels\": 1,\n",
    "              \"kernel_size\": kernel_size,\n",
    "              \"stride\": [1,1,1,1],\n",
    "              \"dilation\": [1,1,1,1],\n",
    "              \"bias\": True,\n",
    "              \"kernel_initializer\" : lambda x: torch.nn.init.constant_(x, 2),\n",
    "              \"bias_initializer\" : lambda x: torch.nn.init.constant_(x, 0)\n",
    "             }\n",
    "#kernel_initializer=lambda x: torch.nn.init.constant_(x, 1),\n",
    "#bias_initializer=lambda x: torch.nn.init.constant_(x, 0))\n",
    "\n",
    "conv4dv2_layer = MyConv4dv2(**layer_pars)\n",
    "\n",
    "test_input_shape = [1,1,6,8,8,8]\n",
    "\n",
    "test_input = torch.ones(*test_input_shape)\n",
    "\n",
    "test_output = conv4dv2_layer(test_input)\n",
    "print(test_output.size())\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size: [1 1 6 8 8 8]\n",
      "output_size: [1 1 3 5 4 3]\n",
      "row_4d_num: 6\n",
      "output_row_4d_num: 3\n",
      "kernel_3d_i: 0\n",
      "convolving rows: [0,3)\n",
      "slicing 4d block of size: torch.Size([1, 1, 3, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([1, 3, 1, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([3, 1, 8, 8, 8])\n",
      "kernel_3d_i: 1\n",
      "convolving rows: [1,4)\n",
      "slicing 4d block of size: torch.Size([1, 1, 3, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([1, 3, 1, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([3, 1, 8, 8, 8])\n",
      "kernel_3d_i: 2\n",
      "convolving rows: [2,5)\n",
      "slicing 4d block of size: torch.Size([1, 1, 3, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([1, 3, 1, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([3, 1, 8, 8, 8])\n",
      "kernel_3d_i: 3\n",
      "convolving rows: [3,6)\n",
      "slicing 4d block of size: torch.Size([1, 1, 3, 8, 8, 8])\n",
      "transposing 4d block to size: torch.Size([1, 3, 1, 8, 8, 8])\n",
      "convolving 4d block of size: torch.Size([3, 1, 8, 8, 8])\n",
      "torch.Size([1, 1, 3, 5, 4, 3])\n",
      "tensor([[[[[[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]]],\n",
      "\n",
      "\n",
      "          [[[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]]],\n",
      "\n",
      "\n",
      "          [[[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]]]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "kernel_size = [3,4,5,6]\n",
    "layer_pars = {\"in_channels\": 1,\n",
    "              \"out_channels\": 1,\n",
    "              \"kernel_size\": kernel_size,\n",
    "              \"stride\": [1,1,1,1],\n",
    "              \"dilation\": [1,1,1,1],\n",
    "              \"bias\": True,\n",
    "              \"kernel_initializer\" : lambda x: torch.nn.init.constant_(x, 1),\n",
    "              \"bias_initializer\" : lambda x: torch.nn.init.constant_(x, 1)\n",
    "             }\n",
    "#kernel_initializer=lambda x: torch.nn.init.constant_(x, 1),\n",
    "#bias_initializer=lambda x: torch.nn.init.constant_(x, 0))\n",
    "\n",
    "conv4dv2_layer = MyConv4dv2(**layer_pars)\n",
    "\n",
    "test_input_shape = [1,1,6,8,8,8]\n",
    "\n",
    "test_input = torch.ones(*test_input_shape)\n",
    "\n",
    "test_output = conv4dv2_layer(test_input)\n",
    "print(test_output.size())\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 5, 4, 3])\n",
      "tensor([[[[[[363., 363., 363.],\n",
      "            [363., 363., 363.],\n",
      "            [363., 363., 363.],\n",
      "            [363., 363., 363.]],\n",
      "\n",
      "           [[363., 363., 363.],\n",
      "            [363., 363., 363.],\n",
      "            [363., 363., 363.],\n",
      "            [363., 363., 363.]],\n",
      "\n",
      "           [[363., 363., 363.],\n",
      "            [363., 363., 363.],\n",
      "            [363., 363., 363.],\n",
      "            [363., 363., 363.]],\n",
      "\n",
      "           [[363., 363., 363.],\n",
      "            [363., 363., 363.],\n",
      "            [363., 363., 363.],\n",
      "            [363., 363., 363.]],\n",
      "\n",
      "           [[363., 363., 363.],\n",
      "            [363., 363., 363.],\n",
      "            [363., 363., 363.],\n",
      "            [363., 363., 363.]]],\n",
      "\n",
      "\n",
      "          [[[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]]],\n",
      "\n",
      "\n",
      "          [[[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]],\n",
      "\n",
      "           [[484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.],\n",
      "            [484., 484., 484.]]]]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "kernel_size = [3,4,5,6]\n",
    "conv4d_layer = \\\n",
    "        Conv4d(in_channels=1,\n",
    "               out_channels=1,\n",
    "               kernel_size=kernel_size,\n",
    "               padding=0,\n",
    "               kernel_initializer=lambda x: torch.nn.init.constant_(x, 1),\n",
    "               bias_initializer=lambda x: torch.nn.init.constant_(x, 1))\n",
    "    \n",
    "test_input_shape = [1,1,6,8,8,8]\n",
    "\n",
    "test_input = torch.ones(*test_input_shape)\n",
    "\n",
    "test_output = conv4d_layer(test_input)\n",
    "print(test_output.size())\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[[0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.]],\n",
      "\n",
      "           [[0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.]],\n",
      "\n",
      "           [[0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.]],\n",
      "\n",
      "           [[0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.]],\n",
      "\n",
      "           [[0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.],\n",
      "            [0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "          [[[1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.]],\n",
      "\n",
      "           [[1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.]],\n",
      "\n",
      "           [[1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.]],\n",
      "\n",
      "           [[1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.]],\n",
      "\n",
      "           [[1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.],\n",
      "            [1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "          [[[2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.]],\n",
      "\n",
      "           [[2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.]],\n",
      "\n",
      "           [[2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.]],\n",
      "\n",
      "           [[2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.]],\n",
      "\n",
      "           [[2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.],\n",
      "            [2., 2., 2., 2., 2.]]],\n",
      "\n",
      "\n",
      "          [[[3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.]],\n",
      "\n",
      "           [[3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.]],\n",
      "\n",
      "           [[3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.]],\n",
      "\n",
      "           [[3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.]],\n",
      "\n",
      "           [[3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.],\n",
      "            [3., 3., 3., 3., 3.]]],\n",
      "\n",
      "\n",
      "          [[[4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.]],\n",
      "\n",
      "           [[4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.]],\n",
      "\n",
      "           [[4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.]],\n",
      "\n",
      "           [[4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.]],\n",
      "\n",
      "           [[4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.],\n",
      "            [4., 4., 4., 4., 4.]]]]]])\n",
      "input_size: [1 1 5 5 5 5]\n",
      "output_size: [1 1 3 3 3 3]\n",
      "row_4d_num: 5\n",
      "output_row_4d_num: 3\n",
      "kernel_3d_i: 0\n",
      "convolving rows: [0,3)\n",
      "slicing 4d block of size: torch.Size([1, 1, 3, 5, 5, 5])\n",
      "transposing 4d block to size: torch.Size([1, 3, 1, 5, 5, 5])\n",
      "convolving 4d block of size: torch.Size([3, 1, 5, 5, 5])\n",
      "kernel_3d_i: 1\n",
      "convolving rows: [1,4)\n",
      "slicing 4d block of size: torch.Size([1, 1, 3, 5, 5, 5])\n",
      "transposing 4d block to size: torch.Size([1, 3, 1, 5, 5, 5])\n",
      "convolving 4d block of size: torch.Size([3, 1, 5, 5, 5])\n",
      "kernel_3d_i: 2\n",
      "convolving rows: [2,5)\n",
      "slicing 4d block of size: torch.Size([1, 1, 3, 5, 5, 5])\n",
      "transposing 4d block to size: torch.Size([1, 3, 1, 5, 5, 5])\n",
      "convolving 4d block of size: torch.Size([3, 1, 5, 5, 5])\n",
      "torch.Size([1, 1, 3, 3, 3, 3])\n",
      "tensor([[[[[[ 81.,  81.,  81.],\n",
      "            [ 81.,  81.,  81.],\n",
      "            [ 81.,  81.,  81.]],\n",
      "\n",
      "           [[ 81.,  81.,  81.],\n",
      "            [ 81.,  81.,  81.],\n",
      "            [ 81.,  81.,  81.]],\n",
      "\n",
      "           [[ 81.,  81.,  81.],\n",
      "            [ 81.,  81.,  81.],\n",
      "            [ 81.,  81.,  81.]]],\n",
      "\n",
      "\n",
      "          [[[162., 162., 162.],\n",
      "            [162., 162., 162.],\n",
      "            [162., 162., 162.]],\n",
      "\n",
      "           [[162., 162., 162.],\n",
      "            [162., 162., 162.],\n",
      "            [162., 162., 162.]],\n",
      "\n",
      "           [[162., 162., 162.],\n",
      "            [162., 162., 162.],\n",
      "            [162., 162., 162.]]],\n",
      "\n",
      "\n",
      "          [[[243., 243., 243.],\n",
      "            [243., 243., 243.],\n",
      "            [243., 243., 243.]],\n",
      "\n",
      "           [[243., 243., 243.],\n",
      "            [243., 243., 243.],\n",
      "            [243., 243., 243.]],\n",
      "\n",
      "           [[243., 243., 243.],\n",
      "            [243., 243., 243.],\n",
      "            [243., 243., 243.]]]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "kernel_size = [3,3,3,3]\n",
    "layer_pars = {\"in_channels\": 1,\n",
    "              \"out_channels\": 1,\n",
    "              \"kernel_size\": kernel_size,\n",
    "              \"stride\": [1,1,1,1],\n",
    "              \"dilation\": [1,1,1,1],\n",
    "              \"bias\": True,\n",
    "              \"kernel_initializer\" : lambda x: torch.nn.init.constant_(x, 1),\n",
    "              \"bias_initializer\" : lambda x: torch.nn.init.constant_(x, 0)\n",
    "             }\n",
    "#kernel_initializer=lambda x: torch.nn.init.constant_(x, 1),\n",
    "#bias_initializer=lambda x: torch.nn.init.constant_(x, 0))\n",
    "\n",
    "conv4dv2_layer = MyConv4dv2(**layer_pars)\n",
    "\n",
    "test_input_shape = [1,1,5,5,5,5]\n",
    "\n",
    "test_input = torch.zeros(*test_input_shape)\n",
    "#test_input[0,0,1,:,:,:] = 1\n",
    "#test_input[0,0,0,:,:,:] = 1\n",
    "\n",
    "for i in range(0,test_input_shape[2]):\n",
    "    test_input[0,0,i,:,:,:] = i\n",
    "print(test_input)\n",
    "test_output = conv4dv2_layer(test_input)\n",
    "print(test_output.size())\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[[ 0.,  1.,  2.],\n",
      "            [ 3.,  4.,  5.],\n",
      "            [ 6.,  7.,  8.]],\n",
      "\n",
      "           [[ 9., 10., 11.],\n",
      "            [12., 13., 14.],\n",
      "            [15., 16., 17.]],\n",
      "\n",
      "           [[18., 19., 20.],\n",
      "            [21., 22., 23.],\n",
      "            [24., 25., 26.]]],\n",
      "\n",
      "\n",
      "          [[[27., 28., 29.],\n",
      "            [30., 31., 32.],\n",
      "            [33., 34., 35.]],\n",
      "\n",
      "           [[36., 37., 38.],\n",
      "            [39., 40., 41.],\n",
      "            [42., 43., 44.]],\n",
      "\n",
      "           [[45., 46., 47.],\n",
      "            [48., 49., 50.],\n",
      "            [51., 52., 53.]]],\n",
      "\n",
      "\n",
      "          [[[54., 55., 56.],\n",
      "            [57., 58., 59.],\n",
      "            [60., 61., 62.]],\n",
      "\n",
      "           [[63., 64., 65.],\n",
      "            [66., 67., 68.],\n",
      "            [69., 70., 71.]],\n",
      "\n",
      "           [[72., 73., 74.],\n",
      "            [75., 76., 77.],\n",
      "            [78., 79., 80.]]]]]], dtype=torch.float64)\n",
      "input_size: [1 1 3 3 3 3]\n",
      "output_size: [1 1 2 2 2 2]\n",
      "row_4d_num: 3\n",
      "output_row_4d_num: 2\n",
      "kernel_3d_i: 0\n",
      "convolving rows: [0,2)\n",
      "slicing 4d block of size: torch.Size([1, 1, 2, 3, 3, 3])\n",
      "transposing 4d block to size: torch.Size([1, 2, 1, 3, 3, 3])\n",
      "convolving 4d block of size: torch.Size([2, 1, 3, 3, 3])\n",
      "kernel_3d_i: 1\n",
      "convolving rows: [1,3)\n",
      "slicing 4d block of size: torch.Size([1, 1, 2, 3, 3, 3])\n",
      "transposing 4d block to size: torch.Size([1, 2, 1, 3, 3, 3])\n",
      "convolving 4d block of size: torch.Size([2, 1, 3, 3, 3])\n",
      "torch.Size([1, 1, 2, 2, 2, 2])\n",
      "tensor([[[[[[320., 336.],\n",
      "            [368., 384.]],\n",
      "\n",
      "           [[464., 480.],\n",
      "            [512., 528.]]],\n",
      "\n",
      "\n",
      "          [[[752., 768.],\n",
      "            [800., 816.]],\n",
      "\n",
      "           [[896., 912.],\n",
      "            [944., 960.]]]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "kernel_size = [2,2,2,2]\n",
    "layer_pars = {\"in_channels\": 1,\n",
    "              \"out_channels\": 1,\n",
    "              \"kernel_size\": kernel_size,\n",
    "              \"stride\": [1,1,1,1],\n",
    "              \"dilation\": [1,1,1,1],\n",
    "              \"bias\": True,\n",
    "              \"kernel_initializer\" : lambda x: torch.nn.init.constant_(x, 1),\n",
    "              \"bias_initializer\" : lambda x: torch.nn.init.constant_(x, 0)\n",
    "             }\n",
    "#kernel_initializer=lambda x: torch.nn.init.constant_(x, 1),\n",
    "#bias_initializer=lambda x: torch.nn.init.constant_(x, 0))\n",
    "\n",
    "conv4dv2_layer = MyConv4dv2(**layer_pars)\n",
    "\n",
    "test_input_shape = [1,1,3,3,3,3]\n",
    "\n",
    "test_input = np.arange(float(np.prod(test_input_shape)))\n",
    "test_input = test_input.reshape(test_input_shape)\n",
    "test_input = torch.tensor(test_input)\n",
    "print(test_input)\n",
    "test_output = conv4dv2_layer(test_input.float())\n",
    "print(test_output.size())\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(320., dtype=torch.float64)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input[0,0,0:2,0:2,0:2,0:2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input[0,0,0:2,1:3,1:3,1:3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv4d_check():\n",
    "\n",
    "    print()\n",
    "    print('TEST PYTORCH CONV4D LAYER IMPLEMENTATION')\n",
    "    print('\\n' + 80 * '-' + '\\n')\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Generate random input 4D tensor (+ batch dimension, + channel dimension)\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    input_numpy = np.round(np.random.random((1, 1, 10, 11, 12, 13)) * 100)\n",
    "    input_torch = torch.from_numpy(input_numpy).float()\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Convolve with a randomly initialized kernel\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    print('Randomly Initialized Kernels:\\n')\n",
    "\n",
    "    # Initialize the 4D convolutional layer with random kernels\n",
    "    conv4d_layer = \\\n",
    "        Conv4d(in_channels=1,\n",
    "               out_channels=1,\n",
    "               kernel_size=(3, 3, 3, 3)\n",
    "               )\n",
    "    \n",
    "    myconv4d_layer = \\\n",
    "        MyConv4d(in_channels=1,\n",
    "               out_channels=1,\n",
    "               kernel_size=(3, 3, 3, 3)\n",
    "               )\n",
    "    \n",
    "    myconv4dv2_layer = \\\n",
    "        MyConv4dv2(in_channels=1,\n",
    "               out_channels=1,\n",
    "               kernel_size=(3, 3, 3, 3)\n",
    "               )\n",
    "\n",
    "    # Pass the input tensor through that layer\n",
    "    output = conv4d_layer.forward(input_torch).data.numpy()\n",
    "    myoutput = myconv4d_layer.forward(input_torch).data.numpy()\n",
    "    myoutputv2 = myconv4dv2_layer.forward(input_torch).data.numpy()\n",
    "\n",
    "    # Select the 3D kernels for the manual computation and comparison\n",
    "    kernels = [conv4d_layer.conv3d_layers[i].weight.data.numpy().flatten()\n",
    "               for i in range(3)]\n",
    "\n",
    "    # Compare the conv4d_layer result and the manual convolution computation\n",
    "    # at 3 randomly chosen locations\n",
    "    for i in range(3):\n",
    "\n",
    "        # Randomly choose a location and select the conv4d_layer output\n",
    "        loc = [np.random.randint(0, output.shape[2] - 2),\n",
    "               np.random.randint(0, output.shape[3] - 2),\n",
    "               np.random.randint(0, output.shape[4] - 2),\n",
    "               np.random.randint(0, output.shape[5] - 2)]\n",
    "        conv4d = output[0, 0, loc[0], loc[1], loc[2], loc[3]]\n",
    "        myconv4d = myoutput[0, 0, loc[0], loc[1], loc[2], loc[3]]\n",
    "        myconv4dv2 = myoutputv2[0, 0, loc[0], loc[1], loc[2], loc[3]]\n",
    "\n",
    "        # Select slices from the input tensor and compute manual convolution\n",
    "        slices = [input_numpy[0, 0, loc[0] + j, loc[1]:loc[1] + 3,\n",
    "                              loc[2]:loc[2] + 3, loc[3]:loc[3] + 3].flatten()\n",
    "                  for j in range(3)]\n",
    "        manual = np.sum([slices[j] * kernels[j] for j in range(3)])\n",
    "\n",
    "        # Print comparison\n",
    "        print(f'At {tuple(loc)}:')\n",
    "        print(f'\\tconv4d:\\t{conv4d}')\n",
    "        print(f'\\tmyconv4d:\\t{myconv4d}')\n",
    "        print(f'\\tmyconv4dv2:\\t{myconv4dv2}')\n",
    "        print(f'\\tmanual:\\t{manual}')\n",
    "\n",
    "    print('\\n' + 80 * '-' + '\\n')\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Convolve with a kernel initialized to be all ones\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    print('Constant Kernels (all 1):\\n')\n",
    "\n",
    "    conv4d_layer = \\\n",
    "        Conv4d(in_channels=1,\n",
    "               out_channels=1,\n",
    "               kernel_size=(3, 3, 3, 3),\n",
    "               padding=1,\n",
    "               kernel_initializer=lambda x: torch.nn.init.constant_(x, 1),\n",
    "               bias_initializer=lambda x: torch.nn.init.constant_(x, 0))\n",
    "    output = conv4d_layer.forward(input_torch)\n",
    "    \n",
    "    myconv4d_layer = \\\n",
    "        MyConv4d(in_channels=1,\n",
    "               out_channels=1,\n",
    "               kernel_size=(3, 3, 3, 3),\n",
    "               #padding=1,\n",
    "               kernel_initializer=lambda x: torch.nn.init.constant_(x, 1),\n",
    "               bias_initializer=lambda x: torch.nn.init.constant_(x, 0))\n",
    "    output = conv4d_layer.forward(input_torch)\n",
    "    \n",
    "    myconv4dv2_layer = \\\n",
    "        MyConv4dv2(in_channels=1,\n",
    "               out_channels=1,\n",
    "               kernel_size=(3, 3, 3, 3),\n",
    "               #padding=1,\n",
    "               kernel_initializer=lambda x: torch.nn.init.constant_(x, 1),\n",
    "               bias_initializer=lambda x: torch.nn.init.constant_(x, 0))\n",
    "    \n",
    "    output = conv4d_layer.forward(input_torch)\n",
    "    myoutput = myconv4d_layer.forward(input_torch)\n",
    "    myoutputv2 = myconv4dv2_layer.forward(input_torch)\n",
    "    \n",
    "    # Define relu(x) = max(x, 0) for simplified indexing below\n",
    "    def relu(x: float) -> float:\n",
    "        return x * (x > 0)\n",
    "\n",
    "    # Compare the conv4d_layer result and the manual convolution computation\n",
    "    # at 3 randomly chosen locations\n",
    "    for i in range(3):\n",
    "\n",
    "        # Randomly choose a location and select the conv4d_layer output\n",
    "        loc = [np.random.randint(0, output.shape[2] - 2),\n",
    "               np.random.randint(0, output.shape[3] - 2),\n",
    "               np.random.randint(0, output.shape[4] - 2),\n",
    "               np.random.randint(0, output.shape[5] - 2)]\n",
    "        conv4d = output[0, 0, loc[0], loc[1], loc[2], loc[3]]\n",
    "        myconv4d = myoutput[0, 0, loc[0], loc[1], loc[2], loc[3]]\n",
    "        myconv4dv2 = myoutputv2[0, 0, loc[0], loc[1], loc[2], loc[3]]\n",
    "\n",
    "        # For a kernel that is all 1s, we only need to sum up the elements of\n",
    "        # the input (the ReLU takes care of the padding!)\n",
    "        manual = input_numpy[0, 0,\n",
    "                             relu(loc[0] - 1):loc[0] + 2,\n",
    "                             relu(loc[1] - 1):loc[1] + 2,\n",
    "                             relu(loc[2] - 1):loc[2] + 2,\n",
    "                             relu(loc[3] - 1):loc[3] + 2].sum()\n",
    "\n",
    "        # Print comparison\n",
    "        print(f'At {tuple(loc)}:')\n",
    "        print(f'\\tconv4d:\\t{conv4d}')\n",
    "        print(f'\\tmyconv4d:\\t{myconv4d}')\n",
    "        print(f'\\tmyconv4dv2:\\t{myconv4dv2}')\n",
    "        print(f'\\tmanual:\\t{manual}')\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST PYTORCH CONV4D LAYER IMPLEMENTATION\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Randomly Initialized Kernels:\n",
      "\n",
      "input_size: [ 1  1 10 11 12 13]\n",
      "output_size: [ 1  1  8  9 10 11]\n",
      "row_4d_num: 10\n",
      "output_row_4d_num: 8\n",
      "kernel_3d_i: 0, row_4d_i: 0\n",
      "output_row: 0\n",
      "kernel_3d_i: 0, row_4d_i: 1\n",
      "output_row: 1\n",
      "kernel_3d_i: 0, row_4d_i: 2\n",
      "output_row: 2\n",
      "kernel_3d_i: 0, row_4d_i: 3\n",
      "output_row: 3\n",
      "kernel_3d_i: 0, row_4d_i: 4\n",
      "output_row: 4\n",
      "kernel_3d_i: 0, row_4d_i: 5\n",
      "output_row: 5\n",
      "kernel_3d_i: 0, row_4d_i: 6\n",
      "output_row: 6\n",
      "kernel_3d_i: 1, row_4d_i: 1\n",
      "output_row: 0\n",
      "kernel_3d_i: 1, row_4d_i: 2\n",
      "output_row: 1\n",
      "kernel_3d_i: 1, row_4d_i: 3\n",
      "output_row: 2\n",
      "kernel_3d_i: 1, row_4d_i: 4\n",
      "output_row: 3\n",
      "kernel_3d_i: 1, row_4d_i: 5\n",
      "output_row: 4\n",
      "kernel_3d_i: 1, row_4d_i: 6\n",
      "output_row: 5\n",
      "kernel_3d_i: 1, row_4d_i: 7\n",
      "output_row: 6\n",
      "kernel_3d_i: 2, row_4d_i: 2\n",
      "output_row: 0\n",
      "kernel_3d_i: 2, row_4d_i: 3\n",
      "output_row: 1\n",
      "kernel_3d_i: 2, row_4d_i: 4\n",
      "output_row: 2\n",
      "kernel_3d_i: 2, row_4d_i: 5\n",
      "output_row: 3\n",
      "kernel_3d_i: 2, row_4d_i: 6\n",
      "output_row: 4\n",
      "kernel_3d_i: 2, row_4d_i: 7\n",
      "output_row: 5\n",
      "kernel_3d_i: 2, row_4d_i: 8\n",
      "output_row: 6\n",
      "input_size: [ 1  1 10 11 12 13]\n",
      "output_size: [ 1  1  8  9 10 11]\n",
      "row_4d_num: 10\n",
      "output_row_4d_num: 8\n",
      "kernel_3d_i: 0\n",
      "convolving rows: [0,8)\n",
      "slicing 4d block of size: torch.Size([1, 1, 8, 11, 12, 13])\n",
      "transposing 4d block to size: torch.Size([1, 8, 1, 11, 12, 13])\n",
      "convolving 4d block of size: torch.Size([8, 1, 11, 12, 13])\n",
      "kernel_3d_i: 1\n",
      "convolving rows: [1,9)\n",
      "slicing 4d block of size: torch.Size([1, 1, 8, 11, 12, 13])\n",
      "transposing 4d block to size: torch.Size([1, 8, 1, 11, 12, 13])\n",
      "convolving 4d block of size: torch.Size([8, 1, 11, 12, 13])\n",
      "kernel_3d_i: 2\n",
      "convolving rows: [2,10)\n",
      "slicing 4d block of size: torch.Size([1, 1, 8, 11, 12, 13])\n",
      "transposing 4d block to size: torch.Size([1, 8, 1, 11, 12, 13])\n",
      "convolving 4d block of size: torch.Size([8, 1, 11, 12, 13])\n",
      "At (1, 4, 3, 2):\n",
      "\tconv4d:\t-26.5401611328125\n",
      "\tmyconv4d:\t-70.64613342285156\n",
      "\tmyconv4dv2:\t-24.736698150634766\n",
      "\tmanual:\t-26.741858668625355\n",
      "At (1, 5, 5, 8):\n",
      "\tconv4d:\t-36.89032745361328\n",
      "\tmyconv4d:\t-27.742931365966797\n",
      "\tmyconv4dv2:\t-42.811588287353516\n",
      "\tmanual:\t-37.09203040599823\n",
      "At (1, 6, 1, 5):\n",
      "\tconv4d:\t33.55345916748047\n",
      "\tmyconv4d:\t-8.753999710083008\n",
      "\tmyconv4dv2:\t-43.94815444946289\n",
      "\tmanual:\t33.35174976289272\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Constant Kernels (all 1):\n",
      "\n",
      "input_size: [ 1  1 10 11 12 13]\n",
      "output_size: [ 1  1  8  9 10 11]\n",
      "row_4d_num: 10\n",
      "output_row_4d_num: 8\n",
      "kernel_3d_i: 0, row_4d_i: 0\n",
      "output_row: 0\n",
      "kernel_3d_i: 0, row_4d_i: 1\n",
      "output_row: 1\n",
      "kernel_3d_i: 0, row_4d_i: 2\n",
      "output_row: 2\n",
      "kernel_3d_i: 0, row_4d_i: 3\n",
      "output_row: 3\n",
      "kernel_3d_i: 0, row_4d_i: 4\n",
      "output_row: 4\n",
      "kernel_3d_i: 0, row_4d_i: 5\n",
      "output_row: 5\n",
      "kernel_3d_i: 0, row_4d_i: 6\n",
      "output_row: 6\n",
      "kernel_3d_i: 1, row_4d_i: 1\n",
      "output_row: 0\n",
      "kernel_3d_i: 1, row_4d_i: 2\n",
      "output_row: 1\n",
      "kernel_3d_i: 1, row_4d_i: 3\n",
      "output_row: 2\n",
      "kernel_3d_i: 1, row_4d_i: 4\n",
      "output_row: 3\n",
      "kernel_3d_i: 1, row_4d_i: 5\n",
      "output_row: 4\n",
      "kernel_3d_i: 1, row_4d_i: 6\n",
      "output_row: 5\n",
      "kernel_3d_i: 1, row_4d_i: 7\n",
      "output_row: 6\n",
      "kernel_3d_i: 2, row_4d_i: 2\n",
      "output_row: 0\n",
      "kernel_3d_i: 2, row_4d_i: 3\n",
      "output_row: 1\n",
      "kernel_3d_i: 2, row_4d_i: 4\n",
      "output_row: 2\n",
      "kernel_3d_i: 2, row_4d_i: 5\n",
      "output_row: 3\n",
      "kernel_3d_i: 2, row_4d_i: 6\n",
      "output_row: 4\n",
      "kernel_3d_i: 2, row_4d_i: 7\n",
      "output_row: 5\n",
      "kernel_3d_i: 2, row_4d_i: 8\n",
      "output_row: 6\n",
      "input_size: [ 1  1 10 11 12 13]\n",
      "output_size: [ 1  1  8  9 10 11]\n",
      "row_4d_num: 10\n",
      "output_row_4d_num: 8\n",
      "kernel_3d_i: 0\n",
      "convolving rows: [0,8)\n",
      "slicing 4d block of size: torch.Size([1, 1, 8, 11, 12, 13])\n",
      "transposing 4d block to size: torch.Size([1, 8, 1, 11, 12, 13])\n",
      "convolving 4d block of size: torch.Size([8, 1, 11, 12, 13])\n",
      "kernel_3d_i: 1\n",
      "convolving rows: [1,9)\n",
      "slicing 4d block of size: torch.Size([1, 1, 8, 11, 12, 13])\n",
      "transposing 4d block to size: torch.Size([1, 8, 1, 11, 12, 13])\n",
      "convolving 4d block of size: torch.Size([8, 1, 11, 12, 13])\n",
      "kernel_3d_i: 2\n",
      "convolving rows: [2,10)\n",
      "slicing 4d block of size: torch.Size([1, 1, 8, 11, 12, 13])\n",
      "transposing 4d block to size: torch.Size([1, 8, 1, 11, 12, 13])\n",
      "convolving 4d block of size: torch.Size([8, 1, 11, 12, 13])\n",
      "At (7, 2, 2, 4):\n",
      "\tconv4d:\t4285.0\n",
      "\tmyconv4d:\t0.0\n",
      "\tmyconv4dv2:\t4149.0\n",
      "\tmanual:\t4285.0\n",
      "At (6, 6, 9, 0):\n",
      "\tconv4d:\t3272.0\n",
      "\tmyconv4d:\t4321.0\n",
      "\tmyconv4dv2:\t4321.0\n",
      "\tmanual:\t3272.0\n",
      "At (2, 6, 6, 5):\n",
      "\tconv4d:\t4001.0\n",
      "\tmyconv4d:\t3946.0\n",
      "\tmyconv4dv2:\t3946.0\n",
      "\tmanual:\t4001.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conv4d_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
